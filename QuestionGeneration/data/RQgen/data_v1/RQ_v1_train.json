{"intro": ": In recent years, conversational agents or chatbots have received great attention. Since 2016, major tech companies started providing open APIs for building chatbots. This resulted in a massive growth of chatbots especially the chatbots on text messaging platforms. Currently, more than 300,000 bots exist on Facebook messenger cutting across a variety of use-cases-online shopping , casual chatting , travel arrangements , etc. So, far, the focus has been largely commercial, e.g. customer support, since the service providers see chatbots as a cost-e ective and e cient way to supplement human-based customer service. However, chatbots also o er opportunities for creating positive social impact . With the ability to reach millions in a ordable ways, chatbots o er unique opportunities to empower those living in the constrained environments. Further, we discuss the ethical implications of introducing breastfeeding education chatbot in the study context and potential societal impact. INTRODUCTION: Recently, HCI and CSCW communities have started exploring use of chatbots for variety of problem domains . In India, the access to doctor is limited given the poor ratio of almost 4.8 doctors to 10,000 people . To ll this gap, India uses a large network of community health workers for critical areas of public health such as maternal and child health. We want to explore the use of chatbots in assisting community health worker and mothers in the exclusive context of breastfeeding. Promoting exclusive breastfeeding is a global priority of maternal and child health programs because of its importance in child survival . Timely initiation of breastfeeding and exclusive breastfeeding for the rst six months of child's life helps in preventing 20% newborn death and 13% under-ve deaths . However, despite this knowledge, breastfeeding rates fall short of recommendation . INTRODUCTION: Our users, community health workers and mothers residing in under-developed (slums) regions of India, have limited or no access to technological advancements in chatbot research, such as Alexa or Google Home, because of poor economic conditions and limited literacy. While they now possess smart-phone, it is often a low-end smart-phone (< $100) . Moreover, the socio-economical conditions dictate that the phone may be shared within the family, often with the husband or other male members of the family . This makes our users, the rst-time users of chatbots. INTRODUCTION: These rst time users of chatbots, in their unique contexts, represent an important class to study and design for. So far, the research around chatbots has been majorly technology driven with limited investigation on user perceptions and contexts of use . INTRODUCTION: In this study, we explore the feasibility of using chatbots for breastfeeding education of community health workers and mothers in urbal slum areas of India and understand how they react and perceive chatbot based intervention. We aim to contribute to the HCI and CSCW community by informing design recommendations for chatbot implementation for causes like breastfeeding education in under-developed areas, with users who are newcomers to personal device use. We guide our exploration with the following research questions: INTRODUCTION: (1) What is the perception of users towards chatbot based breastfeeding assistance? (2) What kind of information users -CHWs and Mothers -seek from a chatbot? (3) What are the contexts of chatbot use for mothers and community health workers residing in slum areas of India? INTRODUCTION: We study users' interaction with the chatbot through a Wizard-of-Oz experiment with 22 participants (12 ASHAs and 10 mothers). We prototyped our chatbot as an interactive questionanswering application and analyzed users' interaction patterns, perceptions, and contexts of use. Our ndings highlight the role of familial unit in breastfeeding practices. We found that the majority of questions sought by users are answerable by a chatbot and value of chatbots for mothers as a rst point of contact. This gives us the con dence that breastfeeding education is a potential application for chatbot intervention. We also discuss implications for the design for future bots and the characteristics they should embody to address users' concern in constrained settings.", "relatedWork": "3.1 Breastfeeding Practices in India, Support System and Role of CHWs: Breastfeeding is considered to be the best way of providing optimal food to infants. Ideally, breastfeeding should be initiated within 1 hr of childbirth, practiced exclusively for the rst six months and then continued with the addition of adequate complementary foods up to two years of life . Good breastfeeding practice is directly linked with improved survival rates of under-5 and child's health that includes optimal cognitive development and lower risk of obesity and diabetes later in life. Mothers get positive bene ts in terms of reduced risk of haemorrhage and breast cancer . RELATED WORK 3.1 Breastfeeding Practices in India, Support System and Role of CHWs: According to the study that examines trends in the young child feeding practices in India in the period of 2006-2016, breastfeeding practices have shown signi cant improvements: Early initiation of breastfeeding nearly doubled from 23% to 42%, and Exclusive breastfeeding increased from 46% to 55%. However, still, a major cohort of children are missing out and the current rates, at best can be described as modest . Several factors play role in dis-continuation of breastfeeding. RELATED WORK 3.1 Breastfeeding Practices in India, Support System and Role of CHWs: While it is known that barriers to breastfeeding occur at the social, cultural and political level that are outside of maternal control , there are di erences in contexts of these factors. Prevalence of traditional beliefs and wrong practices among women (both rural and urban areas) are a major deterrent to exclusive breastfeeding . Many families commonly practice prelacteal feeding as a ritual and discard colostrum . For example, in some of the Hindu communities, after birth, a child is welcomed through a ceremony in which a family member writes the word \"OM\" onto the tongue of the child with honey in the hope to wish good qualities to the infant. In some castes, breastfeeding is delayed until fth day due to their belief in ancient medical science. Perception of insu cient milk supply among mothers and caregivers is also a common barrier to exclusive breastfeeding. The study found that nearly 33% women believed their milk supply would be low for their child and introduced animal milk and external food. Another challenge for new mothers is con icting advice from a health practitioner and a family member. Female relatives in the house have a strong in uence on breastfeeding practices. RELATED WORK 3.1 Breastfeeding Practices in India, Support System and Role of CHWs: From the country's perspective, to support optimal infant and young child feeding practices (IYCF), various strategies have been established . However, gaps remain at the implementation level. For instance, the Maternity Bene t Act 1961 was amended only recently in 2017 for extending the paid maternity leaves for working women from 12 weeks to 26 weeks . Further, currently, the act is applicable to certain establishments e.g. government and other organized sectors and does not protect women working in unorganized sectors such as household sta , contractual labors etc. . This directly hampers the women belonging to lower socio-economic strata which hold a greater percentage of the country's population . To improve awareness of women on IYCF, there is an emphasis on providing counseling at health centers and through community outreach. ASHA workers, who play a crucial role in connecting to marginalized communities, are seen as an important vehicle of behavioral change and thereby also trained on IYCF to promote exclusive breastfeeding in their post-natal home visitations . However, a range of challenges exists in translating the knowledge into actual practice. Due to over-burdened duties, high engagement in paperwork and sub-optimal training, ASHAs' awareness of being health educators has been found to be low . Studies assessing ASHAs knowledge on breastfeeding practices report that though their knowledge is good, signi cant improvement is required on addressing prelacteal feeds, mothers perception on milk supply, and complementary food . Further, there is a scarcity of studies to report on how mothers are supported beyond the six home visits of the ASHAs that is after 42 days of delivery. Conversational Agents: Growth and Opportunities: Although the buzz around chatbot might appear to be newer, the history dates back to 1966 when the rst-ever chatter bot named ELIZA was launched . ELIZA was a computer program that could respond in natural language to engage patients in psychotherapy. Using keyword spotting and pattern matching algorithm ELIZA would select the most appropriate responses from a pre-de ned set. Later, more advanced form of the ELIZA developed and became popular e.g. Parry (1972), JabberWacky (1988), ALICE (1995) . Conversational Agents: Growth and Opportunities: The key idea behind is to provide personalized assistance to the users through the mediation of human-like conversations. Advances in the eld of arti cial intelligence have led the chatbots to pick momentum. They can now learn user experiences and context and based on user history respond better in real-time. These interactions keep on improving as the user interacts more with the bot. Chatbots are increasingly being designed for variety of purposes, e.g. engaging in small talk , imitating psychotherapy , coordinating team events , updating on weather , and improving customer service . And thrives on almost all popular digital forums, like messenger apps, social networking sites, and other conversation interfaces e.g. Amazon Alexa, Google Home, etc. In particular bots embodied in messenger apps gained traction in recent times. For instance, the year end 2016, when Facebook launched its messenger bot platform for the developers, marked the chatbots proliferation to 34,000 , which now has reached 300,000 . Examples of some of the recent popular bots include Mitsuku , started in China, engages and entertains users by telling stories, jokes, and songs. Similar to this is Microsoft's Xiaoice that is mostly liked for its sense of humor and ability to entertain users based on their mood cues. Beyond the commercial purpose, which has been the large focus till now, there is a growing consensus on the potential of chatbots in creating a positive impact on society . Due to the much wider reach, ease of access and interaction, chatbots can extend the public services. Healthcare sector is one of the promising areas for the chatbots. Low doctor to patient ratios, high cost, and complex procedures increase the gap between professionals and patients. Chatbots can bridge the gap by providing preliminary assistance . As of today, the use-cases of tasks taken over by bots include making doctor's appointment, checking medical history, post-discharge follow-up, information searching, and lifestyle promotion. Few examples of the chatbots are as follows. Babylon Health , asks questions on symptoms, provides detailed information and additionally book an appointment with physicians. Florence acts like a nurse that reminds taking pills, track health (body weight, periods ) and help nd a specialist in the nearby area. Safedrugbot is designed to help doctors get information on the side e ects of drugs during breastfeeding Technology and Motherhood: In recent year, HCI research exploring the role of digital technologies for women's health has increased, particularly covering di erent aspects of motherhood. Social attitude towards breastfeeding in public, varies widely across cultures and countries. In UK, where it is mostly perceived to be a personal act, it is di cult for mothers to engage in breastfeeding practice openly outside homes. The study , proposes and develops a mobile application, \"FeedFinder\", to help a woman nd breastfeeding places in nearby area, review and share them with other women. The work report on the challenges in co-designing the application with mothers and design implications for mobile technologies to support public health. On similar lines of understanding the mothers' issues in using technology, presents the development of \"Milk matters\", an application to motivate women in donating surplus breastmilk to nearby milk banks. The paper informs on the design considerations to make while working with mothers: interrupted interactions, elements of distraction and value of positive reinforcement. In many developing countries, the infrastructure to support storage and distribution of breastmilk, often known as Milk Banks does not exist. To address, a recent work , proposed a low-cost solution for milk pasteurization using mobile and sensing technologies. To this emerging line of HCI research around motherhood, contributes by analysis of 1000 submitted ideas of mothers on the improvement of breast pump. The paper highlights the complexity of post-partum phase and suggests using principles of feminist HCI and participatory design in designing supportive technologies. In developed countries, often new mothers face isolation in their initial phase of motherhood, conducted an ethnographic study to understand the role of technology in the emotional and social well being of mothers and highlights the power of technology to provide social connectedness. Applications for expectant and new mothers to share information within their intimate group or communication tools to stay connected with supporting people have been found to be e ective. Technology and Motherhood: Apart from research endeavors, public health services have shown interest in leveraging technology to extend breastfeeding support. For example, Public Health England has launched a chatbot application under the program-Start4life over Facebook Messenger and Alexa platforms to provide 24/7 support . have worked towards developing tools to enhance communication between mothers and hospital sta . Also, commercially, there is an increase in applications targeting motherhood needs. A simple google or app store search on breastfeeding and motherhood leads to various options, which could be either paid or free, available for both android and IOS platforms e.g. Baby Tracker , LactMed , LatchMe , MyMedela , Feed Baby-breastfeeding app etc. Technology and Motherhood: While the above-mentioned works are towards women who are digitally literate and belong to urban settings of the developed world, there are others from marginalized groups, for whom we have limited understanding. Recent a ordances to smartphones in developing nations, have made women in under-served contexts to start owning smartphones and explore the digital world, which earlier was a remote possibility for them. These women represent an important class of users for HCI and CSCW communities. We extend the limited but growing body of work on the intersection of technology for women's health and technology use by marginalized women through presenting our insights into the perceptions, experience, and contexts of chatbot application by mothers and community health workers in slum areas of Delhi, India. Technology Based Support to CHWs: Community Health Workers are the last mile actors of healthcare who serve communities often vulnerable populations towards accessing health services and adopting healthy behaviors. In particular, their role in reducing mortality rates for maternal and child health has been signi cant. Thus, increasingly more programs are aiming towards innovating methods to empower CHWs at the global level. Particularly, empowerment through technology integration in the ongoing endeavors has been an important direction . Technology Based Support to CHWs: Since CHWs often work in resource-constrained settings, whereby, infrastructure and technology penetration is limited, e orts have been towards making simple, low-cost and e ective solutions. For instance, because of the high use of phones by CHWs, mostly feature phones, a rich body of work surrounds designing mobile-based solutions. By providing assistance through mobile applications, researchers focus on furthering CHWs performance which gets a ected due to factors including limited supervision, education, and training . For example, mobile applications e.g. SMSs, IVR, e-checklists have been used in improving CHWs adherence to house visits and case management guidelines . In addition to supporting supervision, data collection by CHWs has been facilitated . Technology Based Support to CHWs: Community education has been highlighted to be one of the most challenging tasks for CHWs . Studies have found a number of causing factors. For example, in persuading families CHWs face resistance due to low literacy, compliance with old age traditions and practices . Due to minimum focus on the role of activists by existing training and supervision, CHWs remain unclear on how to execute the role of counselor . Further, Limited, irregular payment of incentives and overburdened duties have been reported to negatively a ect CHWs motivation towards counseling job . In this regard, use of mobile multimedia is increasingly being investigated in multiple ways because it o ers an e ective method of equipping ASHAs with authentic health information which they can use anytime and anywhere in the elds. Ramachandran et al. addressed two challenges of community education as to how to persuade women towards the adoption of healthy behaviors and enhance the motivation of CHWs towards e ective consultation. By providing short videos on health topics and testimonial videos by in uencing actors of the village to CHWs, researchers could observe enhancement in the quality of dialogue between the CHWs and the families and self-e cacy of CHWs. The study by Fiore-Silfvast et al. further con rms the usefulness of such videos in the work ow of CHWs by understanding their perspective on technology adoption. Technology Based Support to CHWs: Distinct from the aforementioned studies which adopt top-down approach in providing content to CHWs, Molapo et al. proposed a software tool for health trainers in rural areas, to create their localized content. The easy to use computer application enabled the trainers to create nontextual content that ful lled their community speci c needs. On the similar line, Kumar et al. demonstrated the impact of community participation in content creation and its use in the adoption of globally approved health practices. Further, there are studies that complement the prior work by understanding the sustainability aspect of mobile videos and the value of involving CHWs directly in designing the content and applications . Technology Based Support to CHWs: Shortage of skilled trainers is a known challenge in upgrading skills of CHWs on a regular basis. A number of studies and projects have thus attempted to focus on using technology-based solutions to provide better learning opportunities for CHWs . The study by Yadav et al. provided a learning platform, Sangoshthi, that enables live interaction between remote CHWs and experts. The study found positive outcomes in terms of signi cant knowledge gains and perceived usefulness as a supplementary learning platform by the stakeholders.", "rq": ["(1) what is the perception of users towards chatbot based breastfeeding assistance?", " (2) what kind of information users -chws and mothers -seek from a chatbot?", "(3) what are the contexts of chatbot use for mothers and community health workers residing in slum areas of india?"], "id": "dev_0"}
{"intro": "", "relatedWork": ": Many existing recommendation systems already generate explanations, and several attempts have been made to classify these explanations . In item-based explanations, the system relies on the previous recommendation's outcome to justify the current recommendation: \"I have recommended X because you previously liked/bought Y. \" Feature-based explanations use preferences that were specified by the user during the preference-elicitation process: \"Your interest in Z suggests that you would like X. \" These two different types can be combined: an example of item and feature based explanations can be found in , where the system displays the features of previously liked movies to justify the current recommendation. In the domain of movie recommendations, a system can justify its decision by emphasizing a plot similarity or an overlapping cast . An evaluation comparing featurebased explanations, item-based explanations, and a combination of both shows that the hybrid explanation type was significantly more appreciated by users . RELATED WORK: Both item-based and feature-based explanations are machinecentered and thus essentially reveal the system's decision-making process. Although they have a great impact on transparency, these explanations are tightly coupled with the types of features that the recommendation engine is relying on and may lack the persuasiveness and richness that humans often express when they recommend a specific item. Another important question regarding feature-based explanations is whether they should be personalized to match users' preferences. Research indicates that while personalization generally increases satisfaction, it can be detrimental to effective decision-making . This shows how effectiveness and satisfaction aims can be discordant. RELATED WORK: Human-based explanations take an alternative approach; here, the system relies on collaborative filtering to reference similar products: \"People who liked X also liked Y.\" One such example is , in which the system recommends social software items such as social groups or communities and justifies its choice by showing the names of people in the group/community, as well as their relationship to the user. This relation could be \"familiar\" if the user was friends with the person, or \"similar\" if both shared similar interests. The authors' experiment shows that when these people were \"familiar, \" users were more satisfied with the recommendations. RELATED WORK: Human-based explanations can be merged with feature-based explanations by combining existing reviews with users' preferences to generate explanations: \"You might want to watch X because Bob says that the storyline is amazing and I know that you are highly interested in plot. Here is his review: (...). \" This approach thus uses third-party opinions to justify choices. However, reviews are sometimes extremely long, making them difficult to integrate when conversing with a user. RELATED WORK: As recently demonstrated by , researchers would benefit from taking a more human-centered approach for the design of their recommendation systems, i.e., building systems able to express their \"own\" opinions. The authors' recommendation system, which used social conversational strategies such as self-disclosures and reciprocity in its recommendation process, significantly increased users' satisfaction and intention to seek future recommendations. RELATED WORK: In this paper, we aim to build a conversational recommendation system that recommends movies by expressing its \"own\" opinions and experience through social explanations. We thus focus on the following research questions: RQ-1: What are the types of social conversational strategies that humans use when they describe a movie they watched to someone? RQ-2: Do social explanations used by a conversational recommendation agent to justify its recommendations influence the perceived quality of both the recommendations and the interaction?", "rq": [" rq-1: what are the types of social conversational strategies that humans use when they describe a movie they watched to someone?", " rq-2: Do social explanations used by a conversational recommendation agent to justify its recommendations influence the perceived quality of both the recommendations and the interaction?"], "id": "dev_1"}
{"intro": ": Every semester, a few hundred new computer science students start their academic studies at the University of Vienna. They all face the first difficult task -the transition from high school to university. Many first-year students struggle with this transition, and some even fail . The transition from a predetermined, structured school system to the independence of a university system leads to students feeling disoriented and often having difficulties motivating themselves . They must also adapt to higher academic demands and different teaching methods . A smooth transition is, therefore, more likely if students have access to the information they need and feel socially connected . Concerning the social aspect of transition, social presence is consistently linked to the motivation of the students and is also supposed to influence motivation . The right support for freshmen in this transition phase can help the university to achieve a significantly higher persistence rate of first-year students . Research Interest: Q1: How can a virtual companion, based on Chatbot technology, support the onboarding process of freshmen? Research Interest: In this context, we will consider the following possible approaches, where a virtual companion could help new students: Research Interest: \u2022 getting to know the faculty building, the university campus, and the vicinity \u2022 collecting knowledge, best-practices, tips & tricks for everyday student life \u2022 network building with other freshmen Q2: Is a Chatbot suited for this problem? Some problems are suitable for conversational interfaces and some are not adequate for them. In this project, we want to find out whether the chatbot technology is a good fit for our use cases. Research Interest: The goal of this project is to develop a concept and to implement it to ease the transition from high school to university for first-semester students, thus minimizing transition difficulties and increasing the retention rate; as a technology-based supplement and improvement to the already existing offers. Another goal is in-depth research on Chatbots and their possible applications. Since the past several years, Conversational Agents (CAs) such as Chatbots continue to experience increasing popularity as an interaction modality alternative or augmentative to classical graphical user interfaces (GUIs), prompted, among other developments, by advances in the fields of Artificial Intelligence (AI) and Natural Language Processing (NLP). The increasing availability and capabilities of this low-threshold modality of interaction with a conversational agent hold transformative potential in many scales and sectors of smart tools for humans, e.g. a potential in democratization of technology access for social good ( ) or as a new basis of exploration of the notion of Companion Technology ( ). It is subject to current debate, what role(s) Chatbots can play as interactional modality, as e.g. approached by in pursuit of a typology of Chatbots (see Figure 1 ).", "relatedWork": "", "rq": ["q1: how can a virtual companion, based on chatbot technology, support the onboarding process of freshmen?\n network building with other freshmen", " q2: is a chatbot suited for this problem?"], "id": "dev_2"}
{"intro": ": In the contemporary Internet of Things (IoT) era, people can interact with a multitude of smart devices, always connected to the Internet, in the majority of the today's environments . Smart lamps, thermostats, and many other Internet-enabled appliances are becoming popular in homes and workplaces. Furthermore, by using PCs and smartphones, users can access a variety of online services, ranging from social networks to news and messaging apps. In this complex scenario, the End-User Development (EUD) vision aims at putting personalization mechanisms in the hands of end users, i.e., the subjects who are most familiar with the actual needs to be met . Through visual trigger-action programming platforms such as IFTTT and Zapier , users can \"program\" the joint behaviors of their own connected entities, i.e., smart devices and online service, by defining trigger-action (IF-THEN) rules such as \"if I publish a photo on Facebook, then upload it to my Google Drive\", or \"if the security camera detects a movement, then blink the kitchen lamp. \" INTRODUCTION: Despite apparent simplicity, previous studies highlighted many interoperability, scalability, and understandability challenges suffered by contemporary trigger-action programming platforms. In such environments, smart devices and online services are typically modeled on the basis of the underlying brand or manufacturer : as the number of supported technologies grows, so do the design space, i.e., the combinations between different triggers (if s) and actions (thens), and users often experience difficulties in discovering rules and related functionality . As a result, trigger-action programming becomes a complex task for people without any previous programming experience . Some previous works, e.g., , tackled the identified issues by proposing to move towards a new bread of trigger-action programming platforms supporting a higher level of abstraction, with abstract and technology-independent rules that can be adapted to different contextual situations. With triggers such as \"when user is sleeping\" and actions such as \"illuminate the room\", users can personalize their connected entities by saving time and reducing errors, without the need of explicitly programming every single involved technology. While this vision seems promising, however, it is yet unclear how to effectively move from abstract users' needs to the real devices and services needed for implementing them. How can a system decide how to \"illuminate\" a room? Is turning the lights on the right choice for the user? Does the user prefer to open the blinds, e.g., because she is interested in saving energy? First, it allows users to communicate their personalization intentions and preferences (a). Then, it analyzes users' inputs, along with contextual and semantic information related to the available connected entities, to recommend a set of IF-THEN rules able to map the abstract users' needs to real connected entities (b). INTRODUCTION: In this paper, we present HeyTAP, a conversational and semanticpowered platform able to map abstract users' needs to executable IF-THEN rules. By exploiting a multimodal interface, the user can interact with a conversational agent, either by typing or by voice, to communicate her personalization intentions for different contexts, e.g., to personalize her room's temperature when she is near home (Figure 1a ). By interacting with the agent, the user can also specify her preferences on how to reach the goal of her personalization intention, e.g., convenience and preserving security in Figure 1a . To model such concepts, we extended the EUPont model , a semantic representation for End-User Development in the IoT. We exploited the OWL 1 classes and individuals of EUPont to categorize triggers and actions offered by user's connected entities in terms of provided functionality, and to model contextual information, e.g., the devices and services owned by the user and the relative position. Furthermore, we added classes and restrictions to automatically characterize triggers and actions on the basis of the user's preferences, e.g., to discriminate between energy demanding and privacy invasive behaviors. All these semantic information are used to suggest a set of IF-THEN rules that satisfies the user's needs, i.e., intentions and preferences. The user can finally inspect the recommended rules in the multimodal interface and select one or more of them to personalize her connected entities (Figure 1b ). INTRODUCTION: To understand to what extent HeyTAP is able to successfully guide participants from abstract needs to actual IF-THEN rules, 1 https://www.w3.org/OWL/, last visited on January 18, 2020 we ran an exploratory experiment with 8 users. In the study, we challenged participants in freely personalizing a set of connected entities in different contexts. Results confirm the effectiveness of the approach, and show that HeyTAP can successfully \"translate\" abstract users' needs into IF-THEN rules that can be instantiated and executed by contemporary trigger-action programming platforms. Despite participants expressed their personalization intentions with different level of abstractions, in particular, the tool was able to address the 90.63% of the collected needs, by providing IF-THEN recommendations that satisfied the participants. The collected participants' feedback also highlights possible improvements that could inform future works that aim at assisting users in personalizing their smart devices and online services.", "relatedWork": "S 2.1 Trigger-Action Programming: Opportunities and Issues: One of the most popular paradigm to empower end users in directly programming their connected entities is trigger-action . By defining trigger-action (IF-THEN) rules, users can connect a pair of devices or online services in such a way that, when an event (the trigger) is detected on one of them, an action is automatically executed on the latter. Trigger-action programming offers a very simple and easy to learn solution for creating end-user applications , and trigger-action programming platforms such as IFTTT and Zapier are becoming popular . RELATED WORKS 2.1 Trigger-Action Programming: Opportunities and Issues: Recently, researchers started to investigate different aspects of these solutions, e.g., through empirical characterization of usage perfomances and large-scale analysis of publicly shared rules . Despite apparent simplicity, indeed, the process of composing IF-THEN rules in trigger-action programming platforms has been found to be a complex task for non programmers , and the expressiveness and understandability of solutions like IFTTT have been criticized since they are rather limited . Barricelli and Valtolina analyzed the most popular end-user tools for personalizing connected entities, including IFTTT, and found that some of them \"offers a too complex solution for supporting end users in expressing their preferences.\" By evaluating thousands of trigger-action rules publicly shared on IFTTT, Ur et al. found that the trigger-action approach can be both useful and usable for end-user development in IoT settings like smart homes, but they also found that the level of abstraction end users employ to express triggers needs to be better explored: many users, indeed, express triggers one level of abstraction higher, e.g., \"when I am in the room\" instead of \"when motion is detected by the motion sensor. \" In another study, Ur et al. found that a large number of users is using IFTTT to create a diverse set of IF-THEN rules, which represents a very broad array of connections for filling gaps in devices and services functionality. According to the authors, however, the continuous growth of supported entities and connections highlights the need to provide users with more support for discovering functionality and managing collections of IF-THEN rules. The analysis emphasizes also the future need of making \"IFTTT rules more expressive. \" Similarly, Huang and Cakmak conducted two user studies to systematically study how different types of triggers and actions, e.g., states vs. events, influence the understandability of trigger-action artifacts. They found users' inconsistencies in interpreting the behavior of IF-THEN rules and some errors in creating programs with a desired behavior. Towards a Higher Level of Abstraction: The aforementioned issues are strictly related to the \"low-level\" of abstraction of the adopted representations. Contemporary triggeraction programming platforms, indeed, mainly model smart devices and online services on the basis of the underlying brand or manufacturer, thus opening the way to interoperability, scalability, and understandability issues : to program their IoT ecosystems, users need to know all the involved technologies, and they have to define many different rules even if they perform the same logical operations. Towards a Higher Level of Abstraction: To overcome the drawbacks of low-level representations, different previous works envisioned a new bread of triggeraction programming platforms supporting a higher level of abstraction. In the context of smart homes, for example, Funk et al. asserted that we need \"a new approach aimed at first capturing endusers' intentions and potential usage scenarios, then providing this information to a control system that learns to resolve intentions and scenarios for available devices in the context.\" Following this need, Ghiani et al. proposed a novel trigger-action programming platform to let end users personalize the contextual behavior of their IoT applications through trigger-action rules. By exploiting an authoring tool, in particular, users can specify trigger-action rules that indicate the desired specific application behavior for the target contexts of use, e.g., \"when user is sleeping, do turn-off bedroom television. \" Corno et al. , instead, developed EUPont, a high-level representation for IoT personalization that allows users to model abstract trigger-action rules like \"if I enter a closed space, then illuminate it. \" Such rules can be adapted to different contextual situations, independently of manufacturers, brands, and other technical details. Besides describing the model, the authors presented its integration in the architecture of a trigger-action programming platform, and they explored the advantages of using the model in the definition of trigger-action rules thanks to a user study. They found that the usage of a higher level of abstraction allows users to define IF-THEN rules with fewer errors and in less time with respect to existing solutions. Towards a Higher Level of Abstraction: While a higher level of abstraction in IF-THEN rules is a promising direction, the identification of the real devices and services to be used to satisfy users' needs becomes crucial. In this paper, we aim at presenting a conversational and semantic-powered platform able to map abstract users' needs to IF-THEN rules that can be executed by available connected entities. Programming the IoT via Conversation and Recommendations: By using popular conversational agents such as Amazon Alexa and Google Assistant it is now possible to interact with a variety of different smart devices and online services via conversation. To the best of our knowledge, however, the only example of a conversational system that allows to personalize connected entities through the definition of IF-THEN rules is InstructableCrowd, a research prototype developed by Huang at al. . InstructableCrowd is a crowd-sourcing system that enables users to create IF-THEN rules based on their needs. By exploiting a custom user interface on their smartphones, users can converse with crowd workers to describe some problems they are encountering, e.g., being late for a meeting. Crowd workers can therefore exploit a tailored interface to combine triggers and actions in appropriate IF-THEN rules that are then sent back to the users' phones. Programming the IoT via Conversation and Recommendations: In our work, we focus on a similar goal by trying to automatically map abstract users' needs to actual IF-THEN rules, i.e., without the help of other users such as crowd workers. The idea is to adopt a semantic-based approach to analyze users' inputs and contextual information to recommend a set of appropriate IF-THEN rules from which a user can choose. Recommendations, indeed, could be useful to help end users use trigger-action programming systems, and advances in EUD have expanded the opportunities for offering recommendations . In this context, in particular, some recent works investigated how to provide users with recommendations. Yao et al. , for example, developed a probabilistic framework to suggest relevant smart \"things\" to be personalized based on user interests. Corno et al. , instead, proposed RecRules, a semantic recommendation system that suggests trigger-action rules on the basis of content-based and collaborative information. None of such works, however, explore how to calculate recommendations by extracting users' needs via conversation.", "rq": ["rq1. how would users interact with heytap?", "rq2. is heytap able to map abstract users' needs to executable if-then rules?", "rq3. what is the users' satisfaction in using heytap?"], "id": "dev_3"}
{"intro": ": During the past few years, chatbots, which engage users in a one-on-one, text-based conversation, have been adopted for a wide variety of applications . Among various chatbot applications, a promising one is information elicitation (e.g., ). For example, Tallyn et al. use a chatbot to elicit user input in an ethnographic study . Li et al. build a chatbot to interview job candidates and aid in talent selection . Recent studies also show several benefits of chatbots for information elicitation, such as eliciting higher quality information than using traditional form-based methods (e.g., ). INTRODUCTION: Inspired by these efforts, we are building interview chatbots to conduct user interviews and facilitate user research. To conduct effective interviews, interview chatbots should have skills similar to that of effective human interviewers . One of such important skills is active listening-the abilities to understand and respond to a conversation partner properly . Active listening is shown to facilitate interviews, e.g., eliciting higher quality responses and making an interviewer more socially attractive . In addition, studies find that active listening helps not only oral communication, but also online text communication, including text messaging . Inspired by those findings, we hypothesize that interview chatbots with active listening would be more effective at conducting interviews and engaging interviewees. Figure 1 shows an example of such a chatbot, which can understand the user's input and summarize it in its response, making the user feel heard. INTRODUCTION: Despite recent advances in Artificial Intelligence (AI), it is still challenging to build capable chatbots , let alone create chatbots with active listening skills. Below we highlight three main challenges specific to building effective interview chatbots with active listening skills. INTRODUCTION: First, it is challenging to build interview chatbots that can effectively grasp and respond to user input to open-ended interview questions, which is the core of active listening. For example, in one of our user surveys, a chatbot asked an openended question \"what's the top challenge you're facing\". INTRODUCTION: One user responded: INTRODUCTION: \"The biggest challenge I've faced is finding a since of purpose. Being around like minded individuals who are constantly wanting more out of life through countless jobs I've never found something I was proud of\u2026\" INTRODUCTION: Another user answered the same question very differently: INTRODUCTION: \"With a new baby I have a lot of additional expenses. So I have to try to obtain additional income. I try to earn extra income by working on mturk, but the pay is low and I don't like the additional time taken away from my\u2026\" INTRODUCTION: Given such user input, an effective chatbot should respond to each user empathetically to make them feel heard. Few chatbot platforms, however, enable chatbots to handle such complex and diverse user input. For example, popular chatbot platforms like Chatfuel and Manychat hardly handle user free-text input. More advanced platforms like Google Dialogflow and IBM Watson Assistant support Natural Language Processing (NLP), but they often require that a chatbot designer enumerate all user intents to be handled. With such a method, it would be very challenging to build an interview chatbot, since it is difficult to anticipate diverse user responses to open-ended questions and enumerate all possible user intents. INTRODUCTION: Second, it is difficult to build interview chatbots that can effectively handle complex conversation situations to complete an interview task. As indicated by a recent report, natural language conversations are nonlinear and often go back and forth . In an interview, a user may digress from a planned agenda for various reasons. For example, some users may not understand an interview question and want clarifications (e.g., \"What do you mean\"), while others might dodge a question by responding with \"Why do you want to know?\" or \"I don't know.\" Users might also misunderstand a question or simply do not know how to answer it. For example, one user offered an ambiguous response to the question mentioned above: INTRODUCTION: \"Most challenges are met as an opportunity to grow. Hardest part is losing friends.\" INTRODUCTION: Users may also be \"uncooperative\" and intentionally provide gibberish or irrelevant responses, such as those observed in crowd-sourced user studies . INTRODUCTION: To complete an interview task, a chatbot must \"remember\" and stick to an interview agenda no matter how many times or how far a conversation has digressed from the agenda. However, most chatbots support scripted dialog trees instead of dynamic, graph-like conversations required by effective interview chatbots. INTRODUCTION: Third, it is difficult for chatbot designers to take advantage of AI advances due to a lack of AI expertise or resources. For example, deep learning has enabled powerful conversational AI and might help address the first challenge mentioned above. However, these models require large amounts of training data (i.e., interview data), which are hard to acquire. INTRODUCTION: Given the three challenges mentioned above, we explore new ways to build effective interview chatbots. As the first step, we are investigating the feasibility and effectiveness of using existing AI technologies to build effective interview chatbots with active listening skills. INTRODUCTION: Our investigation aims at answering two research questions: INTRODUCTION: RQ1: Whether and how can we employ publicly available AI technologies to build effective interview chatbots with active listening skills?", "relatedWork": ": Our work is related to research in four areas listed below. Conversational Agents for Information Elicitation: There is a rich line of work on developing conversational agents for information elicitation. These agents roughly fall into three categories: survey bots, AI-powered chatbots, and embodied AI interviewers. Conversational Agents for Information Elicitation: Survey bots text users a set of choice-based questions with little natural language interaction . They normally do not ask open-ended questions nor handle user digressions that may arise during a natural language conversation. More recently, AI-powered chatbots have been used to ask users open-ended questions via texting . Additionally, there is a rich body of work on embodied AI interviewers (e.g., ). These AI agents have a human-like form and use both verbal and non-verbal expressions to communicate with users. Conversational Agents for Information Elicitation: Among the three types of conversational agents, our work is most related to AI-powered chatbots. Similar to these efforts, our goal is to deliver engaging interview experience and elicit quality information. However, existing works are limited at handling complex and highly diverse user input . In contrast, our work reported here is intended to improve the conversation capabilities of these chatbots. Task-Oriented vs. Social Conversational Agents: Although conversational agents have been used in a wide variety of applications, they fall into two broad categories . One type helps users accomplish specific tasks, such as meeting scheduling and information search . The other is to socialize with users without a task (e.g., ). Because of the constrained domains and the need for gathering accurate parameters (e.g., meeting time), rule-based approaches are often used to create task-oriented agents . Although a recent data-driven approach to task-oriented agents shows early promises , it is not ready for real use. In contrast, data-driven approaches are mostly used to support open-domain, social dialogues . Task-Oriented vs. Social Conversational Agents: Recently, researchers have developed conversation agents that support both task-oriented and social dialogues in one system . Similar to this line of work, our interview chatbots must support both task-oriented and social conversations during an interview. Unlike this line work, which helps users achieve a task like making a restaurant reservation, interview chatbots must complete its own information elicitation task. Such differences impose new challenges on building interview chatbots, such as handling uncooperative users or irrelevant user responses to open-ended questions. Recent Advances in Conversational Agents: There are numerous computational approaches to building conversational agents, including both symbolic and datadriven approaches . To cope with highly diverse user input, data-driven approaches have been used extensively to handle open-domain conversations. A number of data-driven approaches are used to train retrieval models that find the most probable machine response from a repository of predefined responses for a given user input (e.g., .) Additionally, generative approaches have been explored to synthesize machine responses that do not exist before (e.g., ). However, the quality of generated responses may be erroneous or incoherent, not yet ready for practical applications. Recent Advances in Conversational Agents: Neither retrieval-based nor generative models alone are practical for building interview chatbots, since they require large amounts of training data-often millions or billions of conversation exchanges . It is difficult to obtain interview data let alone large amounts due to the private or sensitive nature of many interviews. Moreover, a lack of interpretability and control of data-driven results would put an interview chatbot at risk especially in high-stakes contexts, such as customer interviews . Recent Advances in Conversational Agents: To improve interpretability, recently, researchers have explored hybrid approaches. For example, Hu et al. propose to incorporate rules as the weights of neural networks to improve interpretability and performance . Sundararajan et al. propose an approach to identify which input features contribute to the prediction of a deep network . Their approach can extract rules from the networks to help interpret the prediction results and debug the networks. These hybrid approaches have inspired us in developing our prototype, which is perhaps the first of exploring a hybrid framework for building interview chatbots. Chatbot Platforms: During the past few years, a number of chatbot platforms have been developed to facilitate the creation of chatbots. There are two types of platforms. The first type, including Chatfuel and Manychat , supports do-it-yourself chatbot making. However, they have little AI/NLP capabilities and cannot support the creation of interview chatbots with active listening skills. The second type, including Google Dialogflow and IBM Watson Assistant , offers AI/NLP capabilities but has a steep learning curve for non-AI experts to use the tools (e.g., they must understand NLP elements such as intents and entities). Moreover, most platforms in this category are designed for making task-oriented chatbots (e.g., restaurant reservation). They must be extended to support interview chatbots to perform tasks and be social at the same time. Chatbot Platforms: Given the limitations of existing chatbot platforms, we decided to extend Juji , a chatbot platform that supports both tasks-oriented and social dialogues and allows easy extensions, to build effective interview chatbots. Our decision to extend Juji is detailed in Section 4.3.", "rq": ["RQ1: Whether and how can we employ publicly available AI technologies to build effective interview chatbots with active listening skill?", "RQ2: How effective can such interview chatbots be at handling complex and diverse user input and affecting user experience and interview quality?"], "id": "dev_4"}
{"intro": ": Cultural heritage is a valuable legacy of humankind. Information and computing technologies not only facilitated the reproduction, representation, and archiving of cultural heritage but also enabled new interaction techniques for easier access, browsing, and experience with cultural contents. In digital cultural heritage research, while there has been much work on tangible cultural heritage such as paintings, sculptures, architectures, and so forth, intangible cultural heritage has been comparatively less studied. Intangible cultural heritage, as defined by the UNESCO World Heritage Center, refers to 18:2 \u2022 X. Wang et al. \"intangible attributes of a group or society that are inherited from past generations, maintained in the present, and bestowed for the benefit of future generations.\" 1 For example, oral traditions, customs, ways of life, traditional craftsmanship, performing arts, theater, social practices, and so forth are all intangible heritages representing cultural identities and diversity of mankind, and they should be preserved and passed on to the current and future generations. INTRODUCTION: Modern computing technology provides us new opportunities for promoting better awareness, understanding, and appreciation of the intangible cultural heritage. Currently, however, virtual heritage applications, especially those for the philosophy domain, are often built for professionals for archiving purposes and used by only a small number of people interested in the subject (e.g., ). Particularly, social values and beliefs, or, in other words, the philosophy of a particular ethnic group, are abstract in nature, which makes it hard to be quantified and conveyed digitally and interactively. The general public usually has the image of philosophers being \"out of touch,\" and many people would be intimidated by the idea of studying such a difficult subject . The aim of our research is to disseminate intangible cultural contents (in particular, traditional Chinese culture represented by the Confucian philosophy) to the general public by leveraging the interactivity and appeal afforded by interactive media and artificial intelligence technology. INTRODUCTION: The Confucian school of philosophy, founded by Confucius, a Chinese philosopher and educator in ancient China, is the cornerstone of the Chinese culture. It was believed that Confucius did not author a single book, and his philosophy was spread by him talking to his disciples, the rulers, and other folks of his time. Indeed, conversation is an old way to communicate ideas and beliefs, but a very natural and effective one. Therefore, to build an interactive application for communicating cultural values, one promising avenue is to model the conversation from classical texts and re-create the experience of having conversations with the philosophers. In fact, use of natural language interaction for knowledge acquisition has been studied extensively in intelligent tutoring systems , but there have been considerably fewer applications in cultural heritage research until very recently (e.g., ). The reasons for the lack of work in this area might be (1) natural language is complex and ambiguous, which makes natural language understanding and generation very difficult; and (2) creating a conversational agent often requires precise modeling and/or heavy scripting, which is very time-consuming. INTRODUCTION: This article reports our work on a conversational agent that emulates the Chinese philosopher Confucius, allowing users to easily explore traditional Chinese culture through natural language communication with the virtual Confucius. The main contributions of this article are twofold. First, we developed a systematic method for the domain experts to easily create a knowledge base from unstructured philosophy texts. Second, we present an algorithm to utilize the knowledge base to answer open questions using a variety of natural language processing technologies, requiring minimal input from domain experts. The creation of virtual agents requires collaborative work between computer scientists and the experts in the domain in which the agent operates. Previously, the knowledge base creation was a laborious task that often required the content preparers to manually author large amounts of question-and-answer pairs and encode them using scripting language. The method we developed greatly reduced the workload of the domain experts by distributing part of it to the computer. The domain experts can work with technology they are already familiar with without learning complex computer skills such as scripting. INTRODUCTION: The rest of the article is organized as follows. In Section 2, we provide a review of conversational systems and their cultural-related applications. In Section 3, we present how we built the Confucius knowledge base and the rationale for our methodology. We then describe the technical details for", "relatedWork": ": Conversational agents have a long history dating back to the 1960s, when the chatbot Eliza was invented by Joseph Weizenbaum . It is a computer program simulating a Rogerian psychotherapist, which can analyze the input sentence by predefined keywords and decomposition rules and then generate the answer by corresponding reassembly rules. Some clever tricks, such as including substrings of the user's input in the program's output and answering questions with questions, are used to create the illusion of understanding. The agent is able to continue the conversation despite an extremely limited knowledge base. Later developments of chatbots follow similar ideas, and new languages have been developed to facilitate script authoring and encoding. One famous example is ALICE , written in AIML (Artificial Intelligence Markup Language). Chatbots created by scripts can be very human-like when the user's input falls into the scripts, but it requires enormous effort to manually author each response rule. For example, the current ALICE implementation includes more than 40,000 rules and still falls short sometimes. Furthermore, such chatbots are mainly used for entertainment purposes or handling highly specific tasks. RELATED WORK: Another related area of work is intelligent tutoring systems (ITSs), where a computer system guides students through the process of learning, usually using natural language. The dialogue between a human student and a computer tutor is highly structured and needs to be designed by careful consideration of the knowledge to be taught as well as related learning theories . RELATED WORK: Natural language interaction has also been explored in designing virtual museum guides. For example, Ada and Grace are two life-sized, photo-realistic characters installed at the Museum of Science in Boston to engage young people in science . The system works by having a statistical text classification algorithm to map the utterance text to the pool of preconstructed character responses. A library of scripted question-and-answer pairs are authored by the domain expert. A software called NPCEditor is created to facilitate content authoring and rephrasing. Other virtual human museum guides include Pixie , which provides information about the agent and the exhibition in the Swedish Telecom museum. Another example is Max , equipped with the ability to converse about the museum, the exhibition, or other topics of interest. Similar works are virtual information kiosks, such as MACK (Media Lab Autonomous Conversational Kiosk) , which gives directions to visitors of the MIT Media Lab based on a repository of user queries and system responses, and August , a talking head representing the Swedish author August Stringberg, which was displayed at the Stockholm Cultural Center to answer questions by predefined answers. RELATED WORK: To the best of our knowledge, there has been little research work on natural language applications specifically designed for intangible cultural heritage. One very recent work is from Mori et al. , who used a conversational agent in a serious game for communicating the cultural contents-the artwork of a particular artist. They developed a dialogue management system to facilitate cultural heritage experts to easily author the conversation without the need for learning scripting language. A similar work is the NICE HCA system, which is a conversational agent representing the fairytale author H.C. Andersen . It is an edutainment system for children and teenagers to learn about the life and work of Andersen, by enabling natural communication through spontaneous speech and 2D gesture. Conversational skill is modeled by templates and topic-centered mini-dialogues. Another older work is the Synthetic Interview technology , which has real actors to play as the famous people, for example, Benjamin Franklin, and records short video clips of the character answering questions. The system then matches its input questions from the user to a preconstructed list of possible questions a guest may ask and plays the corresponding video clip, simulating a real interview experience. RELATED WORK: Besides the scripting or rule-based methods adopted by the aforementioned systems, there is also a trend to directly generate natural language statements using knowledge organization systems and mainly ontologies . Some of them have been successfully applied in museum guides (e.g., ). While this method can be useful for natural language applications dealing with information that is highly structured and thus can be represented in a formal representation such as the OWL, 2 it is not suitable for our application. The writings of traditional Chinese philosophy are not formal philosophical works, but rather records of philosophers' sayings. Chinese philosophy is abstract and unstructured, and it is not possible to organize it into hierarchies, classes, and relations. This leads to our research question: How can we convert these unstructured texts into the knowledge base of a conversational agent in an easy and efficient way? RELATED WORK: The target questions addressed by the systems mentioned previously are mostly biographical and factual questions, such as life and work of a person or exhibition information in a museum. Such information can be easily anticipated and authored as templates or question-and-answer pairs. In contrast, in the case of a conversational agent for communicating cultural values, while there is factual information in the knowledge base, there is also a large part that is more subjective and free to interpretations. Thus, many of the questions to the agent would be asking for opinions, or advice, rather than simple factual information . There is no way for us to predict the common questions that would be asked by users. Therefore, we need to explore a new approach other than the current standard practice of manual authoring in building the conversational agents, as it requires too much human effort and is almost unfeasible in our case.", "rq": ["RQ1 - Is it possible to train a neural network based unscripted virtual character that is able to sustain brief smalltalk interactions and create the appearance that the virtual character understands its interlocutor?", "RQ2 - How anthropomorphic is the appearance of the virtual characters to human judges, and what is the influence of the model that generates the responses?"], "id": "dev_5"}
{"intro": ": A recent report by Grand View Research 1 predicts that the global chatbot market will reach $1.25 billion by 2025. Chatbots have utilized the power of artificial intelligence (AI) for various application domains ranging from customer services and healthcare to product recommendations . In the domain of recommender systems, there are several cases where product recommendations are delivered to customers through chatbots with an aim to improve customer engagement. At the same time, a number of research work 22] have emphasized the importance of user control in recommender system. INTRODUCTION: Various studies with critiquing-based recommender systems (CBRS) have shown the positive effects of increased interactivity on the effectiveness of recommendations. Critiquing is an iterative approach of evaluating the outputs of a recommender system, which allows the system to continuously update the settings and provide users with recommendations that better represent desired outcomes . Figure 1 shows a typical interaction flow of CBRS. CBRS simulate an artificial salesperson who first recommends products based on a user's initial preferences and then shows a new set of products based on the user's feedback (aka critiques), e.g., \"something cheaper\", \"larger screen\", etc. Thus, CBRS are well suited to accommodate user control during the recommendation process. INTRODUCTION: Most existing research studies have compared different critiquing techniques with graphical user interfaces (GUIs). However, little work has studied different critiquing techniques with conversational user interfaces (CUIs) that mimic a conversation with a real human either by text or voice. Moreover, it has been shown that personal characteristics such as musical sophistication affect user perception of controls for music recommenders ; however, the effects of personal characteristics have not been validated on critiquing techniques yet. To fill these research gaps, this paper compares two typical critiquing techniques with CUIs and investigates how personal characteristics influences user perception and interaction of recommended items (see the dashed lines in figure 1 ). To achieve these objectives, we implemented a hybrid critiquing-based music recommender MusicBot, which uses a chatbot to enable users to interact with recommendations through both text and voice. The system offers two major critiquing techniques, user-initiated critiquing (UC) and systemsuggested critiquing (SC) to refine the recommendation. UC enables users to construct critiques according to their own needs, while SC generates a set of critiquing candidates for users to choose a desired critique. We then conducted an evaluation with 45 participants using MusicBot in a within-subject design. We raise three research questions for evaluating critiquing-based Music recommenders particularly with a conversational user interface (CUI). INTRODUCTION: RQ1: Which critiquing setting, UC versus HC, is better suited for controlling music recommendations? INTRODUCTION: RQ2: Which personal characteristics (e.g. musical sophistication, desire for control, chatbot experience, and tech savviness) might influence user's perception and interaction of recommendations? INTRODUCTION: RQ3: Are critiquing techniques perceived as useful in low-involvement product domains as in high-involvement product domains? INTRODUCTION: Our main contributions are four-fold: INTRODUCTION: (1) We demonstrate a multi-modal (text and voice) conversational music recommender that incorporates both a userinitiated critiquing technique (UC) and a system-suggested critiquing technique (SC). We then employ a mixed qualitative and quantitative research method to compare UC with a hybrid critiquing technique (HC) in terms of subjective user experience (UX) with recommendations. Overall, recommendations generated by UC and HC were perceived at the same level, while users tend to need more effort to find a song using HC. (2) We find that two personal characteristics, desire for control and musical sophistication, positively influence several key UX metrics of recommendations such as interest matching, intent to give feedback, and perceived controllability. INTRODUCTION: (3) Our study also verified the usefulness of critiquing techniques in a low-involvement domain of music recommendations. (4) Based on the findings in this study, we proposed specific design suggestions for critiquing-based recommender system with conversational interaction. This paper is organized as follows: We first introduce related work, followed by the design and implementation of MusicBot. INTRODUCTION: We then present the quantitative and qualitative results of a user study. Finally, we conclude with a discussion of study findings and limitations.", "relatedWork": ": In the following sub-sections, we review previous work that are closely related to our research. Critiquing-based Recommendations: Based on the way of constructing critiques, critiquing-based recommender systems (CBRS) can be categorized into two types of critiquing: system-suggested, and user-initiated. In addition, the distinction is made between unit critiques and compound critiques. Unit critiques refer to critiques that only constrain a single feature at a time, while compound critiques are capable of making a critique over multiple features simultaneously to improve performance of conversational recommender systems . Due to the pros and cons of each type of critiquing technique , by taking the advantages of both UC and SC, a hybrid system increases decision accuracy and needs less cognitive effort . However, most studies of comparing different critiquing techniques are conducted only with graphical user interfaces (GUIs). To enable critiques with conversational interaction, we evaluate a hybrid critiquing system in a multi-modal chatbot for music recommendations. Critiquing-based Recommendations: Figure 2 : A user interface of a hybrid critiquing system that combines UC and SC . Critiquing-based Recommendations: User-Initiated Critiquing (UC). UC is a flexible critiquing approach that allows users to determine which features and how the features are critiqued (see Figure 2 ). Thus, users are able to make either unit critiques or compound critiques. This technique is particularly useful for tradeoff navigation between compromising values on less important attributes and obtaining more optimal values for important attributes. The most representative systems of UC are Example Critiquing and Flat Finder . UC empowers users to have a higher level of user control, which does not lead to higher perceived cognitive load. However, some previous user studies of UC also found users may suffer from the difficulty of getting started with UC without prior knowledge. Critiquing-based Recommendations: System-Suggested Critiquing (SC). Instead of asking users to construct critiques, SC generates a set of critique candidates for users to pick (see figure 2 ). Generating critiques is based on the system's knowledge about the current user's preference and the availability of remaining products. The earlier systems of SC, FindMe and ATA , presented pre-designed unit critiques to users with less adaptation to the changes of user preference and interaction. Later on, Reilly et al. proposed Dynamic Critiquing based on association rules such as Apriori algorithm to find frequent sets of value differences between the recommended product and the remaining alternatives. Furthermore, Incremental Critiquing greatly reduces interaction cycles by avoiding to show the user rejected critiques in history. To take into account users' interest in the suggested critiques, Zhang and Pu proposed to generate MAUT (Multi-Attribute Utility Theory) based compound critiques. The approach significantly increases recommendation quality by ranking the critique candidates based on the overall satisfaction degree with user preferences. A more advanced SC is the Preference-based Organization technique that is able to generate more diversified compound critiques and achieve higher critique prediction accuracy and recommendation accuracy. Overall, SC is able to produce more dynamic critiques based on the current user's preferences. It is specially useful for users who have difficulties to initiate critiques or build critiques by themselves. However, domain experts may call for more control over recommender systems, so SC may restrict the way they intend to make critiques. Critiquing-based Recommendations: Hybrid Critiquing (HC). Similar to the idea of hybrid recommender systems , HC intends to take advantage of each type of critiquing techniques. Chen and Pu compared two hybrid critiquing systems that combine a UC system (Example Critiquing) with a SC system (Dynamic Critiquing or Preference-based Organization) in a graphical user interface. Users showed positive attitudes toward HC that comprises both UC and SC. In addition, HC can also overcome the issues of adopting a single type of critiquing technique and lead to high decision accuracy and low objective effort in making a choice. Critiquing-based Recommendations: All research findings discussed above were tested only with graphical user interfaces. In contrast, this study tries to compare different critiquing techniques with a conversational user interface. Conversational Recommender Systems: Conversational interaction is well suited for critiquing the recommendation through natural language. Several works have demonstrated systems that elicit user preference and present recommendations in a conversational dialog. ExpertClerk is a conversational agent that acts as a human salesclerk to ask user questions for getting user shopping preference and proposes the matched products with explanations. Adaptive place advisor provides personalized recommendations for traveling places. The system refines user queries by considering both long-term interests over many conversations and short-term interests in the current conversation. The two systems are typing-based conversational recommender systems. Conversational Recommender Systems: As voice recognition techniques continue to improve, speech interaction is becoming more capable of allowing users to express more complex content. ReComment presents a speech-based user interface for making unit critiques (critiquing over a single feature at a time), and it improves the perceived ease of use as well as the overall quality of recommendations. A recent study found that users tend to express longer and more conversational content with speech-based user interfaces than with typing-based user interfaces. However, speech user interfaces might negatively influence the efficiency of consuming recommendations and user exploration . So far, most speech-based UIs for recommender systems are still featured with search-oriented commands rather than more sophisticated commands to control recommendations. Conversational Recommender Systems: To the best of our knowledge, the existing critiquing systems with speech interaction only incorporate user-initiated critiquing. Little work has integrated system-suggested critiques into the dialog-based conversational recommender system. In addition, the effect of users' personal characteristics on their interaction behavior and subjective perception of critiquing-based systems has not been investigated yet. Personal Characteristics: Although previous research has shown how personal characteristics influence the way users control music recommendations through an interactive visualization, we do not know whether personal characteristics also affect user perception and interaction of critiquing based recommendations. In the following paragraphs we explain the four personal characteristics we have considered in this paper as well as the rationale for selecting them. Personal Characteristics: Desire for Control (DFC). Greenberger et al. first used a questionnaire to measure DFC in various work-related tasks of their new jobs. Users with higher DFC tend to perform better on the task and do better on upcoming tasks than subjects with low DFC . We use a widely used DFC scale proposed by Burger et al. to measure the degree of control individuals perceive towards outcomes. DFC is an important personal characteristic (PC) to measure for this study, since the two different critiquing techniques in our system empower users to have different levels of user control. Personal Characteristics: Musical Sophistication (MS). MS has been found as a key PC that influences the way users interact with music recommender systems . The Goldsmiths Musical Sophistication Index (Gold-MSI) is an effective test for measuring domain knowledge of participants. Several studies investigating the effect of personal characteristics on music recommender systems have employed the Gold-MSI to measure the participant's musical sophistication. Personal Characteristics: Tech Savviness (TS). TS often reflects a participant's confidence in trying out new technology. Several studies have investigated how TS may influence the way participants interact with recommender systems. Therefore, we think TS may also influence the way participants critique recommendations in a conversational agent. Personal Characteristics: Chatbot Experience (CE). Due to the impact of assimilation bias, participants with previous chatbot experience are prone to overestimate or underestimate the sophistication of using a chatbot . Previously, when conversational agents were not popular, researchers often measured participants' previous experience with computers as an influencing factor for conversational agents . A recent study measures the effect of previous experience with voice user interfaces on a voice-based conversational agent. As chatbots are becoming pervasive in everyday life, we measure CE of participants in our study.", "rq": ["RQ1: Which critiquing setting, UC versus HC, is better suited for controlling music recommendations?", "RQ2: Which personal characteristics (e.g. musical sophistication, desire for control, chatbot experience, and tech savviness) might influence user\u2019s perception and interaction of recommendations?", "RQ3: are critiquing techniques perceived as useful in low-involvement product domains as in high-involvement product domains?"], "id": "dev_6"}
{"intro": ": Healthy eating implies complex decision making processes , including being aware of healthy options and choosing among them . One solution to overcome this issue and help people to make healthier choices is to develop health-aware food recommender systems . While significant effort has been put recently into optimizing the food selection algorithms , many other factors can also influence users' overall experience when interacting with a recommender system . Indeed, the way the recommendation is presented , the system's response time , or even the length of the system's utterances can have an influence on users' perception of the system. INTRODUCTION: One trend to improve users' experience is to make the interaction more natural by designing the recommendation process as a conversation . Besides helping users to achieve task-oriented goals, conversations can also fulfill interpersonal functions, such as building rapport . Rapport can be described as a dynamic process that can be achieved when people \"click\" with each other or feel the interaction is due to \"chemistry\" . Human-human studies have found that rapport between two people can influence task performance in situations as diverse as peer-tutoring and negotiation . Based on these findings, it becomes important to endow recommender systems with social conversational infrastructure that would allow them to build rapport with their users to improve task effectiveness. INTRODUCTION: In this paper, we present a conversational system able to recommend recipes matching users' needs while building rapport with them. More specifically, our work focuses on investigating how the conversational skills of a recipe recommender system and the interaction modes it offers to its users would influence users' perception and their intention to cook. First, we describe the design of our system and its architecture before we explain how the recommendation process works. Then, we evaluate our system through an experiment in which we study the impact of our system's conversational skills and interaction mode on its persuasiveness. Our main contributions are (1) a rapport-building conversational approach to deliver recipe recommendations adapted to users' needs and habits and (2) a subjective evaluation investigating the influence of a recommender system's conversational skills and interaction mode on users' perception of the system, users' perception of the interaction and users' intention to cook the recommended recipes.", "relatedWork": ": Food Recommender Systems. A common approach for food recommender systems is to recommend a recipe based on its ingredients. In , for example, the authors developed a system that relies on recipes that people like to infer their preferred ingredients. The system then recommends new recipes containing the previously inferred ingredients. In , the authors developed a system that collects users' preferences by asking them to rate and tag the recipes they usually cook at home. The system then relies on user's preferences to rank recipes and deliver recommendations with the highest scores. This Matrix Factorization algorithm outperformed the content-based approach proposed by . Other approaches only rely on dietary information to recommend recipes that would match users' needs. YumMe, the recommender system developed in , automatically extracts dietary information from pictures of recipes to form a user profile. The system then relies on this user profile to deliver subsequent recommendations. In , authors analyzed people's eating behavior and clustered people in two categories: those interested in getting healthy recipes, and those who did not care about that. They found that two of the main recipe rating predictors for the first group were the fat and calorific content of the recipe, and decided to incorporate these features in their recommendation process. RELATED WORK: All these works focus on improving recommendation algorithms. They do not investigate how the modality of the interaction between the system and its users can improve users' experience which, according to , should not be neglected.", "rq": [" rq1: how does the way users interact with a conversational recommender system influence their perception of and their intention to cook recommended recipes?", " rq2: how do a conversational recommender system's conversational strategies influence users' perception of and their intention to cook recommended recipes?"], "id": "dev_7"}
{"intro": ": Conversation is an essential design component of a chatbot. As a conversational user interface (CUI), in a chatbot the user and the agent interact with a series of chat bubbles in a conversational manner. When designing conversations for chatbots, designers often employ an iterative design process: designing a conversation flow, testing with users, reviewing user data, and improving the design. Many designers use existing chatbot prototyping tools such as Landbot 1 , Botmock 2 , and Chatfuel 3 . Designers rely on visual aids like flow diagrams offered by the tools to create a conversation scenario and generate a working prototype. Normally, an interactive prototype is exported as a web link, which gets distributed to potential users for their testing and feedback. After the testing, designers analyze the collected data manually and revise their conversation design. INTRODUCTION: Although iterative conversation design is possible with existing prototyping tools, we observed several challenges around the design process in our formative interview with conversation designers. When designers try to verify their design, it is difficult to recruit participants quickly whenever they want to in order to get feedback on the design. Even though the tools mentioned above support testing chatbots, for testers, there is no way to provide feedback on specific components (e.g., whether the sequence of the conversation is natural, whether a specific utterance is awkward, whether a branch is needed, whether additional topics should be included) due to limited ways to express detailed suggestions. This results in user feedback that is often abstract and not actionable, which in turn presents challenges to designers in making informed design decisions. There have been several methods around collecting granular feedback on design via crowdsourcing in domains such as UI and poster design . However, those approaches mainly support visual design tasks, which might not directly apply to conversational user interfaces. The design of CUI involves 'conversation' that mainly uses free-form responses whereas in GUI, the user interaction is gathered through button clicks, menu selections, etc. As follows, CUI designers cannot easily predict and limit the range of user interactions. Here, we try to collect granular feedback on the unique and specific domain of 'chatbot conversation design', and explore design considerations for getting granular feedback on conversational user interfaces. INTRODUCTION: In this paper, we explore the idea of engaging an online crowd in the design process to support conversation design. First, we increase the availability of test participants by making it possible for designers to recruit crowd workers on demand within a chatbot design tool. Second, we guide the crowd to provide concrete and clear feedback on specific components during a testing session. Finally, we provide multiple types of interactive visualizations to help designers effectively interpret the collected data and make design revisions. INTRODUCTION: To investigate the feasibility of the three directions we suggest, we introduce ProtoChat, a crowdpowered system built to support the iterative process of conversation design. Designers can create a conversation flow with branching to support conditional flows. After crowd-testing, designers can review and inspect crowd data with interactive visualizations, such as an overview of conversation flows and an utterance-level review of crowd conversations. As a tester, a crowd worker can perform three kinds of tasks within the crowd-testing interface-conversing with the chatbot to follow the conversation flow, adding an appropriate utterance on the chatbot's side, and adding a branch in the conversation. INTRODUCTION: To evaluate how crowd workers and designers use ProtoChat in a conversation design scenario, we conducted a three-day study with eight designers. They went through a design iteration each day and performed four main design tasks (Design, Crowd-test, Review, and Interview) with ProtoChat. INTRODUCTION: Participants chose different domains for their conversation design, which varied from ice cream order to YouTube channel recommendation to talking behind significant other's back. Each day, we recruited a new batch of crowd workers whose number was determined by the designer. We found that ProtoChat could provide an agile design experience to create, test, analyze, and improve the conversation. Designers were able to improve their design with evidence collected from the crowd, by modifying the overall structure of the conversation or fixing a specific part of the conversation. Designers also diversified the options provided to the user, modified the response format (e.g., natural input, button choice) of topics, or gathered insights of UI design implications for the final version of chatbot. Beyond the conversation itself, some designers set a persona (e.g., proactive, good listener) for the chatbot by editing chatbot utterances with crowd input as hints. The conversation design increased in complexity over time through iterations by 33% after the first iteration, and 11% after the second iteration. INTRODUCTION: The contributions of this work include: INTRODUCTION: \u2022 Insights from the formative interview that identify challenges in conversation design and the required support for a more agile iterative design process; \u2022 ProtoChat, an interactive chatbot design tool that supports designers to make informed decisions by collecting design feedback from crowd workers and visualizing the crowdsourced data; \u2022 Empirical findings from a user study that shows how our system could help designers to utilize the crowd feedback and provide the crowd workers the methods to suggest concrete feedback.", "relatedWork": "BACKGROUND AND RELATED WORK: We review previous work related to conversation design and crowdsourcing applications. We first investigate what kind of methods are currently being used for conversation design of chatbots. BACKGROUND AND RELATED WORK: Then, as we propose a system empowered by the crowd, we discuss how crowdsourcing is utilized in chatbot design and how the crowd is invited to work on usability testing in general. Conversation design methods for chatbot: Prior work has been done to investigate possible ways to design conversations that can be used for chatbots. Existing approaches collect conversation data from humans by Wizard-of-Oz prototyping and workshops . The conversation of Dara , a chatbot that helped Indian artists to discover international opportunities, was designed with Wizard-of-Oz at the beginning. Ko et al. also utilized the Wizard-of-Oz method to notice the user scenarios of searching business cards, which could result in the multi-dimensional search flow in CardBot. Moreover, Wizard-of-Oz was used to personalize the reflection questions for the agent Robota . Conversation design methods for chatbot: Reflection Companion leverages a 12-user workshop to generate the system's mini-dialogue flows. Wizard-of-Oz and workshop methods enable designers to collect quality conversation data in a controlled setting. However, these methods make designers overwhelmed due to time and participant management. Plus, the human-human conversation needs to be verified again to apply in human-agent conversation. Conversation design methods for chatbot: Other approaches formulate the conversation by analyzing existing data sources such as Twitter conversation data , mail threads of DBpedia , existing chatbot logs and extracted data from apps . Hu et al. and Xu et al. collected and utilized twitter conversation into a training dataset to generate tone-aware and emotional responses. Athreya et al. used the official mailing lists of DBpedia, which includes discussion and conversational threads of mailing lists so that they could be used for creating conversational scenarios. XiaoIce , an empathetic social chatbot used two data sources to generate conversation; one is conversational data from the internet, the other is the previous chat log between XiaoIce herself and her users. Kite automatically created chatbot templates from existing mobile apps which share the logic of user tasks. Although, human conversation data from the internet such as twitter and mailing lists can be easily crawled at scale, it is hard to be directly applied to design human-agent conversation. Conversation design methods for chatbot: Different from the previous work, we aim to quickly and easily collect large amounts of granular feedback on the conversation design by crowdsourcing. The crowd can contribute to improving the conversation design by (1) inserting new chatbot-side utterances that match the current context, and (2) suggesting new branches in a conversation that have not been supported by the designer. Furthermore, the crowd responses could be provided as the data for designing a concrete and high-coverage conversation, which can cover as many as possible scenarios that crowd workers want to proceed around that domain. These interaction data from the crowd gives more concrete insights into how to elaborate the conversation design even before implementing a chatbot, which can foster fast iterations on the conversation design. Crowdsourcing in chatbot design: Crowdsourcing has been applied in diverse design domains such as collecting design examples , real-time prototyping , and getting design critique or feedback . Likewise, crowdsourcing has been utilized in the chatbot domain. There has been work to utilize the crowd to collect and produce dialogue data for the social chat system. Fantom uses a graph-based dialog model for context-maintenance to find suitable responses. The graph gradually evolves with actual chat interactions and system responses by the crowd. InstructableCrowd is an agent that can crowdsource \"trigger-action\" rules for IF-THEN constructs to automate the management of sensors and tasks. Crowdsourcing in chatbot design: Other kinds of work leveraged the crowd to respond to the end-user in real-time while maintaining contexts. Chorus is operated with a group of crowd workers who propose responses, vote each other for the best answer, and share collected chat history to maintain the consistency of the conversation. Chorus demonstrated how the crowd could come up with not only a diverse set of responses but also a diverse set of variations of descriptions on a given topic, where they expected crowdsourcing as a potential approach to explore diverse conversations in the chat domain. CI-Bot is a hybrid system that works with crowd experts so that if the user asks an unknown question, it collects the answers from crowd experts and responds. If the answer is satisfying, the answer is appended to the response list of CI-Bot. Crowdsourcing in chatbot design: Otherwise, crowdsourcing has been used as a method of evaluating the chatbot. ChatEval conducted automatic and human evaluation of chatbots with DBDC (Dialogue Breakdown Detection) tasks and A/B testing with the crowd. Yu et al. suggested a method for evolving existing dialog scenarios by requiring users to evaluate an appropriation, correcting, for answers given by chatbot as they proceed with the conversation. This study showed that the crowd's evaluation is effective in evolving the scenario. They have indeed suggested a method of systematic, accessible chatbot evaluation, but the method is only possible with an already existing chatbot with the complete design of conversation. Choi et al. explored how crowd workers can evaluate a conversation design, and identified designers' needs and expectations in involving the crowd in the design process. We extend this work by introducing a fully functional system that supports designers to quickly test with the crowd workers, collect evidence, and analyze the data and by validating through a user study. Crowdsourcing in chatbot design: ProtoChat: Supporting the Conversation Design Process with Crowd Feedback 225:5 Crowd-testing user interfaces: Crowdsourcing platforms allow for the quick collection of user feedback at a low cost. Kittur et al. found that, for prototype or user testing, collecting data points from a diverse crowd population was more useful than collection data from a limited pool of experts. Also, Komarov et al. showed that crowdsourcing is a productive way for conducting performance evaluations of user interfaces, there have been studies about leveraging the crowd into testing. Leicht et al. organized the crowd-testing types in four categories: (1) functional and verification, (2) nonfunctional, (3) validation, and (4) usability, all of which are commonly applied to software testing. Muccini shared that the method has benefits such as availability, high coverage, costeffectiveness, real scenarios, and speediness but also has the challenges of lacking standards, reward mechanisms, and coverages. Crowd-testing user interfaces: To explore and overcome the lacking features of crowd-testing in software engineering, Guaiani et al. explored the way of integrating the crowd-testing into laboratory settings which could potentially complement each other. They collected surveys from crowd testers and found that the difficulties they faced are time pressure or insufficient amount of information, which can be mitigated through better test management. When applying the crowd-testing methods to evaluate web-based interfaces, Nebeling et al. proposed the system CrowdDesign and the toolkit CrowdStudy to invite crowd workers into the process of designing and usability testing the web-based interfaces. For easy integration of crowd-testing, ZIPT was proposed as a way of comparative usability testing at scale without any integration of apps. As a result, designers can easily collect, aggregate and visualize the user's interaction path between third-party apps. Chen et al. introduced two techniques to increase the coverage of crowd-testers. The interactive event-flow graphs collected interactions of every tester and visualized in a single graph and GUIlevel guidance could prevent the inactive exploration of paths. As Wang et al. pointed out, crowd-testing often generates a high degree of test case duplication, because crowd workers tend to follow the same paths while testing in parallel. Crowd-testing user interfaces: We aim to apply crowd-testing to support an iterative design of chatbot conversations. As the domain of our interest differs from previous literature such as software engineering or web interface design , design considerations for building crowd-testing interfaces, which aim to evaluate the conversation design, need to be discussed. Our system creates a chatbot prototype that embeds the conversation design. The chatbot not only presents the utterances but also asks for feedback and suggestions to improve the design during the conversation session. Crowdsourcing granular feedback and suggestions can give designers more concrete insights into future iterations on the conversation design.", "rq": [" (1) can the crowd produce high-quality work with protochat?", "(2) how does the designer utilize the crowd outcome in their design process with protochat?"], "id": "dev_8"}
{"intro": ": A great deal of learning involves factual knowledge (e.g., numerous topics in medicine, language, and law). Further, such information is often learned outside of a formal classroom setting. Developing more effective automated methods for accelerating or improving factual learning therefore has the potential to benefit a multitude of students on a broad scale. INTRODUCTION: Traditional electronic tools for practicing factual knowledge tend to be flashcard based . Flashcard apps are simple and can be easily designed to provide personalized adaptive practice based on well-studied models of human memory . However, to optimize for speed, flashcards typically involve passive learning (i.e., the user is asked to visualize the answer and then check for correctness). This may not fully take advantage of the testing effect (retrieval through testing with proper feedback) . As shown in many previous studies, retrieval practices like testing lead to higher retention than purely studying via even multiple passive means of self-evaluation . Feedback received from test results further improves retention . INTRODUCTION: Moreover, flashcards are not typically designed to be engaging, making their effectiveness heavily dependent on people's desire to learn. Research confirms engagement can mediate learning effectiveness , especially for technologybased learning . A more engaging way to learn factual knowledge could therefore lead to better learning outcomes. INTRODUCTION: One possible path towards boosted engagement is using Natural Language Processing (NLP) powered chatbots, which are becoming increasingly sophisticated . For example, such systems enable students to speak or type out their answers during a two-way dialogue and receive targeted feedback from NLP techniques interpreting the spoken or written words. This new interaction for learning factual knowledge may be much more motivating and engaging, and may also be more effective at providing adaptive feedback and promoting deeper learning . INTRODUCTION: Given this potential for conversational approaches to enhance learning, we designed and built QuizBot, a dialoguebased adaptive learning system for students to learn and memorize factual knowledge in science, safety, and advanced English vocabulary. These three subjects were chosen because they cover diverse topics in medicine, language, and rules. They can represent important subclasses of factual knowledge that are usually learned outside the classroom setting. INTRODUCTION: On the technical side, QuizBot leverages the supervised Smooth Inverse Frequency (SIF) algorithm for automatic answer grading and the DASH model for adaptive question sequencing. On the design side, we created Frosty, an encouraging tutoring agent that provides targeted feedback to learners based on their inputs (see Figure 2 ). The design of QuizBot was inspired by previous studies to leverage the persona effect, the strong positive impact of animated agents on learning experience . INTRODUCTION: To determine the impact of QuizBot on learning, we evaluated it against a carefully designed flashcard app, the typical medium for learning factual knowledge, through two controlled within-subject studies. We aimed to closely match the flashcard app to QuizBot in order to target assessment at the impacts of the conversational components. Specifically, the flashcard app used the same DASH algorithm for adaptive question selection, and a single pool of questions and answers was subdivided for the flashcard app and QuizBot. INTRODUCTION: In the first within-subject study with 40 students, when the number of practice items was held constant for both flashcards and QuizBot, students scored substantially better on recall (fill-in-the-blank) and recognition (multiple-choice) with QuizBot than for items trained using flashcards (66.3% vs. 45.2% for recall and 87.2% vs. 65.8% for recognition). However, the time taken was longer with QuizBot than flashcards. In the second within-subject study with 36 students, we allowed learners to voluntarily allocate their time between the two apps. We found students spent 2.6x more time on QuizBot, and that students performed equivalently on recognizing items but significantly better with QuizBot at recall (with an effect size of .45). These results suggest that QuizBot is more engaging to use and more effective at recall and equally effective at recognition in typical user-driven scenarios. In normal use, QuizBot may be less efficient per unit time, but still yields improved learning on recall due to users voluntarily choosing to use it substantially more. INTRODUCTION: This work has three chief contributions. First, QuizBot is the first chat-based learning system for factual knowledge memorization outside of classroom settings. Moreover, we show its effectiveness and engagement through rigorous comparison studies with a traditional learning tool for knowledge memorization, and our results demonstrate benefits of using chatbots to learn factual knowledge, especially for casual learning. Lastly, our results also reveal inefficiencies of chat-based learning systems, and we offer design suggestions for building improved future educational chatbot systems.", "relatedWork": ": Our work was built upon previous studies on natural language tutoring systems, semantic similarity algorithms, and memory models.", "rq": ["(1) how engaging is quizbot to learners in comparison to flashcards?", "(2) how effective is quizbot with helping learners in recognition and recall, both per number of practice items and per time spent, compared with flashcards?"], "id": "dev_9"}
{"intro": ": Many people with mental health issues face significant challenges getting the help they need. Mental health service falls short in accessibility and affordability due to a wide gap between needs and provision. While 1 out of 10 people have a mental health problem, only 1% of the global health workforce provides mental healthcare . Psychological counseling or psychiatry services could be a luxury expense for people under financial stress . Beyond structural barriers, fear of being stigmatized also prevents people from seeking psychological help . To expand the access to mental health services and to counteract the problems of stigma, there has been a burgeoning growth in internet-based and mobile applications for mental health interventions. However, these digital interventions are characterized by relatively poor adoption and adherence , which may be due to the lack of the quality of human interaction that a therapist-patient relationship offers . INTRODUCTION: More recently, text-based conversational agents, or chatbots, have gained traction as the new generation of digital mental health support system. Some prominent examples emerging from industry and academia include Woebot (woebot.io) and Wysa (wysa.io). Powered by artificial intelligence (AI) and natural language processing techniques, these conversational agents offer a more natural way of interaction. As people engage in dialogues, chatbots process all text and emoji that a user might enter, and offer responsive, guided conversations and advice to help users cope with challenges to mental health . This human-agent interaction sets to invoke anthropomorphism, making people feel like being in a conversation with humans via a messenger app. The typical mental health services these chatbots provide include targeted therapy exercises, including reframing one's thoughts, mindful breathing, and motivational interviewing. INTRODUCTION: Literature specifically related to psychotherapeutic chatbots is rather sparse. Recent researchers began to evaluate the efficacy of using conversational agents for mental health outcomes (e.g., ). However, this line of research has not thoroughly interrogated how specific design features might influence client engagement and perceptions of the system. On the other hand, HCI scholarship suggests that conversational agents need to adopt the characteristics of human-human interaction in order to be more engaging . So far, researchers have examined linguistic and conversation styles, such as empathic and emotional expression , self-disclosure , humor , and how these characteristics might influence human-agent relationship . Studies also explore visual characteristics (e.g., . But to the best of our knowledge, there is no empirical study on how the perceived racial (dis)similarity might influence people's engagement with and perceptions of agents for psychotherapeutic purposes. INTRODUCTION: Nonetheless, racial identity is an integral part of anthropomorphized agents. It also shapes human's social experiences. In traditional in-person settings, matching clients with therapists of the same race has been found to result in stronger bonding and more positive attitudes . Does perceived racial similarity still matter in agent-based psychotherapy context? If so, understanding the complex relationship between identity and influence will inform a better, human-centric experience. INTRODUCTION: To evaluate the racial mirroring effects, we developed a conversational system with racially heterogeneous personas. Distinct profile pictures were used as strong visual cues to indicate agents' racial identities, including White/Caucasian, Black/African American, Latinx, and Asian. Due to mixed evidence of cross-gender effects on chatbot perceptions and following , we created both female and male personas for each racial group. Beside the differences in agent racial personas, the agents interact with users in the same flow of conversation structured in accordance with motivational interviewing (MI) guidelines. This framework offers a collaborative conversation for strengthening a person's own motivation and commitment to change. It is broadly applicable and often used in cognitive behavioral therapy for mental health issues, such as anxiety and depression and substance use . INTRODUCTION: Using these prototypes, we conducted an online experiment to investigate the effects of racial mirroring, defined here as the match between the user and agent race/ethnicity. Participants were randomly assigned to racial-mirroring, non-mirroring or control groups. After interacting with the agent, participants completed a survey assessing their perceptions and evaluations of the agent. We investigate the following three research questions: \u2022 RQ1. How are people's perceptions of the agent influenced by racial mirroring in a psychotherapeutic conversation? \u2022 RQ2. How is people's continued engagement with the agent influenced by racial mirroring? \u2022 RQ3. What are people's preferences for racial persona when they are given a chance to customize the conversational interface? Our analyses revealed that racial mirroring had a positive influence on people's perceived interpersonal closeness with the agent. Although the presence of same-race agents decreased people's comfort with self-disclosure, they reported a higher level of satisfaction associated with their use of chatbot for managing mental well-being. With regard to future engagement, we found participants reported a higher desire to continue interacting with the agent. Participants also predicted a closer future relationship with the same-race agents. Finally, people were significantly more likely to select same-race agent personas when they were given an opportunity to customize the conversational interface. The current study offers three major contributions. First, we identify a racially-conscious approach to increasing people's rapport and engagement with therapeutic chatbots. Second, we provide empirical evidence on how racial-mirroring could facilitate people's adherence to psychotherapeutic agents. Finally, we open up a discussion about the important issues of race and diversity in intelligent systems interface design.", "relatedWork": "", "rq": [" rq1. how are people's perceptions of the agent influenced by racial mirroring in a psychotherapeutic conversation?", "rq2. how is people's continued engagement with the agent influenced by racial mirroring?", "rq3. what are people's preferences for racial persona when they are given a chance to customize the conversational interface?"], "id": "dev_10"}
{"intro": "", "relatedWork": ": Although research showed that longer queries could produce better results for information seeking tasks, e.g. , people usually tend to use short search queries . There are many approaches to support users in finding relevant information, e.g. through facets, recommendations, implicit and explicit user feedback. However, only few works have tried to motivate users to type in more query terms and thus provide more detailed information about their initial information need. Belkin at al., for example, showed that a queryentry box with several lines led to longer queries than a line mode search bar and that query lengths were significantly longer when the query box was labelled with \"Information problem description (the more you say, the better the results are likely to be)\" than when it was labelled with \"Query terms\" . Furthermore, they found that longer queries significantly increase searchers' satisfaction . In contrast, Agapie et al. found that telling users that longer queries deliver better search results does not influence query length. However, they showed that using a coloured halo around the search bar motivates searchers to provide significantly more query terms in a complex Web search scenario. Hiemstra et al. evaluated the proposed halo effect in a website search system in a 50-day A/B test (N = 3506) but could not confirm the positive impact on query length. They conclude that this approach might be sensitive to the search task and search context. Kelly and Fu show that additional information (domain knowledge, the information need, and search motivation) help to increase the retrieval performance. Likewise, Bendersky, Croft and Bruce propose a machine learning method to extract the key facts from long queries. Their system performs better on longer natural language queries as compared to shorter, keyword-like queries. RELATED WORK: A reliable information need elicitation is getting more critical with the increasing use of voice assistant systems. Without a graphical user interface, refining the search via facets and exploring the results and recommendation lists becomes cumbersome. Research in the context of conversational search has explored asking clarifying questions or coached conversational preference elicitation . With one good question, Aliannejadi et al. improved the retrieval performance by over 150%. Focusing on conversations, however, requires processing natural language (with challenges such as vague language and ambiguity ), which is, so far, not supported by common product search engines.", "rq": ["rq 1: Do users reveal more about their information need when interacting with more conversation-like interfaces?", "rq 2: are users more inclined to use natural language when interacting with more conversation-like interfaces?"], "id": "dev_11"}
{"intro": ": Information on a patient's medical history is essential for the diagnosis and therapy decision process. In the first appointment with a physician, he or she is asking the patient many questions to get to know the medical history of the person. The accuracy of this information affects significantly the quality of the diagnostic process . One of the main causes of misdiagnoses is an incomplete medical history . Beyond, studies show that certain health problems remain unrecognized in the patient-doctor conversation. For example, 50% of psychosocial and psychiatric problems are not recorded in the anamnesis . 54% of problems and 45% of concerns are neither reported by the patient nor revealed by the attending physician . A digital medical history entered by a patient himself can improve this situation and helps avoiding unnecessary duplication of data, as long as the medical history data is available for the different actors in the health care process. Self-anamnesis is a procedure in which the patient answers questions about the personal medical history without direct interaction with a doctor or medical assistant. A digital representation of the anamnesis enables a structured and thus more complete recording of the information . In the course of the implementation of the eHealth Act in Switzerland and in other countries, a digital medical history can be stored in future in the electronic patient record, which avoids unnecessary duplication of data. INTRODUCTION: Several means exist already for fetching the medical history of a patient in a digital manner by means of electronic questionnaires or tools like AnaBoard (http://anaboard.de ). It has been proven that such electronic gathering helps to improve the correctness and completeness of the data compared to the traditional paperbased anamnesis survey . The data quality of a digital acquisition is therefore potentially better than the traditional data collection process. In existing approaches, however, it turned out to be a problem to motivate patients to answer an often comprehensive catalogue of medical history questions . In this paper, we want to address this challenge by exploiting a dialog-oriented user interface for a mobile application that offers the possibility to interact with the user already during the medical history survey. More specifically, the main research question for this work is: Can a self-anamnesis be realized as a mobile application with conversational user interface? As specific use case, we have chosen the field of music therapy. Music therapy uses specifically selected music in the therapeutic process to promote, maintain and restore mental, physical and mental health. A complete, systematic history of experiences with music and of the music taste of a patient to be treated plays an important role in therapeutic process . The therapy plan and in particular music selection is made based on the music biography that is collected in the first meetings with the patient. The aim of application is not to replace the therapist or physician and the first consultation, but to provide a better and higher quality information base for the first consultation with the therapist or physician as well as for the following decision making process.", "relatedWork": ": A conversational user interface or chatbot system is a computer program that interacts with users using natural language. Different terms are used for a chatbot such as machine conversation system, virtual agent, dialogue system, conversational user interface and chatterbot. The purpose of a chatbot system is to simulate a human conversation. Chatbots are usually text-driven, with images and unified widgets, which make it easy to start interacting with a bot. There are two types of chatbots: Unintelligent chatbots interact using a predefined conversation flow. Intelligent chatbots use machine learning to automatically generate responses on the fly. Already in 1966, Weizenbaum presented ELIZA , a program that allows a natural language conversation with a computer. ELIZA stored its knowledge directly into the application code. Later, the design language Artificial Intelligence Markup Language (AIML) was used to manage the knowledge-based data (\"chatbot brain\") . Chatbots have been reported in the literature for health related applications for example for student education, patient advice, information access, to achieve health behaviour change or disease self-management. Lokman and Zain introduced a chatbot that serves as a virtual dietitian for diabetic patients. The chatbot asks questions and gives at the end a diet advice suitable for the current diabetic situation. The conversation is going along a path that is remembered by the system to consider all answers in the decision-making. VPbot, an SQL-based chatbot for medical applications is a chatbot that takes advantage of relational database model design to store, manage and use the SQL language to perform the matching process within the chatbot conversation. eMMA, the electronic medication assistant, is a mobile application developed to support a patient in the medication management. The app is equipped with a chatbot for providing information on interactions between food and medications and to collect compliance data . Several chatbots have been implemented in the health domain and are available in the app stores even though no scientific publication is available. The existing systems provide a triage, search functionalities or support to a certain extent disease management or conversation with doctors (e.g. Ada, https://ada.com/). Babylon Health (https://www.babylonhealth.com/) provides a triage function via a conversational user interface that is intended to supplement or replace the telemedicine hotline in the English health care system. So far, there is no application with conversational user interface available that is fully integrated in the treatment process such as a self-anamnesis chatbot. Our self-anamnesis concept aims at improving the data collection at the beginning of the diagnosis and treatment process. In contrast to existing systems, our concept foresees the integration of the collected data into the treatment process.", "rq": ["can a self-anamnesis be realized as a mobile application with conversational user interface?"], "id": "dev_12"}
{"intro": ": In many domains, including human-computer interaction (HCI) research , conducting surveys is a key method to collect data. With the widespread use of the internet, self-administered 15:2 Z. Xiao et al. online surveys have replaced old-fashioned paper-and-pencil surveys and have become one of the most widely used methods to collect information from a target audience . Compared to paper-and-pencil surveys, online surveys offer several distinct advantages. First, an online survey is available 24x7 for a target audience to access and complete at their own pace. Second, it can reach a wide audience online regardless of their geographic locations. Third, online survey tools automatically tally survey results, which minimizes the effort and errors in processing the results. INTRODUCTION: Due to the extensive use of online surveys, survey fatigue is now a challenge faced by anyone who wishes to collect data. Research indicates two typical types of survey fatigue . One is survey response fatigue. Since people are inundated with survey requests, they are unwilling to take any surveys . The other is survey-taking fatigue. Evidence shows that as a survey grows in length, participants spend less time on each question and the completion rate also drops significantly . For example, one of the biggest survey platforms, SurveyMonkey, shows that on average, participants spend 5 minutes to complete a 10-question survey but 10 minutes to finish a 30-question survey. 1 The problem is exacerbated with open-ended questions because of the extra time and effort required for formulating and typing responses to such questions . Open-ended questions are an important method to collect valuable data and are widely used in self-administered online surveys . INTRODUCTION: In particular, open-ended questions allow respondents to phrase their answers freely when the options of responses cannot be pre-defined or the pre-defined responses may introduce biases . Moreover, open-ended questions help collect deeper insights, such as the background and rationales behind the answers . However, open-ended questions often induce more cognitive burdens and survey-taking fatigue, and respondents are more likely to skip such questions or provide low-quality or even irrelevant answers . Consequently, surveytaking fatigue adversely affects the quality and reliability of the data collected especially when open-ended questions are involved . INTRODUCTION: To combat survey taking fatigue especially to motivate and guide survey participants to provide quality answers to open-ended questions, several approaches have been proposed. One set of proposals is to inject interactive features into an online static survey, such as providing response feedback and probing responses , to improve response quality and encourage participant engagement. However, no existing survey platforms support such interactive features nor do they automatically motivate and guide survey participants to provide quality answers to open-ended questions during a survey. INTRODUCTION: A lack of support of such interaction features on existing platforms may be due to two main reasons. First, it is difficult to automatically interpret participants' natural language responses to an open-ended question due to the diversity and complexity of such responses . For example, when asked \"What do you think of the product,\" participants' responses could be: \"N/A,\" \"I don't know,\" or \"Although I've heard of the product, I've never used it so I don't know what to say.\" Interpreting such highly diverse or complex free-text input requires sophisticated natural language processing algorithms, which is a non-trivial task . Second, even if a system can interpret participants' free-text responses to open-ended questions, it is difficult to manage potentially complex interactions based on participant responses. Using the above example, a participant may be unwilling to answer the open-ended question and may even provide a gibberish response such as \"afasf asfasf afyiasfaf asf\" . In another example, a participant is willing to answer the question, but provides a very terse answer such as \"not bad\" as opposed to detailed, rich information. Yet in another example, instead of answering the question, a participant asks a clarification question \"Which aspects of the product do you want me to comment on.\" Handling all these situations Using an AI-Powered Chatbot to Conduct Conversational Surveys 15:3 or their compositions requires that a system not only understands a participant's input but also automatically handles diverse interaction situations, which is very challenging to implement . INTRODUCTION: On the other hand, the advent of chatbots with their increasingly more powerful conversational capabilities can offer an alternative approach to static online surveys. Specifically, an artificial intelligence (AI)-powered chatbot can conduct a conversational survey. As shown in Figure 1 , in a conversational survey, a chatbot asks open-ended questions, probes answers, and handles social dialogues. INTRODUCTION: Intuitively, a chatbot-powered conversational survey retains the advantages of online surveys and offers several additional benefits especially facilitating gathering participant responses to open-ended questions. First, a chatbot can frame survey questions in more personalized, conversational messages, which might help improve participant engagement and response quality . Second, the perceived anthropomorphic characteristics of a chatbot can potentially deliver human-like social interactions that encourage survey participants to reveal personal insights . Third, it is natural for a chatbot to interactively encourage information exchange in the course of a survey, such as providing response feedback and probing responses, which in turn helps reduce survey-taking fatigue and improve response quality. Moreover, it is the inherent functions of chatbots that interpret diverse user natural language input and handle complex conversations. As a result, chatbots can potentially serve as a moderator and proactively manage a survey process, such as dealing with \"uncooperative\" participants, clarifying the meaning of a question per a participant's request, and guiding a participant to provide richer and more authentic responses . INTRODUCTION: Despite their benefits, chatbots bear several risks for their use in conducting surveys. First, a turn-by-turn chat requires participants to take extra time and effort to complete a survey. It is unclear whether people would be willing to take the time to chat and complete a survey, let alone providing quality responses. The risk is even higher for surveys with paid participants, who would not be rewarded for taking a longer survey. Second, current chatbots are far from perfect and their limited conversation capabilities may lead to user disappointment and frustration . It is unknown whether the limited capabilities would deter participants from offering quality responses or completing a survey. Moreover, it is difficult for a chatbot to accurately interpret and properly respond to humans' diverse free-text input to open-ended questions . Once participants realize that a chatbot cannot fully understand or assess their responses, it is unknown whether they would do mischief by intentionally feeding the chatbot with bogus responses, which would adversely affect the overall response quality. Finally, the use of a personified conversational system may lead to user behaviors that affect survey quality. For example, studies show that people have positivity bias when giving opinions to an agent , producing potentially biased survey results. INTRODUCTION: To our knowledge, there have not been any in-depth studies examining the effectiveness and limitations of AI-powered chatbot surveys in contrast to typical online surveys. We, therefore, ask two research questions: INTRODUCTION: \u2022 RQ1: How would user response quality differ, especially the quality of user free-text responses to open-ended questions in an AI-powered chatbot-driven survey vs. a traditional online survey? \u2022 RQ2: How would participant engagement differ in an AI-powered chatbot-driven survey vs. a traditional online survey? INTRODUCTION: To answer the above research questions, we designed and conducted a field study that compared the use of an AI-powered chatbot vs. a typical online survey with the focus on eliciting user answers to open-ended questions. As mentioned above, there are potential benefits and risks of using chatbots to conduct surveys, especially when involving open-ended questions. However, none of the benefits or risks have been examined. In this first study, we thus decided to focus on examining the holistic effect of a chatbot instead of investigating the effect of separate chatbot features. INTRODUCTION: Additionally, to ensure that our study is based on real-world survey practices and offers practical value, we collaborated with a global-leading market research firm that specializes in discovering customer insights for the game and entertainment industry. Per the firm's request, our field study was to learn how gamers think and feel about two newly released game trailers. The study involved about 600 gamers, half of whom took a chatbot survey and the other half filled out a typical online survey. Through detailed analyses of over 5,000 collected responses, we addressed our two research questions. We also discussed the design implications for creating effective chatbots to conduct engaging surveys and beyond. INTRODUCTION: To the best of our knowledge, our work is the first that systematically compared the holistic effect of an AI-powered conversational survey with that of a typical online survey on response quality and participant engagement. As a result, our work reported here provides three unique contributions. INTRODUCTION: (", "relatedWork": ": Broadly, our work is related to research in six areas as detailed below. Conversational AI and Chatbots: Our work is related to a rich body of studies on the applications of conversational AI or chatbots. For example, past studies have examined chatbots as a personal assistant , intelligent tutor , customer service agent , job interviewer , and worker's companion . Conversational AI and Chatbots: The HCI community has long been interested in the interaction benefits offered by conversational interfaces. The general consensus is that conversational interfaces offer several advantages over traditional Windows, Icons, Menus, and Pointers (WIMP) interfaces . First, conversational interfaces offer a natural and familiar way for users to express themselves, which in turn improves the usability of a system. Second, such interfaces are flexible and can accommodate diverse user requests without requiring users to follow a fixed path . Third, such interfaces are often personified and their anthropomorphic features could help attract user attention and gain user trust . Conversational AI and Chatbots: Inspired by the potential advantages of conversational interfaces over WIMP-based user interfaces, our work investigates the use of conversational interfaces for conducting surveys. Differing from existing works on conversational interfaces, we are exploring a new application of conversational AI for conducting surveys, which has its own set of unique challenges. For example, survey participants would not be as motivated or cooperative as job candidates who interact with a conversational AI agent . Neither would survey participants be as tolerant or patient as a student or an employee who interacts with an AI companion . Conversational AI and Chatbots: Furthermore, conversational interfaces are far from perfect due to technical difficulties in processing user natural language expressions and managing diverse and complex conversation situations . It is thus unknown how the shortcomings of conversational interfaces (e.g., failure to understand a user's input during a survey) might influence survey participants and survey results. Therefore, we hope to investigate whether and how conversational interfaces might bring in practical values to traditional survey practices, which use WIMP-based interfaces to elicit information. As the first step, we compare the holistic effect of a chatbot survey with that of a traditional online survey on survey participants and survey results in a real-world setting. Conversational AI for Information Elicitation: Our work is directly relevant to the use of conversational AI for information elicitation. Researchers have built various AI agents to elicit information from a user through a one-on-one, text-based conversation, such as eliciting information from a job candidate and gathering data from a study participant . Information elicitation may serve various purposes. A common task is to elicit \"parameters\" for information retrieval or recommendation . This kind of system often supports task-oriented conversations, such as helping a customer book a flight reservation, finding a desired restaurant, and scheduling an event . The main goal of such systems is for an agent to gather required information (e.g., travel dates) to perform a task . Conversational AI for Information Elicitation: More recently, conversational AI has been explored as a means to elicit information for additional purposes beyond fulfilling a specific task. For example, there have been agents that elicit information for recommending products, movies, and jobs , group decision support , psychotherapy , and voting . An emerging area is using conversational AI to conduct in-depth interviews or longitudinal studies in the real world . For example, Li et al. deployed agents to interview a pool of real job candidates and compared the effect of two agent personalities on the candidates' behavior. Tallyn et al. developed a chatbot to gather ethnographic data from participants in real-time. They showed that a simple chatbot with little language understanding capabilities was effective in capturing data from the participants. In a more recent study, Xiao et al. used a chatbot to interview university students and gather their thoughts and feelings about teaming. Conversational AI for Information Elicitation: Different from our investigation of using a chatbot as a general surveying tool, prior studies tended to focus on examining the feasibility and effectiveness of a chatbot for a specific information elicitation task. For example, Xiao et al. studied the use of a chatbot for eliciting student preferences and opinions about team building and investigated whether and how the elicited information predicted team performance . Li et al. built a chatbot to elicit information from job candidates and examined the candidates' trusting behavior with the chatbot . However, unlike our work, none of the existing studies compared the effectiveness of a chatbot in information elicitation with that of a traditional approach. In particular, we want to quantitatively measure the holistic effect of chatbots on user engagement and response quality compared to that of a traditional online survey. Conversational AI for Information Elicitation: Although a typical online survey can elicit information through various question prompts, including open-ended questions, such a survey is not interactive or adaptive in nature. For example, in such a process, a survey participant cannot ask a clarification question, neither can the system probe a user response. On the other hand, chatbots can naturally employ a diverse set of conversation prompts to elicit information interactively, such as question prompts , follow-up probes , and topic-specific discussions . In addition, conversation prompts can be context sensitive. For example, Williams et al. employed both emotion-centric prompts \"how do you feel\" and task-centric prompts \"what did you do\" to elicit rich responses from users about work experience to improve workplace productivity . Conversational AI for Information Elicitation: However, existing work has not examined how a chatbot's often imperfect conversation capabilities would affect information elicitation involving open-ended questions, including user response quality and satisfaction. A recent study showed that most chatbots can hardly understand user input and manage seemingly simple tasks such as scheduling a meeting . This is because users' natural language expressions are highly diverse and challenging to interpret. Moreover, a seemingly simple conversation is often still complex and nonlinear (i.e., going back and forth with a user on a topic), which requires a chatbot to continously track and proactively manage a conversation context . Our study is thus set out to explore both the advantages and shortcomings of a chatbot in conducting surveys with open-ended questions and to compare its holistic effect against that of a traditional online survey to answer our two research questions. Conversational AI and Information Disclosure: In the context of information elicitation, studies show that conversational AI may enhance user engagement and encourage self-disclosure. Prior work has demonstrated that the exhibited social behaviors of agents are effective in improving user engagements in various social settings by a set of metrics, such as interaction duration, breadth, and depth of self-disclosure (e.g., discussing personal subjects), and a positive attitude toward the agent and interaction outcome . Conversational AI and Information Disclosure: On the other hand, user's positive attitude toward AI agents has raised concerns on user privacy protection and encouraged studies on investigating the effect of chatbots on user trust and privacy in the context of information elicitation. For example, a recent study showed that users trusted a customer service chatbot more if they were well-informed in the conversation where the information was stored . Sannon et al. found that users were less likely to share personal sensitive information (e.g., financial or health stress) with a personified chatbot . However, none of the existing studies compared survey participants' behaviors (e.g., self-disclosure and answer quality) influenced by a chatbot vs. in a traditional online survey. We thus set out to gauge how conversational AI affects user engagement and the quality of survey results, hoping to discover new survey methods that may improve traditional online survey practices. Evaluating Conversational Interfaces: With the advent of conversational interfaces, evaluating the effectiveness of such interfaces is a continuously evolving research topic. Traditionally, the evaluation criteria have been divided into objective metrics on the system performance (e.g., user input interpretation accuracy and user task completion rate) and subjective metrics based on user feedback (e.g., user satisfaction) . Objective metrics are directly computed from logs of the interaction and can be based on task or domain coverage, error rate, number of interaction issues, accuracy or other metrics compared to \"ground truth\" . Subjective metrics are often based on user opinions around certain aspects, such as satisfaction and intelligibility, (e.g., ). There are also comprehensive methodologies that consider both subjective user satisfaction and objective performance metrics including task success, dialog efficiency (e.g., duration and total turns) and dialog quality (e.g., latency) . Evaluating Conversational Interfaces: In addition to examining user satisfaction and usability of conversational AI agents, HCI researchers have investigated how agent behavior impacts users' social perceptions, such as trust , rapport , anthropomorphism, and likability . Such user subjective feedback is often measured by questionnaires, i.e., Likert-scale ratings on self-reported statements. Additionally, automatic methods have been developed to predict user satisfaction based on users' behavioral signals, such as dialogue acts, words, and user actions . Evaluating Conversational Interfaces: Compared to the existing work, our study focuses on evaluating the outcomes of a conversational interface with a target goal-collecting high-quality survey data and keeping the survey taker engaged. We, therefore, have proposed several content-based metrics to measure response quality and participant engagement. Conversational Interfaces vs. Graphical User Interfaces: Our work is also related to evaluating the effect of a conversational interface vs. that of a graphical user interface (GUI). A recent study by YouGov compared the use of a traditional GUI form with a Facebook Messenger Bot for conducting a survey. 2 They found that the chatbot significantly improved response rate. More recently, researchers compared the response quality between a chatbot survey and a form-based survey in more depth . They also found that the chatbot surveys produced more differentiated responses and the participants were less likely to satisfice. However, all the existing studies used only choice-based questions and have not examined how chatbot-driven surveys would impact user responses to open-ended questions, which has been one of the major challenges in typical online surveys . Conversational Interfaces vs. Graphical User Interfaces: In other task domains, researchers have explored how a conversational interface in lieu of a traditional GUI interface impact user behavior. One such area is conversational search . For example, Trippas et al. show that verbal communications led to more complex user queries such as having multiple requests in one utterance, while the interactivity encouraged user collaborative behavior, such as actively requesting more specific information. Conversational Interfaces vs. Graphical User Interfaces: Similar to this line of work, we compare the effect of using a conversational interface vs. a traditional GUI for conducting surveys. However, we focus on quantifying their effect on the quality of collected free-text survey responses and user engagement, which has never been addressed before. Improving Survey Quality: Our work is related to survey research on improving survey quality. Researchers have put tremendous effort into improving sample validity and response quality. Heerwegh and Loosveldt find that personalization can significantly increase web survey response rate by 4.4% while not necessarily leading to social desirability response bias. Behr et al. have tested three probing variants and found that such probings lead to a higher number of meaningful answers in web surveys. In a field experiment with over 4,000 participants, De Leeuw et al. have shown that a polite probe can successfully reduce item non-response (\"don't know\") without sacrificing the reliability of the final answers. Conrad et al. also show that interactive feedback can improve the quality of responses in web surveys. Additionally, Oudejans and Christian propose to use explanations and probings to improve the quality of user responses to open-ended questions. Improving Survey Quality: On the one hand, our work is built on top of existing findings. For example, we learned that interactive features, such as response feedback and probings, help improve participation and response quality. On the other hand, our study is a natural extension of existing efforts. In particular, we explore the use of chatbots to offer various interactive features in a survey, hoping that such features would improve participant engagement and response quality.", "rq": [" rq1: how would user response quality differ, especially the quality of user free-text responses to open-ended questions in an ai-powered chatbot-driven survey vs. a traditional online survey?", "rq2: how would participant engagement differ in an ai-powered chatbot-driven survey vs. a traditional online survey?\njuji: what do you think of the trailer you just watched?"], "id": "dev_13"}
{"intro": ": Conversational machines are being increasingly employed in physical spaces for both private and public usage. Examples include hotel lobbies and store showrooms , car dashboards , and home devices . With such machines, or chatbots, human interactions may happen in the presence of an audience, be it friends, family (e.g., while on a road trip), or simply strangers and bystanders (e.g., in a hotel lobby). INTRODUCTION: Previous studies have found that humans tend to change their normal conversation behavior when in front of others. In such contexts, people sometimes resort to using long and complicated words, uttering jokes, quoting from obscure authors, and, in general, pretending to be smarter, wittier, or funnier than in private conversations . Also, when in the presence of others, some people may enhance the emission of dominant responses , according to the status of those in the audience . However, some people react in the opposite way, becoming more shy than normal, failing to complete sentences, getting nervous, or even stuttering. INTRODUCTION: Understanding such changes in behavior are important because it may be necessary to design the machine conversation systems to handle those situations where people change their usual behavior to accommodate the presence of an audience. We were motivated to study this kind of behavior change by some initial observations we made of visitors experiencing an art exhibit where they interacted with a group of chatbots either alone or in front of acquaintances and/or strangers. For example, we observed some people trying to amuse their friends by trying to \"break\" the machine with impossible questions; asking questions related to local politics and sports to provoke the other visitors; and uttering deep and complicated questions to show off to others their knowledge about the subject of the artwork. In any of those cases, we found that the art exhibit could have been designed to better handle the presence of an audience. For example, the system could have a higher threshold of guessing the right answer to complex questions when an audience is present. It could, for instance, assume that a visitor asking a complex question in front of an audience is less a situation where she is looking for knowledge and more like the system is being made fun of. While in the former case the appropriate response could be trying to find a good answer as hard as it could, whereas in the group situation it could be simply deflecting the question. INTRODUCTION: Beyond art exhibits, as conversational systems become more ubiquitous, similar situations will be common in more down-to-earth scenarios. For instance, a conversation speaker (like Amazon's Echo or Google's Home) could benefit to adjust its behavior to handle audience effects. It could be less prune to making jokes to avoid making anyone in the audience uncomfortable, or, even worse, feeling ridiculed in front of acquaintances. In other words, by recognizing the audience context, the conversational system may be designed to answer in a more appropriate form for a situation of group social interaction, adapting to and enhancing the overall experience of users and their audiences. INTRODUCTION: However, such considerations and strategies only make sense if we understand whether and how users change their behavior when conversing with machines in front of other people. Do they feel more embarrassed, powerful, or wittier by an audience when dialogging with a machine instead of a person? Are the changes different if the audience is comprised of acquaintances or strangers? To shed a light on such questions, we went further and performed two studies on the art exhibit and its visitors. This was a setting where single or multiple visitors freely conversed in a physical space with three text-based chatbots representing characters from a well-known 19th century book in Brazil. No control on how visitors interacted with the space or the chatbots was in place, with the exception that they had to do it through a single tablet. Images from the exhibit are depicted in Figure 1 . INTRODUCTION: To explore changes in conversational behavior of people due to the presence of an audience, we investigated the visitor perceptions of the three agents' social skills and the user's engagement with agents with the artwork. In the majority of the situations the interaction happened in front of other visitors, some of them known to the users, but also often in front of strangers. In our first study, we conducted 92 semi-structured interviews with visitors, after observing their behavior at the exhibit. Analyzing this data, we were able to determine that, in some specific situations, it was very likely that the audience presence was affecting the user experience of the visitors. In a second study, we analyzed the conversation logs of more than 5,000 sessions. Coupled with a silent video of the audience interaction, which we used to manually determine the occurrence and type of audience, we were able to explore changes in conversation patterns which could be related to the presence of other people around the visitor. The two studies seem to provide evidence of audience effects, and that designers should be taken into account audience effects in conversational systems in physical spaces. Moreover, our findings seem to indicate that those effects are modulated by many factors, including gender, knowledge about the content of the exhibit, and whether there were strangers in the audience. INTRODUCTION: The next sections describe in detail the related work, the experimental setup, the two studies, their findings, and our main conclusions. Finally, we discuss some design implications, indicating how our findings may guide the design of conversational systems in physical spaces.", "relatedWork": ": In this session, we describe the previous work as a background for our study, both in the scope of social interaction with chatbots and in the context of audience effects. RELATED WORK: Social Interaction with Chatbots: With the recent advances in conversational and natural language technologies, interest has increased on how humans interact with conversational systems, here referred generically as chatbots, and on how social presence and context may play a key role in understanding the dynamics of the interaction . RELATED WORK: Social presence is described as the social connection and involvement between two or more people in an interaction often developing and maintaining some sort of personal relationship . The perception of social presence is sometimes connected to the anthropomorphism of physical robots, chatbots, and avatars. In particular, anthropomorphism is a prevailing topic of Embodied Conversational Agents (ECAs), a special case of embodied agents in which the agents provide human-like capabilities of face-to-face dialogue. RELATED WORK: Studies with ECAs have provided evidence that they can induce social-emotional effects comparable to those in humanto-human interactions . Previous work found that people conversing with ECAs or interacting with robots show social reactions such as social facilitation or inhibition , a tendency to socially desirable behavior , and increased cooperation . For example, analyses of users' utterances while interacting with a museum agent showed semblance with human-to-human communication, with similarities in the amount of greetings and farewells, common phrases (such as \"How are you?\"), and human-likeness questions (e.g., \"Do you have a girlfriend?\"). RELATED WORK: In general, system which exhibit human-like traits tend to improve the quality of the user experience with them., Cafaro et al. found that smile, gaze and proxemics are important for conversational museum guide agents, implying that those agent influenced user's interpretation of agent's extraversion and affiliation and impacted on the user's decisions about further encounters. RELATED WORK: Although the degree of veracity in the dialogue often improves the quality of the interaction, it might have the opposite effect: the uncanny valley effect where people are averse to a high degree of human similarity has also been observed. Experiments, such as , have validated this hypothesis by observing the user's emotion engagement strategies towards agents of varying human likeness. RELATED WORK: In this study, we contextualize our study object, the art exhibit, as containing three embodied chatbots. Even though the chatbots did not have a physical body they have a clear physical presence provide by scenographic elements (see Figure 1 ): female and male hats hanging above chairs around a table unmistakably embodied the chatbots. RELATED WORK: Audience Effects:. Seminal work on drive-producing effects of the presence of an audience uncovered specific group interaction behaviors, which led to theories and design frameworks for spectatorship (e.g. ). Among the implications and findings of audience effects are the impact of behavior and views of bystanders on the response to an interaction, which has been known to influence engagement, either being related to attention, interest, or affective feelings . RELATED WORK: One of the early studies of audience effects concluded that proximity and presence of audience enhance the emission of dominant responses , i.e. responses governed by strong verbal habits at the expense of responses governed by weaker ones. Active audiences who looked and interacted with the subjects directly affected individual performance measured by the average number of responses in a word recognition task. In 1982, Michaels et al. performed a classical study on social facilitation showing that the performance of good pool players improved 14% in front an audience while bad pool players had a dramatic decrease of 30% . RELATED WORK: Love and Perry studied the behavior and views of bystanders in response to a proximal mobile telephone conversation held by a third party. In their experiments, subjects demonstrated noticeable changes in body posture when viewing and listening to a confederate attending a call. The influence of audience has been also studied in video gaming, where researches explored audience aspects including age , size and distance of the interactor , typologies of spectatorship , player performance and perceived game difficulty , co-located/remote and virtual/real audience , cheering , supportiveness , activeness , and social aspects . Overall, the findings report that different characteristics and behaviors of audience have positive and negative impacts, sometimes affecting the entire gameplay experience. RELATED WORK: Spectator experience design has been proposed by Reeves et al. , which produced a taxonomy that uncovers design strategies based on interface manipulations and their resulting outcomes. Audience participation in public spaces has also been studied from the point of view of interaction and engagement in many domains, such as education , sports , and arts . One common observed practice which directly affects the experience is the honey-pot effect, where interaction with a screen in public can drive social clustering and further engagement . Furthermore, Group interaction helps to explain how users understand and react to displays in public settings. RELATED WORK: Although previous works explored audience and spectatorship effects in games, sports, arts and other domains, to the best of our knowledge no research efforts have been made to study the experience of audience effects in scenarios where the main interaction is conversing with chatbots in a physical space. Finally, given that our setting is an art exhibit, we use the terms visitor and user interchangeably. In our study, a person is both a visitor of the exhibit as well as the user of the physical chatbot architecture described next.", "rq": ["rq1: what are the effects of audiences on the users' perceptions of social interaction with chatbots?", "rq2: Does the presence of audiences influence the type andcontent of user\u2019s questions directed to chatbots"], "id": "dev_14"}
{"intro": "", "relatedWork": ": The problem of reducing the complexity of performance analysis has been tackled previously. Solutions have been proposed for abstracting the process of problem stating from choosing, configuring, and running an appropriate performance analysis approach . Especially in the field of application performance management , automatic analysis of the results is becoming an important requirement for tools that aim to be market leaders. The issue here is that these approaches still require significant prior knowledge in the field, as well as experience to analyze the results. Some works have been proposed for integrating performance-awareness into development environments, e.g., to assess and display the performance (impact) on code changes using model-based and measurementbased approaches (e.g., performance tests and production monitoring) . However, these approaches do not focus on configuring the performance evaluation and do not include the use of conversational interfaces such as chatbots. Generally, also visualizations make performance analysis more accessible; various specialized approaches have been suggested , but none for visual reporting of load tests or similar scenarios. Chatbots (also called conversational interfaces or natural language interfaces) are gaining popularity in many applications and have already been applied for data analysis. Not a full-fledged conversational interface, but a popular example that answers data-related questions phrased as keywords or a sentence is Wolfram|Alpha; it often provides a mix of visualizations, tables, and lists as a reply, but actual conversations are not possible. Also, general-purpose search engines like Google answer more and more queries directly or by providing visualized data-snippets (e.g., for \"How many people live in California?\"). Srinivasan and Stasko provide a short overview of natural-language interfaces that are combined with visualizations for data analysis-systems mostly focus on specifying a visualization and trigger visualization-related interactions. A recent example that covers both aspects is FlowSense where users can both generate visualizations (e.g., \"Show a scatterplot of 'mpg' and 'horsepower'. \") and control interactions (e.g., \"Highlight the selected cars in a parallel coordinates plot. \"). Such systems are different from our approach that specifies a data-generating test scenario but does not immediately control the visualizations. RELATED WORK: Also, software engineering research has started to investigate the application of conversational interfaces in the context of the development process. The BotSE 2019 workshop (co-locacted with ICSE 2019) discussed the usage of bots (chatbots being a subtype of these) in software engineering. Chatbots have been tested or discussed, for instance, to find experts for a certain code artefact , to help avoid potentially conflicting code changes , or to support project meetings with background information on the development . Regarding the visualization of software dependencies, chatbots can help to select and filter elements ; a natural-language interface (here, also involving speech recognition) is particularly useful when software visualizations are presented in virtual reality, and hence, text input gets harder . RELATED WORK: In addition to the chat interface, our approach provides the analysis results as a detailed interactive report. It is inspired by previous work that uses natural language generation (NLG) to generate documentation of software or to report data analysis results. For instance, there are approaches that textually summarize source code , commits and releases , or characteristics of executed tests . Some approaches combine the generated texts with interactive visualizations similar to our reports, for instance, to describe runtime information of a method or to summarize different aspects of code quality . In an earlier work-in-progress publication , we already sketched a reporting framework (Vizard), which we now integrate with the chatbot interface.", "rq": ["rq1: how does performobot help participants to create and execute a load test?", " rq2: how do participants perceive performobot and interact with it?", "rq3: what educational effect does performobot have on the participants?", "rq4: how does the interaction with performobot depend on the knowledge and experience of the participants?"], "id": "dev_15"}
{"intro": ": Chatbot systems 1 have been increasingly adopted in many fields (e.g., healthcare , human resources (HR) , and customer service ), since the first chatbot system-ELIZA-emerged in 1964 to provide consulting sessions as a computer therapist . In recent years, an increasing number of chatbot systems are being developed in various research labs and companies with a premise that these systems can have more powerful capabilities and support more user scenarios . For example, Hu et al. built an experimental chatbot system that can understand the tones in a text input (e.g., sad or polite) and generate responses with an appropriate tone. INTRODUCTION: Following these system development efforts, many recent Human-Computer Interaction (HCI) and Computer-Supported Cooperative Work (CSCW) studies have examined various aspects of chatbots from the end users' perspective, such as human-in-the-loop chatbot design , user perception of chatbots , playful usage of chatbots , and human trust in chatbots . However, most of these studies have inherent limitations: 1) many chatbot systems (e.g., ) use a rule-based architecture, which makes the chatbot capable of understanding only a limited number of user inputs and responding with prescripted sentences, hindering its generalization; and 2) most chatbots are deployed and tested only in single-user scenarios, but how these systems interacting with and impacting a group of users (or a community) is understudied. INTRODUCTION: The first limitation of current chatbots -only returning a pre-defined list of responses to a user -is partially caused by the use of traditional heuristic rule-based algorithms or information retrieval techniques . Even with some advanced chatbot-development toolkit's help (e.g., Microsoft Cognitive Service and IBM Watson ), a chatbot can only use neural-network based approaches (NN) to understand the text, but its responding function is still limited to a rulebased selection process. In this work, we propose a NN-based chatbot architecture based on which a chatbot system can accurately handle unseen questions and generate various forms of responses with the same meaning. This architecture is designed to have a high scalability and generalizability, so that other researchers and developers can take our code 2 , provide it with a cleaned and labeled training dataset, retrain it, and deploy it for different online communities. Inspired by previous literature , we also build a human-in-the-loop module so a human operator can monitor and intervene the fully automated architecture, if needed. INTRODUCTION: The second research gap is that most of today's HCI and CSCW research primarily focus on an individual user's interaction with and perception of a chatbot system , and it is unclear how a chatbot system may affect a group of users or a community. In this paper, we aim to address this research gap by building and deploying a social-support chatbot system, CASS (ChAtbot for Social Support), and evaluating its impact on the individuals who need social-support as well as on the other members in the community. Motivated by existing literature that online communities often suffer low engagement from the members due to that many posts can not get a timely response, our chatbot's primary function is designed to engage in conversations with those un-replied social-support-needing posts. CASS automates the entire end-to-end process: retrieving INTRODUCTION: \u2022 An empirical understanding of the challenges and user needs in an online pregnancy healthcare community, and how these findings can be used to tailor a chatbot system design; \u2022 A scalable and generalizable chatbot development architecture, with which researchers and developers can easily build a fully automated chatbot system with NN-based models to be deployed in another online community; \u2022 Insights and recommendations for designing and deploying future chatbots systems to interact or collaborate with humans in the context of online communities.", "relatedWork": ": The literature review is divided into three subsections: we first review selected HCI work on social support scenarios in online health communities. Then, we focused on the group of literature about human and chatbot interaction. Lastly, we switch to the literature that specifically addresses challenges and issues of chatbot systems deployment in real world. Online Health Community and Emotional Social Support: Online community has been a longstanding research topic for HCI and CSCW researchers (e.g., ). Existing studies have looked at a variety of topics including community structure , community activities , members' commitment and contribution , engaging newcomers , rewarding mechanism design , and the cold start problem . Recently, a number of studies has focused on a special type of online community -the online health community for pregnant women . This is a special group of users. In addition to the significant changes on their bodies, their mental state also changes a lot over the trajectory of their pregnancy. They often have a much higher stress level than before getting pregnant, thus their mental health is at high stake . Banti et al. reported that 12.4% of pregnant women had presented some depression symptoms during the pregnancy, and 9.6% of them encountered depression in the postpartum period. Online Health Community and Emotional Social Support: It is known that pregnant women often go to online health communities to seek social support from peers . Previous literature reveals that members in such health communities actively seek social support from others, and they are also willing to volunteer their time to provide social support to other help seekers . Prior research roughly divided the social supports into two categories: informational social support and emotional social support . Informational support refers to posters seeking information or knowledge about the course of their disease, treatments, side effects, communication with physicians, and other burdens (e.g., financial problems) . Emotional support refers to posters seeking encouragement and empathy when experienced an emotional disturbance . In this project, as an illustration, our chatbot system focuses on providing non-informational social support to community members. Online Health Community and Emotional Social Support: It is often difficult to motivate community members to actively reply to others members' posts in a timely manner . Seminal research has explored various ways to solve this problem . In more traditional online communities (e.g., Wikipedia), researchers have attempted to stimulate member's intrinsic and extrinsic motivations with monetary reward or virtual badges and reputation rewards . In the online health communities, when a user posts a support seeking post, he/she is recommended to use simpler language and express the needs more explicitly . It is also suggested that posts with more detailed user profile information and a photo are more likely to get replies . Even so, there are many posts may never get a reply. For example, Wang et al. reported that at least 10% posts in an online community never received a response. Online Health Community and Emotional Social Support: When a pregnant woman posts a support seeking post and never gets a response, it may have more severe harms to the user and to the community. Because pregnancy women are already stressful, overlooking their support seeking may make things worse . Furthermore, when community members constantly fail to get the needed social support, they are less likely to contribute to the community, so the community engagement level decreases accordingly, and even worse, the members may leave the community over time . Online Health Community and Emotional Social Support: In this paper, we will illustrate how to leverage on the latest AI technology to build a chatbot system that can automatically detect non-informational support-seeking posts, and respond to it with appropriate sentences. The system architecture is scalable and generalizable so it can be easily migrated to other online communities. Human Interaction with Chatbots: Chatbot is an increasingly popular research topic in recent years. Most of today's chatbot systems are built to interact with a single user . For example, the famous ELIZA and its successors can provide individual cognitive therapy sessions to users with a purpose of relieving their stress and anxiety, as well as helping them gain self-compassion . Many commercial chatbots in customer service domain are designed to answer customers' frequently asked questions or perform a simple function (e.g., check bank account balance) . There are also human resources (HR) chatbots serving as a process guider to lead new employees to go through their onboarding process . There are also some chatbot applications in the healthcare domain which can help patients to better understand their symptoms . Human Interaction with Chatbots: Only till recently, a number of researchers have started to explore and build chatbots that can interact with a group of people . For example, Toxtli et al. built a chatbot as a group chat facilitator to assign tasks to group members. Zhang et al. developed a chatbot for an online communication application to automatically summarize group chat messages. Cranshaw et al. developed a chatbot system that can serve as an assistant to coordinate meetings for multiple people via email. All these studies expand the chatbot user scenario from supporting single user to multiple users. Notably, Seering et al. recently built a chatbot in an online gaming community on Twitch. They designed four different versions of the chatbot -\"baby\", \"toddler\", \"adolescent\", and \"tennager\" -to simulate a chatbot's grownup process in a 3-week deployment. However, the user interaction with the chatbot is quite primitive that users need to input command-line text (e.g., \"@Babybot\" or \"!feed\"), thus it is more like a digital pet (tamagotchi) than a chatbot. Human Interaction with Chatbots: Along this research line, our work builds a chatbot system that can provide emotional support to pregenant women members in an online community; also, we design a field experiment to reveal findings on how such deployment of the chatbot can impact the whole community. Different from Seering's work , where they deployed the \"digital pet\" into a Twitch community and users can have chitchat with the system, we aim to build a chatbot to meet community members' existing needs -social-support seeking. We hope our chatbot can provide functional benefits to the users through a conversational communication. Another difference is that Seering's system used an information retrieval (IR) approach, and in turn, it could only return limited responses that were pre-defined by the researchers. The rule-based approach (e.g., IR) constraints the potential of chatbot in providing social support for a community , and users may perceive the responses from the chatbot not as useful as from people . In contrast, we build an architecture that leverages on the state-of-the-art NN-based models for the development of more powerful chabot systems. Impacts of Chatbot System Deployment: While reviewing recent work on building and deploying chatbots , we found that despite many of these chatbots were designed with a good will, the deployment of certain systems may negatively impact the stakeholders or the intended users. Impacts of Chatbot System Deployment: One example is the chatbot system developed by and deployed on Twitch. It designs a novel interaction approach that users can \"raise\" the chatbot as a pet through a number of commands, such as \"!feeding\". However, the deployment of such a chatbot may distract users' attention from their original goal of using the platform, which is to watch videos and socialize with the host and the other community members. Thus, with the chabot, users may engage with the platform but not with each other. Such close bonding with a chatbot may even hurt the individual user's benefits in the long term 4 and also negatively impact the community's engagement level . Impacts of Chatbot System Deployment: The unexpected consequence of a chatbot's deployment is not uncommon when putting AI and machine learning systems to practical use. Often, today's NN-based algorithm research requires a large amount of data. Such data may come from an online community (e.g., Reddit), and they need to be tagged with ground truth labels by human annotators. However, the benefit of the original human annotators may be neglected during the training and deployment of the algorithm, as the algorithm's performance and optimization is developer's most important objective. For example, developing a functional customer service chatbots needs a significant amount of training data labeled by human customer service experts or obtained from their practices (e.g., ). But the deployment of such chatbots may cause companies to hire fewer customer service workers in the future, which may also in return reduce the sources of training data. Impacts of Chatbot System Deployment: Fortunately, some HCI researchers have noticed this challenge and they jointly work on an emerging research topic -Human-Centered AI -that aims to take an algorithm's impact on human users into the consideration of the algorithm design . For example, Woodruff et al. interview 44 participants from several marginalized populations in the United States. Participants indicate that algorithmic fairness (or lack thereof) could substantially affect their trust in a company or product, if such application is deployed . Thus, such fairness considerations should be taken into account during the algorithm design . In addition to the fairness, various other design considerations may also influence the eventual consequence of an AI system in the real world deployment, such as stakeholders's tacit knowledge and community involvement . It is also important to build an in-depth understanding of user needs or even involve them in the design process, as exemplified by a few recent work adopting participatory design research method . Impacts of Chatbot System Deployment: In addition to incorporating the various considerations into an AI system design, there are also some good practices that one can follow in the deployment of the AI system . For example, a group of researchers designed and developed ORES -an algorithmic scoring service that supports real-time scoring of wiki edits using multiple independent classifiers trained on different datasets. This paper proposes an example of deploying AI algorithms in an online community, but their algorithm is less explicit to the users, compared to the chatbot systems that we aim to develop and deploy in this paper. Impacts of Chatbot System Deployment: In this paper, we design and develop a chatbot system that can provide social support for an online health community. Besides the objective of ensuring a good functional performance, we are also interested in evaluating its potential impacts on the online community after its deployment. This work joins the recent Human-AI Collaboration research effort that aims to develop and deploy AI systems that can work together with people, instead of replacing people. It differs from the Human-AI Interaction discussion , as it goes beyond the usability and interactive design of AI systems, but focuses more on the cooperative nature of AI systems with human partners and their context (e.g., ).", "rq": ["what types of support do users (e.g., pregnant women) seek in this online community?", " How do community members respond to those support seeking posts? ", "What issues or barriers exist in communications and interactions in the community?"], "id": "dev_16"}
{"intro": ": Motivating people to change their attitudes and engage in healthy behavior is a difficult and important task. The pervasive use of computers and mobile devices paves the way for using software applications as a scalable means to help individuals follow health guidelines and attain their goals. Accomplishing this successfully requires creating interventions that are tailored to the individuals' characteristics and circumstances . A common method for tailoring is identifying a user's stage of change using the transtheoretical model of health behavior change . Stage-specific techniques can then be used to motivate people towards behavior change or behavior continuity. INTRODUCTION: Motivational interviewing (MI) is a counseling method used to enhance a person's motivation for change and has a variety of techniques that are used at different stages of change. The main goal of MI is for counselors to help their clients resolve their ambivalence about their current behavior and get them to consider behavior change. The counselor elicits this change-talk from clients using particular strategies, such as listing the pros and cons of their behavior, talking about their current level of motivation and confidence to change, and encouraging them to speak freely without being judged. INTRODUCTION: Given the effectiveness of MI , creating systems capable of conducting MI sessions automatically would be beneficial. Embodied conversational agents (ECAs) are virtual agents that simulate face-to-face interactions by having a human embodiment and exhibiting non-verbal behaviors , and thus can be a vehicle for driving digital counseling interventions for health behavior change. However, since MI relies on open elicitation from clients, designing automated conversational interventions that implement MI faithfully is challenging . Some researchers have implemented an ECA system that uses a few techniques from MI that work with constrained input, e.g., only allowing users to select what to say from a multiple-choice menu , but these are very limited in functionality. INTRODUCTION: In our current effort, we developed an ECA that promotes two health behaviors-physical activity and fruit and vegetable consumption-using MI to increase motivation and confidence to change. We address these behaviors due to their wide applicability and because most American adults struggle to meet the Center for Disease Control's general recommendations, e.g., 23% of American adults meet the recommendations for physical activity and more than half of Americans consume less than the recommended daily servings of fruits and vegetables . INTRODUCTION: The ECA makes use of fully-constrained user input to the MI counseling conversation. Rather than being a limitation, constrained interfaces provide opportunities to explore novel methods for bringing about attitude change, for example, by only allowing users to express change-talk at key moments of the session. This approach is based on the phenomenon of opinion change following forced compliance, a derivative of cognitive dissonance theory studied in the field of behavioral psychology. Researchers found that people who were forced to advocate for an opinion they did not hold (e.g., to come up with and rehearse counter-arguments) shifted their private views towards the position they advocated for, particularly when offered low extrinsic reward . In our case, we evaluate the effect of constraining users to only being able to express motivation and confidence in their ability to change or maintain the target health behaviors, compared to a less constrained condition in which they are provided with both positive and negative statements. INTRODUCTION: To explore these ideas and evaluate the interventions, we conducted a study to address the following research questions: RQ1: Can we implement an ECA that uses MI techniques to bring about attitude change towards physical activity and fruit and vegetable consumption? RQ2: Is the agent accepted by users and will they endorse its future use? RQ3: Does the interaction lead to increased confidence or motivation to change? RQ4: If we force them to endorse change-talk at key moments in the dialog, does that boost this effect?", "relatedWork": ": Digital health interventions are increasingly used to promote health behavior change and a growing number of these interventions are implemented based on theoretical foundations. In a review of digital online interventions that promote health behavior change, Webb et al. found that interventions based on theory and those that incorporated more behavior change techniques tended to have larger effect sizes than ones that did not . Among the top theories and behavior change techniques, with respect to effect size impact, were the transtheoretical model and barrier identification coupled with problem solving, an important MI technique. RELATED WORK: There have been several attempts to build automated health behavior change interventions that incorporate elements of MI, are deployed using ECAs, or both. One such example is the MAPIT program, which is a web-based intervention to increase motivation for substance abuse treatment among clients in the criminal justice system using illicit substances. The program uses the extended parallel process model, MI, and social cognitive theory in two sessions. The first session aims to motivate clients to complete probation, change their substance use, and obtain HIV care. The second session, 30 days later, focuses on goal setting, coping strategies, and social support. Participants in a pilot test were generally positive about the program's features, felt that it would help them be more successful on probation and in treatment. They appreciated that the system tailored content to them, it could display personal and population statistics, and give them insight into other people's reasons for completing probation . RELATED WORK: Another research-driven digital intervention combines MI and cognitive behavioral tools to create a self-guided supportive coaching experience for improving the mental health and wellness of its users. The system is a texting platform that leverages artificial intelligence and natural language technologies to conduct its interactions with users. In a feasibility study, 95% of users reported improvements in their mental wellbeing, though the particulars of how the system uses the counseling methods is not reported . RELATED WORK: With recent advances in speech recognition and machine learning technologies, using conversational agents for healthcare that allow natural language input has increased; however, their effectiveness remains unclear. In a review of 14 systems that allow natural language input (written or spoken), only one system was found to have a significant effect on participants' health . The same review found that approximately 70% of the conversational agents suffered from problems with language understanding and/or dialog management , threatening user safety . RELATED WORK: Several researchers have evaluated the use of constrained input ECAs and social robots to drive automated MI sessions. Schulman et al. (2011) implemented a model of MI dialog into the dialog manager of an intelligent conversational agent to promote exercise and healthy eating behavior. The model contained adjacency pairs (agent utterance and user options) for each type of MI-specific dialog act that can be enacted depending on the context at any given time in the conversation. In a formative evaluation, users rated the system highly on satisfaction . RELATED WORK: In an ECA-based intervention delivering a brief MI for reducing alcohol consumption, Lisetti et al. (2013) found that an empathic ECA was rated significantly higher than a text-only system on several measures of usability and user experience, while a nonempathic ECA showed fewer significant results . This finding is congruent with the emphasis that is placed on using empathy in MI . These findings on using MI to promote behavior change through constrained interactions with ECAs and social robots have shown that MI can increase satisfaction and usability of these systems. Our current effort focuses on measuring the effects of an interaction with ECAs on behavior change attitudes and explores the additional effects of being coerced into change-talk.", "rq": [" rq1: can we implement an eca that uses mi techniques to bring about attitude change towards physical activity and fruit and vegetable consumption?", "rq2: is the agent accepted by users and will they endorse its future use?", "rq3: Does the interaction lead to increased confidence or motivation to change?"], "id": "dev_17"}
{"intro": ": Collaboration between people and conversational artificial intelligence (AI) agents-AI systems that communicate through natural language -is now prevalent. As a result, there is increasing interest in designing these agents and studying how users interact with them . While the technical underpinnings of these systems continue to improve, we still lack fundamental understanding of the mechanisms that influence our experience of them. What mechanisms cause some conversational AI agents to succeed at their goals, while others are discarded? Why would Xiaoice amass millions of monthly users, while the same techniques powering Tay led to the agent being discontinued for eliciting anti-social troll interactions? Many AI agents have received polarized receptions despite offering very similar functionality: for example, Woebot and Replika continue to evoke positive user behavior, while Mitsuku is often subjected to dehumanization. Even with millions of similar AI systems available online , only a handful are not abandoned . The emergence of social robots and human-AI collaborations has driven home a need to understand the mechanisms that inform users' evaluations of such systems. INTRODUCTION: In HCI, experiences of a system are typically understood as being mediated by a person's mental model of that system . Conveying an effective understanding of the system's behavior can enable users to build mental models that increase their desire to cooperate with the system . However, a mental model explanation is insufficient to answer the present question: in the case of Xiaoice and Tay, both agents were based on the same underlying technology from Microsoft, but they resulted in very different reactions by users. Likewise, other agents such as Replika and Mitsuku elicit very different evaluations while existing even within the same cultural context. While theories of mental models and culture each help us understand how users experience conversational AI agents, we require additional theoretical scaffolding to understand the phenomenon. INTRODUCTION: An important and unexamined difference between these otherwise similar agents are the different metaphors that they project. Conceptual metaphors are short descriptions attached to a system that are suggestive of its functionality and intentions . For instance, Microsoft described Tay as an \"AI that's got no chill\" , while it markets Xiaoice as an \"empathetic ear\"-two very different metaphors. Metaphors are a central mechanism in the designer's toolkit. Unlike mental models, they offer more than just functional understandings of the system-they shape users' expectations from the system. And while most existing expectation-shaping mechanisms depend on the functionality of the specific AI system or task , metaphors are agnostic to specificities of a system and can be used to shape expectations for nearly any AI system. Prior theory suggests that pre-use expectations of AI systems influence both initial behaviors and long-term behaviors , even if the system itself remains unchanged while varying user expectations . INTRODUCTION: We propose that these metaphors are a powerful mechanism to shape expectations and mediate experiences of AI systems. If, for example, the metaphor primes people to expect an AI that is highly competent and capable of understanding complex commands, they will evaluate the same interaction with the system differently than if users expect their AI to be less competent and only comprehend simple commands (Figure 1 ). Similarly, if users expect a warm, welcoming experience, they will evaluate an AI agent differently than if they expect a colder, professional experienceeven if the interaction with the agent is identical in both cases. INTRODUCTION: In this paper, we test the effect of metaphors on evaluations of AI agents. We draw on the Stereotype Content Model (SCM) from psychology , which demonstrates that the two dimensions of warmth and competence are the principal axes of human social perception. Judgements along these dimensions provoke systematic cognitive, emotional, and behavioral reactions . The SCM suggests that user expectations and therefore evaluations, are mediated by judgements of warmth and competence. We crowdsource the labeling of a set of metaphors along these axes to identify a set of metaphors that appear in different quadrants of the SCM -e.g., a toddler, who is high warmth and low competence, and a shrewd executive, who is low warmth and high competence. INTRODUCTION: We perform an experiment (\ud835\udc41 = 260) that manipulates the metaphor associated with an AI agent and measures how it invokes expectations of competence and warmth and how those two dimensions affect ratings of usability, intention to adopt, and desire to cooperate. We draw on an established method from prior experiments to instantiate the agent itself as a remote Wizard-of-Oz who is blind to the condition and randomized across conditions for each participant. Participants are first exposed to the agent's metaphor, then converse with the agent to complete a travel planning task . INTRODUCTION: Our results suggest that, contrary to how designers typically describe their AI agents, low competence metaphors lead to increases in perceived usability, intention to adopt, and desire to cooperate relative to high competence metaphors. These results persist despite both the low competence and high competence agents operating at full human-level performance levels via a wizard, suggesting that no matter how competent the agent actually is, people will view it negatively if it projects a high level of competence. Participants perceive the wizards to possess lower competence than the expectations implied by high competence metaphors. These results align with Contrast Theory , which states that users' evaluations are defined by the difference between their experiences and expectations. Finally, we find that the warmth axis operates conversely to competence: users viewed the AI with higher warmth more positively, interacted with it longer, and were more willing to cooperate with it. This result aligns with Assimilation Theory : users recolor warmth experiences in light of their initial expectation. INTRODUCTION: Previous work has sought explanations for user behavior and evaluations of AI by profiling users or by making the AI more interpretable . However, these approaches fail to explain why otherwise functionally similar systems elicited vastly different user responses. Our analysis suggests that designers should carefully analyze the effects of metaphors that they associate with the AI systems they create, especially whether they are communicating expectations of high competence. In discussion, we consider implications for design by retrospectively analyzing the metaphors used to describe existing and past AI agents, such as Xiaoice, Tay, and Mitzuku, and show that our results are consistent with the adoption and user cooperation with these products. The connection between our conclusions and the outcomes experienced by Xiaoice and Tay cannot explain the whole story; however, the pattern is striking and motivates the need for exploration of mechanisms to shape expectations and elicit prosocial user behavior. INTRODUCTION: We begin by laying out related work, deriving our research question and hypotheses from prior theories. We then describe our procedure for sampling metaphors. In Study 1, we study the effects of metaphor warmth and competence. In Study 2, we sample additional metaphors along the competence axis in order to understand the effects of competence at a more fine-grained level. In Study 3, we test the negative effects of portraying a low competence metaphor by studying the effect that warmth and competence have on participants' interest in using the system in the first place. Finally, we discuss the implications of our findings for the choice of metaphors when designers deal with the dual objective of attracting more users and ensuring a positive user experience.", "relatedWork": ": Pre-use expectations play a critical role in users' initial usage of a system or design . Setting positive or negative expectations colors users' evaluation of what would otherwise be identical experiences . The effects of these pre-use expectations can have effects on evaluations even after weeks of interaction with a service . RELATED WORK: In the case of AI systems, which are often data-driven and probabilistic, there exists no simple method of setting user expectations. Providing users with performance metrics does not establish an accurate expectation for how the system behaves . In the absence of effective mental models of AI systems, users instead develop folk theories -intuitive, informal theories -as expansive guiding beliefs about the system and its goals . RELATED WORK: Prior work has shown how subjective evaluations of interface agents are strongly influenced by the face, voice, and other design aspects of the agent , beyond just the actual capabilities of the agent. These results motivate our study of how metaphors set expectations that affect how users view and interact with conversational AI systems. Inaccurate expectations can be consequential. Previously, interviews have established that expectations from conversational agents such as Siri, Google Assistant, and Alexa are out of sync with the actual capabilities and performance of the systems . So, after repeatedly hitting the agent's capability limits, users retreat to using the agents only for menial, low-level tasks . While these prior interview-based studies have demonstrated that a mismatch between user expectations and system operation are detrimental to user experiences , they haven't been able to establish causality and quantify the magnitude of this effect. This gap motivates our inquiry into understanding mechanisms that might shape these expectations and measuring the effect of expectations on user experiences and attitudes. We are guided by the following research question: RELATED WORK: Research Question: How do metaphors impact evaluations of interactions with conversational AI systems? Metaphors shape expectations: Conceptual metaphors are one of the most common and powerful means that a designer has to influence user expectations. We refer to a conceptual metaphor (or user interface metaphor, or just metaphor) as the understanding and expression of complex or abstract ideas using simple terms . Metaphors are attached to all types of AI systems, both by designers to communicate aspects of the system and by users to express their understanding of the system. For instance, Google describes its search algorithm as a \"robotic nose\" and YouTube users think of the recommendation algorithm as a \"drug dealer\" . Starting with the desktop metaphor for personal computing in the Xerox Star , conceptual metaphors proliferated through the design of user interfaces -trash cans for deleted files, notepads for freetext notes, analog shutter clicking sounds for mobile phone cameras, and more. Some AI agents utilize metaphors based in personas or human roles, for example an administrative assistant, a teenager, a friend, or a psychotherapist, and some are metaphors grounded in other contexts, for example a Jetsons-style humanoid servant robot. Such metaphors are meant to help human-AI collaboration in complex domains by aiding users' ability to understand and predict the agent's behavior . Metaphors include system descriptions outside of those rooted in human roles as well: Google describing its search algorithm as a \"robotic nose\" and Microsoft's Zo marketed as a bot that \"Will make you LOL\". The notion of \"metaphors\" extends beyond conversational AI to non-anthropomorphic systems that \"personas\" or \"roles\" may be ill-equipped to describe. Metaphors are effective: they influence a person's folk theories of an AI system even before they use it . Prior work has developed methods to extract conceptual metaphors for how people understand AI systems and aggregate them into underlying folk theories . Metaphors shape expectations: Metaphors impact expectations, sometimes implicitly by activating different norms, biases, and expectations. For example, social robots that are racialized as Black or Asian are more likely to be subject to antisocial behaviour such as aggression and objectification . Similarly, femalegendered robots can elicit higher levels of dehumanisation than male-gendered bots. Antisocial behavior leads to verbal disinhibition toward AI systems , and in some extreme cases, to physical abuse and even dismemberment . Female voice agents are viewed as friendlier but less intelligent . Users also have a higher tendency to disclose information to female gendered agents . Race and gender of pedagogical agents affect learning outcomes-agents racialized as Black or female-gendered lead to improved attention and learning . Beyond race and gender, agents portrayed as less intelligent, taking on roles such as \"motivator\" or \"mentor\", promote more self-efficacy than agents projected as \"experts\" . Young, urban users respond positively to bots that can add value to their life by suggesting recommendations, while in the role of a \"friend\" . Metaphors shape expectations: However, designers typically aim to use metaphors to affect expectations in more explicit, controlled, and pro-social ways. Most obviously, a metaphor communicates expectations of what can and cannot be done with an AI agent . Just as we expect an administrative assistant to know our calendar but not to know the recipe for the best stoat sandwiches, an AI agent that communicates a metaphor as an \"administrative assistant\" projects the same skills and boundaries. In a similar vein, describing an agent as a \"toddler\" suggests that the agent can interact in natural language and understand some, but not all, of our communication. Metaphors shape expectations: While other expectation shaping mechanisms for AI agents such as tutorials and instructions have been studied , the effect of metaphors on user expectations and evaluations have not. Our work also bridges to research suggesting that people already form metaphor-based theories of socio-technical systems and suggests design implications for how designers should choose their metaphors. Competing predictions: assimilation vs. contrast: As people view AI agents as social agents , the metaphor-and thus the nature of that agent-is likely to influence their experience. However, the literature presents two competing theories for how changes to the metaphor -and thus to expectations -will impact user evaluation of an AI system. Assimilation theory states that people adapt their perceptions to match their expectations, and thus adjust their evaluations to be positively correlated with their initial expectations. (As Dumbledore points out to Snape in Harry Potter and the Deathly Hallows, \"You see what you expect to see, Severus. \") Assimilation theory argues that users don't perceive a difference between their pre-use expectations and actual experiences. Prior work supports that, for interactive systems, users' expectations do influence evaluations . For example, users rate an interactive system higher when they are shown a positive review of that system before using it, and rate the system lower if they are shown a negative review before using it . Likewise, humor and other human-like characteristics that create high social intelligence expectations can be crucial in producing positive evaluations . Competing predictions: assimilation vs. contrast: Assimilation theory would predict that a metaphor signaling high competence will set positive expectations and subsequently lead to positive evaluation: Hypothesis 1 (H1). Positive metaphors (e.g., high competence, high warmth) will lead to higher average intention to adopt and desire to cooperate with an AI agent than if it had no metaphor or negative metaphors. Competing predictions: assimilation vs. contrast: Contrast theory , on the other hand, attributes user evaluations to the difference they perceive between expectations and actual experience. Contrast theory argues that we are attuned not to absolute experiences, but to differences between our expectations and our experiences. For example, exceeding expectations results in high satisfaction, whereas falling short of expectations results in lower satisfaction. This suggests that it is beneficial to set users' initial expectations to be low (with practitioners reasoning in the manner of George Weasley, in Harry Potter and the Order of the Phoenix, \"'E' is for 'Exceeds Expectations' and I've always thought Fred and I should've got 'E' in everything, because we exceeded expectations just by turning up for the exams.\") Users of conversational AI agents such as Alexa stumble onto humorous easter egg commands that raise their expectations of what the system can do, but then report disappointment in the contrast to discovering the system's actual limits . Likewise, ratings of interactive games are driven in part by contrasting players experiences against their expectations of the game . Competing predictions: assimilation vs. contrast: Contrast theory predicts that positive metaphors will backfire because AI agents inevitably make mistakes and have limits: Hypothesis 2 (H2). Positive metaphors (e.g., high competence, high warmth) will lead to lower average intention to adopt and desire to cooperate with an AI agent than if it had no metaphor or negative metaphors.", "rq": ["how do metaphors impact evaluations of interactions with conversational ai systems?"], "id": "dev_18"}
{"intro": ": Recommender systems have become critically important for helping users quickly find ideal items among a large number of products . However, personalized recommendations may lead users to increasingly narrower space of items over time (called \"filterbubble\" effects) . To mitigate this issue, several attempts have been made to encourage users to explore diverse sets of items, such as diversity-driven algorithms and visualizing recommendations . On the other hand, dialogue-based conversational recommender systems enable users to freely give feedback on recommendations through natural language , which show considerable potential for promoting users' exploratory activities. However, so far little work has studied supporting user exploration through conversational interaction. INTRODUCTION: Recently, there is a work that studied a chatbot for accommodating user control in music recommendations with two critiquing techniques (i.e., user-initiated critiquing (UC) and system-suggested critiquing (SC) ). The user study of this work reveals that users tend to feel receiving more diverse recommendations when using the system with both UC and SC. Inspired by this observation, we consider to stimulate users' exploration of recommendations by strengthening the critiquing technique in conversational interaction. INTRODUCTION: Therefore, in the current work, we have designed two kinds of system-suggested critiquing technique: Progressive systemsuggested critiquing (Progressive SC) and cascading systemsuggested critiquing (Cascading SC) for facilitating users' exploration of music with two different directions: The former is preference-oriented, which provides critiques based on users' current preferences and incremental critiquing feedback , while the latter is diversity-oriented, which suggests critiques to steer users into a cascade of diverse types of music using a strategical approach with the assumption of the cascading user behavior as inspired by . Then, we have developed a music chatbot with three system variants, which are respectively featured with UC (i.e., users can make critiques on the recommended songs to explore songs they want), Progressive SC and Cascading SC. To investigate how these critiquing techniques influence users' music exploration with conversational interaction, we conducted a between-subject user study (involving 107 participants) to compare the three system variants in terms of both user perception of and user interaction with recommendations. We also examined how these critiquing techniques moderate the relationship between user interaction behavior and user perception of music recommendations. INTRODUCTION: In a short summary, we have mainly focused on answering two research questions as follows (see Figure 1 ): RQ1: How do critiquing techniques influence users' exploration of music in a conversational recommender? INTRODUCTION: RQ2: How do critiquing techniques moderate the relationship between user interaction behavior and user perception of music recommendations? INTRODUCTION: Our main contributions of this work are four-fold: INTRODUCTION: (1) We have proposed two kinds of system-suggested critiquing technique, in order to encourage users' exploration of music recommendations, and compared three variants of the system supported with different critiquing methods (i.e., UC, Progressive SC, and Cascading SC) in terms of users' perception of and interaction with recommendations. The experimental results show that users perceive higher diversity of recommendations with the system that offers Cascading SC and feel more serendipitous recommendations with the system that offers Progressive SC. INTRODUCTION: (2) We have investigated the moderation effects of critiquing techniques, and find that the critiquing techniques significantly moderate some relationships between interaction metrics (such as number of listened songs and number of dialogue turns) and user perception metrics (such as perceived helpfulness and serendipity). (3) We have analyzed users' interaction flow towards UC and SC, and find that users tend to use UC when they have gradually established their new preferences during the interaction with conversational recommendations, while users may be stimulated to request SC when they have benefited from the SC proactively offered by the system. (4) We have discussed our findings and provided practical implications for designing a critiquing-based conversational recommender system for supporting users' music exploration.", "relatedWork": "2.1 User Exploration in Recommender Systems: Prior work has shown various strategies to support user exploration by diversity-driven algorithms or visualizing recommendations. Diversity-driven algorithms typically generate recommendations that maintain the balance between accuracy and diversity . For instance, some researchers proposed to increase the recommendation diversity based on items' attributes, such as book topics , movie genres, and social tags . In , the authors proposed a way to help users take a gradual path towards the desired new music preference by traversing user preference graphs and generating a sequence of artists as guided transition. Most of the related studies have attempted to increase the diversity for a ranked list, but there are some limitations , such that users tend to pay less attention to the bottom of the list when exploring recommendations, which is a position bias. Besides, some works have visualized recommendations to support user exploration in recommender systems. For example, to raise users' awareness of exploration, highlighted the regions of the underrepresented recommendation space, so-called blind spots, which could help users to identify what is known and what is unknown in their profile. Some visualization systems, such as TalkExplorer, , and Moodplay , allow users to explore diverse items during the recommendation process. In , the authors introduced a shortlist as a short-term memory to reduce users' cognitive efforts and help users make better decisions when exploring diverse movies. The recommender systems discussed so far support user exploration by presenting diverse recommendations or visualizations. To the best of our knowledge, little work has been done to support user exploration with conversational interaction. Conversational Recommender Systems: Conversational recommender systems aim to help users seek for their desired items through natural language . Several studies have demonstrated this kind of conversational systems . For instance, ExpertClerk is a conversational agent designed to interact with shoppers by asking questions to obtain their preferences and proposing recommendations to assist users to find their satisfactory products. Adaptive place advisor provides personalized recommendations to assist users to find preferable places for traveling by considering both users' long-term preferences and short-term interests. Also, several studies show the superiority of conversational user interfaces over graphical user interfaces during the process of recommendations . Conversational Recommender Systems: In the broad area of recommender systems, critiquing-based recommender systems have been proposed to elicit users' critiquing feedback to help the system improve the recommendation . In particular, there are two major types of critiquing technique, including user-initiated critiquing (i.e., users construct critiques by themselves) and system-suggested critiquing (i.e., the system generates a set of critique candidates for users to choose). A recent work studied such kind of system with conversational interaction and found that critiquing techniques enable users to control recommendations in conversational user interfaces. They also observed that users tend to perceive higher diversity and efficiency when the conversational recommender presents system-suggested critiques compared to the system that only supports user-initiated critiquing. Inspired by this observation, we are interested in in-depth investigating how critiquing techniques can support users' exploration of recommendations with conversational interaction. Conversational Recommender Systems: Different from , in this work, for stimulating users' exploratory activities, we introduce two kinds of system-suggested critiquing: Progressive system-suggested critiquing that is preference-oriented (generating critiques considering both users' current preferences and incremental critiquing feedback ); and cascading systemsuggested critiquing that is diversity-oriented (suggesting critiques in a strategic approach with the assumption of the cascading user behavior as motivated by ). In addition, we consider the chatbot's proactivity in our designed systems (i.e., the ability of proactively offering SC to encourage users to explore music), since some previous studies have shown that the robot's proactivity may help people get rich information and reduce the decision space .", "rq": [" rq1: how do critiquing techniques influence users' exploration of music in a conversational recommender?", "rq2: how do critiquing techniques moderate the relationship between user interaction behavior and user perception of music recommendations?"], "id": "dev_19"}
{"intro": ": The productivity of information workers can be significantly influenced by information overload and stress. Due to the ubiquity of multiple devices, including desktops, laptops, phones, surfaces, smart watches and speakers, notifications, messages and other kinds of disruptions have become a serious problem for keeping focused on high priority tasks at work. A large body of work in human-computer interaction (HCI) research has concentrated on better understanding how workers manage their tasks, attempt to stay focused, and deal with distractions and interruptions throughout the day. In any given day, information workers are typically faced with multiple tasks that they need to complete, and often they devise unique strategies to remember and make note of these tasks . A diary study of information workers found that workers had an average of 50 task-shifts over an entire work week . Furthermore, information workers are usually faced with numerous interruptions throughout their day. INTRODUCTION: At work, people average 40 seconds on a computer screen before switching , and it can take several minutes for an office worker to return to their original task after interruptions. The deleterious effects of notifications, email and face-to-face interruptions has been very well documented in terms of lowered productivity at work. Different factors like the type and duration of the interruption, the complexity of the task prior to interruption, and even the exact moment of the interruption can have a negative effect on workers' ability to resume a task, their perceived productivity and their satisfaction with their performance . For instance, past work from Iqbal and Horvitz found that when information workers were interrupted by conversation, they were more likely to return to work on more peripheral tasks like email and web searches, rather than resume their previous task. INTRODUCTION: Research suggests that more distractions can lead to higher reported stress and lower productivity in the workplace . While there have been many attempts to design software to assist with this problem in order to reduce stress and improve focus (e.g., Freedom, Windows FocusAssist , Tracktime , see for a review), few of these products have yet to be widely adopted in the Figure 1 : We present two productivity agent prototypes which help users schedule and block time on their calendar to focus on important tasks, monitor and intervene with distractions, and reflect on their daily mood and goals. Snapshots of the sample morning dialogue interactions for the text-based (left) and virtual agent (right) prototypes are shown. The face images are blurred to respect privacy. INTRODUCTION: workplace. Therefore, people continue to design their own methods and workarounds, but report having trouble nonetheless . INTRODUCTION: These findings suggests that maintaining focus in the face of constant shifting priorities and interruptions in the workplace is a complex and important problem. Yet, to our knowledge, only one system, from Kimani et al. , has yet been designed that helps knowledge workers with prioritizing their work, providing reminders on when to switch tasks or get back on task, to take breaks, as well as to reflect on how much they accomplished at the end of the day. While this effort was notable for its complex system design, the user interface was quite simple in its design, similar to a standard chatbot. In our work, we design two different agent prototypes which build upon this past work from Kimani et al. (described further in the related work). Our paper offers three main contributions: 1) The design of two different conversational agents, one text-based (TB), similar to a chatbot, and one virtual, embodied, conversational agent that responds to the user's emotion (VA), 2) a longitudinal evaluation of these two agents against a shipping product that tries to help users schedule focus time in Microsoft Outlook, and 3) actionable insights from qualitative analysis of user feedback on agent design around anthropomorphism, user task scheduling, and the need for better back and forth negotiation and control with the user.", "relatedWork": ": For task and time management, various different applications have been developed, most notably, MeTime , RADAR , TaskBot , and Calendar.help that each aim to assist users be more efficient in managing their work through different approaches. MeTime aims to provide real-time awareness of how users are spending their time through graphic visualization of their application usage in order to promote efficiency of time use achieving their task goals . The authors showed that exposure to meTime decreased time spent on distractions (e.g., social media), and increased their feelings of productivity . RADAR is an AI system that was designed to help reduce email overload by automatically producing tasks and to-do lists directly from users incoming emails . Through an experimental setup, users that were aided by RADAR that were confronted with overload performed better at completing email intitiated tasks than without RADAR. TaskBot, a chatbot agent was designed to mediate the creation and management of tasks within project teams . Users found TaskBot useful for naturally transferring conversations into actionable tasks, but found that the system struggled when having to deal with multi-threaded conversations . Finally, Calendar.help used an AI interface integrated with the user's email to automatically schedule user's meetings, and allowed the user or another human assistant to make adjustments manually when needed . RELATED WORK: Applications developed within this domain have also aimed at helping block distractions to help users focus. One such example is Microsoft Focus Assist, which allows users to define \"whitelisted\" work related sites and applications and \"blacklisted\" non-work related sites and applications . Focus Assist also then blocks access to non-work related sites and applications for a period of time determined by the user . RELATED WORK: Finally, other applications have aimed at promoting workers to reflect on their emotions and goals throughout the workday, as well as to promote saving time for healthy and appropriate breaks. For instance, Robata was developed to be voice mediated agent that helped its users plan and organize their tasks, reflect on their motivation and satisfaction throughout the day, and also promote and reflect on their self-learning . Users of Robata reported generally appreciating a way of reflecting on their planning and goal setting . BreakSense is another application that was developed to help promote mobility for its users during their breaks in order to encourage healthy activity and lifestyle in office environments that can be often very sedentary . RELATED WORK: Although each of these applications attends to a specific problem area within the broader domain of promoting workplace productivity and well-being, there has been little research on the development and evaluation of AI systems that incorporate task scheduling and management, distraction blocking and monitoring, and mood and goal reflection in a single, standalone application. To our knowledge, the only application that has attempted to integrate all these different functionalities into a single system is the work of Kimani et al. . In their work, they presented Amber, a conversational desktop assistant whose purpose was to help workers in four main areas: (1) scheduling high priority tasks, (2) aiding workers in transitioning from one task to the next, (3) avoiding and intervening with distractions, and (4) reflecting on their work through a conversational AI interface . In our work, we present our productivity agent, which builds upon the infrastructure and capabilities of this previous agent developed by Kimani et al. . Similar to the work from , we gave our agent a female gender. RELATED WORK: Our work extends this previous work in a number of ways. First, as Kimani et al. found in their analysis that users desired an agent that took more control over the flow of interaction, we designed our agents to provide a series of dialogues that started at the beginning of each day with scheduling their tasks, helping users progress through these tasks until the end of the day. These dialogues were initiated automatically when appropriate without any extra user input. Second, in addition to incorporating the four major functionalities from Kimani et al. , we also wanted to investigate the impact that a more human-like agent with more emotional intelligence would have on user perceptions, as well as their focus and productivity. In past studies of virtual agents, research has found that emotionally appropriate responses from an agent contribute to a more positive and satisfying experience during interaction . Furthermore, emotional intelligence in agents has been shown to help alleviate negative emotions, like frustration . In a study of the effectiveness of different agent characteristics in an organizational setting, anthropomorphic appearance in agents was also shown to increase users perceptions of the agents usefulness . As little research has investigated the effect of more human-like agents in the context of workplace focus and productivity, a primary goal of our study was to evaluate and compare its effectiveness to a typical chatbot agent. Therefore, in this work, we build two different prototypes of our agent: a text-based conversational interface prototype (TB) that employs a similar UI to the previous version developed by Kimani et al. , and a prototype virtual agent conversational interface (VA) version with a video avatar that speaks to the user. The VA prototype incorporates the ability to detect user emotions through video input and adapt its responses to be appropriate and congruent with the users emotional state. We conduct a three week long within-subjects user study to evaluate and compare the VA prototype, the TB prototype, and a simple, non-conversational task scheduling tool integrated into users' email, similar in part to Calendar.help , as a control. To our knowledge, our work presents the first multi-week user study evaluating different intelligent agent prototypes that aim to increase focus and productivity at work.", "rq": ["rq1: are users more productive and less distracted during the time periods they scheduled for focused work through the agents?", "rq2: With which agent prototype are users most productive, least distracted, and most satisfied?", "rq3: what features of the agent prototypes are most useful, and are there design improvement opportunities?"], "id": "dev_20"}
{"intro": ": The importance of self-disclosure-revealing personal or sensitive information to others -for mental well-being has been proved in substantial literature . For example, through selfdisclosure, people can release their stress , analyze themselves , gain social support and receive professional services . But it is always challenging for mental health professionals by bringing the unique insight that trust may be transferable from human-AI to human-human through AIs.", "relatedWork": ": In this section, we first present literature on how chatbots are a promising technological solution for promoting people's self-disclosure; then, we discuss related work about how people self-disclose with peers through ICTs, e.g., social media platforms. Finally, we provide background work on the remaining challenges of self-disclosure with medical health professionals (MHPs), often without ICTs. With the literature review, we propose our research questions. RELATED WORK: 2.1 Promoting Self-Disclosure to a Chatbot Chatbots have been broadly used in different areas . They can not only help people complete various tasks but can also improve mental well-being (e.g., self-compassion ). For example, chatbots are utilized in the workplace to assist team collaboration , to improve workers' quality of life and work productivity , and to reduce caregivers' workloads . Park et al. adopted Motivational Interview in the chatbot conversation to help users cope with stress and found that their design can facilitate a conversation for stress management and self-reflection. Lee et al. designed a dialog to make the users take care of a chatbot's negative experience. After a two-week interaction with the chatbot, the user's self-compassion significantly increased. These studies have demonstrated the potential benefits of using a chatbot in different purposes, and our research aims at understanding how to use a chatbot to mediate sensitive information. The Computers Are Social Actors (CASA) paradigm indicated that people may apply social norms of human relationships when interacting with computer agents . Thus, research has been focusing on advancing technological contributions for making computer agents to naturally chat and understand people; thus, some studies examined different strategies to enhance users' experience when talking with a chatbot. For example, Hu et al. found that the tone-aware chatbot could be perceived as being more empathetic than a human agent . RELATED WORK: People's self-disclosure to chatbots can be used to detect symptoms, identify possible causes, and recommend actions to improve their symptoms by promoting people's self-disclosing, as well as to encourage interviewees to disclose themselves more openly in an interview session . Scholars compared web surveys against chatbots and found that respondents tended to provide more highquality data when using the latter . Fitzpatrick et al. utilized a therapy chatbot \"Woebot\" in their study to explore its feasibility to help reveal people's mental illness; their results showed that the chatbot helped relieve symptoms of anxiety and depression . Additionally, chatbots can be deployed to various platforms using both speech and text; chatbots provide cost-effective solutions for self-disclosure or deliver education materials for self assessment (e.g., alcohol risks ). However, most of the works focus on human-chatbot interactions, and little work studied: RELATED WORK: 2.2 Self-Disclosure with Peers through ICTs Self-disclosure behavior on social network sites has gained the attention of HCI scholars. For example, people freely disclose stress, depression, and anxiety through online social media platforms . It was found that such anonymous self-disclosure with their peers could help users maintain their mental well-being, as they may receive social support from their peers . Similarly, Yang et al. investigated the self-disclosure behaviors of online health support communities, and the study found the members' self-disclosure in private and public channels affected how they reciprocated with other and reached out for social support. Although self-disclosure on social media could help each other seek social support, people naturally avoid revealing their vulnerabilities to others , as it might also cause social risks . Thus, Andalibi et al. explored how people used throwaway accounts on Reddit to disclose their stigmatized issues (e.g., sexual abuse) and found that people using anonymous means engaged more in seeking support. RELATED WORK: Through interacting with the chatbot, people can search useful resources, i.e., self-help information, before reaching out for face-to-face counselling . Therefore, chatbots have become popular in response to the demand of mental health care in modern society . A recent work shows that chatbots can play a role to inquiry users answering questions and convincing them to share diet information with their family members so as to support each other . Also, coaching apps have been developed, not only for boosting users' awareness of their own mental well-being, but also for helping mental-health professionals gain more knowledge about their clients . In this study, we investigate using a chatbot to facilitate self-disclosure to a MHP: RELATED WORK:Self-Disclosure with Medical Professionals without ICTs: In the sphere of mental health care, journaling is a common practice of self-tracking that has been proven effective in terms of boosting mood and reducing anxiety . Prior studies have shown the positive effect of deploying a chatbot to facilitate journaling and for helping people to realize their mental issues and relieve their symptoms. Self-Disclosure with Medical Professionals without ICTs: However, how people interacted with the chatbot differently when they self-disclosed sensitive topics to mental health professionals has not been investigated. According to social penetration theory , self-disclosure is critical for the development of a successful interpersonal relationship that involves give-and-take between its parties. Self-disclosure is evaluated from two dimensions, breadth and depth . The breadth of self-disclosure can be demonstrated with a wide range of topics disclosed; on the other hand, the depth is more involved with personal experiences, intimate relationships, and possible negative feelings as a result of life difficulties. Prior works on chatbots often highlighted the volume of self-disclosure in terms of its breadth (e.g., ); less was discussed on its depth. In order to assess mental well-being, a high depth of disclosure (deep self-disclosure) is needed . To elicit self-disclosure at a deeper level, a higher level of trust is often associated in the relationship . Self-Disclosure with Medical Professionals without ICTs: Our work fills the void by focusing on evaluating self-disclosure depth by running an experimental study and by comparing participant's daily journaling and answers to sensitive questions before and after sharing with a real mental health professional via the chatbot. According to the norm of reciprocity, when someone discloses something deeply personal, his or her interlocutor feels pressure to share a similar level of information , therefore, therapists often disclosed themselves to encourage partients' self-disclosure . In a recent work, reciprocity was found to happen in human-chatbot interaction as well, e.g., a self-disclosing chatbot received more self-disclosure from users . Lee et al. indicated that small-talk increased users' trust in the robot, and found that a user's greeting with the robot could predict the user's conversational strategies such as sociable interaction and self-disclosure. Thus, these studies demonstrated that a reciprocal social conversation may increase people's trust in a computer agent. Although mutual self-disclosure can, with time, facilitate intimacy, trust, and depth of self-disclosure by both parties , whether and how a psychiatrist should self-disclose to clients is the subject of ongoing debate . Some studies have raised concerns that too much closeness with clients might derail their progress . However, others have suggested that therapists' carefully selected self-disclosures could be beneficial as a means of building rapport with clients and of building certain skills that can strengthen the counseling relationship, such as active listening , gradually building trust , and matching communication styles . On the other hand, lack of trust in online applications may lead to inaccurate information being collected and deterred efficacy of services provided by the applications . What if the MHP is not involved in the conversation directly, and instead, the MHP only receives self-disclosure content from people through a chatbot? This is the context of our study. Self-Disclosure with Medical Professionals without ICTs:", "rq": ["rq1: Do people self-disclose to a medical professional through a chatbot differently from selfdisclosing with a chatbot alone?", "rq2: what is an effective chatbot design as a mediator for eliciting self-disclosure to a medical professional?", "rq3: how do people self-disclose to a medical health professional (mhp) through a chatbot?\n rq4: what factors contribute to people' self-disclosing behavior to the mhp through a chatbot?"], "id": "dev_21"}
{"intro": ": There were over 4 billion phone users in 2008 , and close to 60% of subscribers live in developing countries . Thus, many entities with a global development focus have turned to the mobile phone as a potential platform for delivering development services, in sectors spanning education, finance, health, agriculture, and governance . One of the challenges of delivering such services, however, is that 41% of the population in the least developed countries is nonliterate , and even the literate among the poor are typically novice users of computer technologies. Previous research shows that nonliterate populations avoid complex functions, and primarily use phones for synchronous voice communication . This brings us to the question of how we can design mobile phone interfaces such that novice and low-literacy users can use more advanced services, if they were provided. INTRODUCTION: Mobile devices lend themselves to a rich design space of alternative user interfaces. As depicted in Figure 1 , it is natural to classify mobile interfaces along two axes, according to the flexibility of their input and output modalities. Rigorous comparisons between points in this space are only starting to be explored by researchers. Concurrently to the studies conducted in this article, researchers have examined the trade-offs between interactive voice response (spoken menus with keypad navigation) and spoken dialog systems (spoken menus with speech navigation) and have reached varying conclusions regarding the benefits of typed versus spoken inputs . However, to the best of our knowledge, there has never been a quantitative evaluation of mobile interfaces that encompasses the full space of designs, spanning text, audio, and graphics. We present the first such evaluation in this article. INTRODUCTION: The contributions of this article are twofold. First, in order to understand the usage patterns of nonliterate and semiliterate mobile phone users, we conducted an ethnographic exploration involving 79 subjects and 100 hours of interviews in India, the Philippines, and South Africa. We also leverage 11 interviews conducted in Kenya by Ratan . This investigation revealed several barriers to using existing text-based interfaces, including difficulties understanding or utilizing hierarchical structures, soft keys, scroll bars, nonnumeric inputs, and specialized terminology. We formulate a set of design recommendations to improve the usability for low-literacy populations, including the provision of graphical cues, voice annotations, and local language support, as well as avoiding complex navigation and inputs. INTRODUCTION: To evaluate and refine these guidelines, we conducted two separate experiments that quantitatively assess the impact of various design elements on novice and lowliteracy users. Depicted graphically in Figure 1 and summarized in Table I , these studies incorporate over 70 subjects in India and represent the second contribution of the article. Both studies compare text-based mobile interfaces to richer alternatives. The first study considers automatic solutions (spoken dialog 1 and graphical, text-free UI ), and the second study compares text input to a live human operator. In both scenarios, we find that the nontext interfaces greatly outperform their textual counterparts. In the context of mobile banking, not a single low-literacy subject could complete a transaction using the text interface, while 72% completed the task using spoken dialog and 100% were successful using a graphical UI. In the context of health data entry, literate health workers and hospital staff demonstrated approximately a 5% error rate using text interfaces, but performed ten times better using a live operator. INTRODUCTION: Our studies also uncover new trade-offs in designing mobile interfaces for novice and low-literacy users. While the spoken dialog system offered lower rates of task completion than the graphical interface, users that did succeed in completing the task did so more quickly and with less external assistance on the spoken dialog system. We attribute this to the fact that most users are more comfortable and familiar with providing spoken inputs, and thus can complete task more quickly; however, some users lack a basic understanding of the context, the terminology, or the interface and, being unable to acquire that understanding through an automated spoken dialog system, are unable to complete the task at all. For the graphical UI which required typed inputs to proceed, we observed that while task completion rates were higher, more time as well as more external assistance was required. We attribute this to the fact that users required significant prompting, encouragement, and time to press any key as they were nervous that they might \"break\" or \"spoil\" the phone. Also, our evaluation of the live operator interface suggests that it offers several benefits in addition to the high accuracy achieved, including the ability to change the interface over time and the ability for users to convey detailed, unstructured information over the phone. In environments such as India, an operator interface is also highly cost effective, and can be less expensive than providing programmable phones to field staff. For these reasons, the results of our study caused a community partner to change their plans for a rural tuberculosis treatment program from using electronic forms to using a live operator. INTRODUCTION: In the rest of this article, we describe related work (Section 2) before presenting our ethnographic investigation (Section 3) and each of our user studies (Sections 4 and 5). We conclude in Section 6. Our presentation summarizes and extends research whose", "relatedWork": ": Here we consider related work in evaluating the accuracy of data entry on mobile devices, as well as design techniques to improve usability for low-literacy users. Evaluating the Accuracy of Mobile Data Entry: As summarized in Table II , there have been several initiatives to apply PDAs and cell phones for mobile data collection in the developing world. While a fraction of the studies on PDAs include an experimental analysis of the error rate incurred, we are unaware of any prior study which systematically measures the accuracy of data entry (or the likelihood of completing a task) on a low-cost cell phone. This is a central novelty of our work. As detailed elsewhere , previous studies of PDA entry accuracy have found that novice users can achieve an error rate of less than 2% (i.e., less than 2 errors per 100 entries) given that they receive at least an hour of training . In two of these studies, error rates are as low as 0.1-0.6% and 0.4% . However, in a context where novice users received only 2-3 minutes of training, error rates were observed to be 14%; entry accuracy was substantially higher for those who had completed secondary schooling . Evaluating the Accuracy of Mobile Data Entry: Additional programs have applied PDAs for data collection in the developing world, but have not provided a rigorous analysis of entry accuracy . In the case of SATELLIFE , there are anecdotal reports that PDAs improved data quality and demonstrated decreased error rates as estimated on a five-point scale . An additional report had users rate the usability of the system . However, we are unaware of a quantitative assessment of the error rates incurred. DataDyne EpiSurveyor is also argued to be more accurate than paper forms , though we are unaware of a controlled study. Evaluating the Accuracy of Mobile Data Entry: Cell phones have also found broad application for mobile data collection in the developing world, with interfaces spanning electronic forms and interactive voice response . While we are unaware of previous evaluations of entry accuracy, there are three studies ( published concurrently to our own) that assess the accuracy of novice users in navigating interactive voice response systems . The studies have varying results: one reports that task completion is higher with dialed inputs than with speech inputs , one reports comparable task completion but a preference for dialed inputs over speech inputs , and one reports that speech inputs significantly outperform dialed inputs . Evaluating the Accuracy of Mobile Data Entry: To avoid the complexities of navigating electronic forms, the CAM framework offers a hybrid system in which paper forms are used for organization while phones are used for data entry . Each field on the paper form is annotated with a barcode which is recognized by a camera on the phone prior to data entry. Users that lacked prior camera or computer experience were trained to a level of comfort within 5-15 minutes. A separate study measures error rates of 1% or below using the CAM system . This represents an interesting and useful design point, especially in cases where paper forms are already ingrained into the workflow. We focus on solutions that are independent of any paper workflow and which do not necessarily require a camera-phone. While phones that support electronic forms (e.g., via Java) often have cameras, our SMS, USSD, spoken dialog, and live operator solutions are suitable to the most inexpensive phones. Design Principles for Low-Literacy Users: Because for the most part illiteracy correlates strongly with poverty, nonliterate users are very different from the target users of typical UI designs . Most previous work with nonliterate users focuses on the mechanics of the interface, and on PCs or PDAs. Many researchers have recognized the value of imagery, and have advocated extensive use of graphics . Voice instructions and audio annotations are also powerful, and much of the interesting work in this area focuses on the interplay between graphics and audio to generate a usable interface, as reviewed elsewhere [Medhi et al. 2007a [Medhi et al. , 2007b . Some authors note that the use of numbers is acceptable, as many nonliterate people can read numerical digits [Medhi et al. 2007b; Parikh et al. 2003a Parikh et al. , 2003b . Design Principles for Low-Literacy Users: Other work has focused on ultra-simple navigation as a design goal , or on removing anxieties about technology use. For example, looping video clips which include dramatizations of the overall usage scenario have been found effective in reducing barriers to usage by first-time users . Voice recordings of \"help\" information have also been shown valuable . These principles have been applied to application domains such as job information systems , health information dissemination , and microfinance [Parikh et al. 2003a [Parikh et al. , 2003b . Design Principles for Low-Literacy Users: Interfaces for low-literacy users have also been studied in the context of Automatic Teller Machines (ATMs). Two studies propose an icon-based approach for ATMs . Another study looks at attitudes in literate and semiliterate bankaccount holders towards ATMs and alternative ATM interfaces (speech based and icon based) . Overall, groups showed a tendency to prefer an icon-based alternative ATM interface over the other choices. Evaluations of a pilot trial by one large bank in India make various recommendations for ATMs for low-literacy users: avoid use of text altogether; loop voice instructions in simple, slow vernacular; provide biometric authentication; use consistent visual cues . Design Principles for Low-Literacy Users: Apart from work that focuses on PCs, PDAs, and ATMs, there is some amount of research that looks at mobile phone UIs for low-literacy users. Researchers have recognized the value of voice feedback and speech interfaces . Others have questioned suitability of menu-based navigation for novice users and have discussed designs that advocate fewer menus and dedicated buttons for this target group . Again there is work that looks beyond the UI at coping mechanisms of illiterate and semiliterate users when confronted with traditional mobile interfaces [Chipchase 2005 [Chipchase , 2006 .", "rq": [" we divide our analysis according to two orthogonal questions: why were users faster and more independent on the voice ui, and why were they also more likely to give up?"], "id": "dev_22"}
{"intro": ": After an American actress Alyssa Milano tweeted a request to those who have been sexually harassed or assaulted to reply with \"me too\", 1.7 million tweets were made within ten days in at least 85 countries . According to a survey in 2018, 81% of women and 43% of men in the US reported experiencing sexual harassment or assault in their lifetime . Incidents of SH continue to be reported on a regular basis and many organizations are seeking ways to build a proper anti-harassment culture such as offering repeated and mandatory SH prevention training. A typical training program is comprised of presenting information and resources online with case studies and evaluating learner's comprehension using surveys and quizzes. In-person classes are sometimes held to supplement the online training and discuss SH issues . INTRODUCTION: Despite prevalent training, recurring SH incidents are raising doubts about the effectiveness of existing SH prevention programs . Some researchers assert that current methods have little impact on changing one's actual behavior and may even have the opposite effect . As our results will later show, the existing designs are perceived to be tedious, overwhelming, uncomfortable to express honest opinions, and un-motivating. Our work envisions a new class of interactive training delivered by an intelligent conversational agent. This paper progresses toward that vision by providing a realistic experience of having a conversation with an intelligent agent representing a person who has been sexually harassed. INTRODUCTION: In this paper, we explored the design of a text-based conversational interface (CI) to incorporate design principles that underlie effective SH training. We derived three key principles from the literature about how to design effective SH prevention training : 1) Foster empathy towards SH targets through the use of first-person narratives, 2) use interactive and experiential methods (e.g., role-play scenarios), and 3) utilize synchronous delivery methods (e.g., online chat). While prior studies in the design and education research communities have tested different subsets of these principles , we designed and implemented a CI that demonstrates a novel synthesis of all three principles for SH prevention training. Our proof-of-concept interface was designed to have a persona of a woman, named Jane, who has been sexually harassed in the workplace and engages the learner in a conversation about her experience from a first-person perspective. INTRODUCTION: We conducted a mixed-methods study (N=32) to explore the benefits and limitations of the CI design for the purpose of SH prevention training. Participants were randomly divided into two groups, either interact with our interface (CI group) or read the same vignette on a web page (Control group). In both groups, we measured empathy using an 8-item scale and Inclusion of the Other in the Self (IOS) scale , and SH attitude using Sexual Harassment Myth Acceptance (SHMA) scale to evaluate how experiencing the vignette through the interfaces affects learners' empathy towards the target and attitude towards SH. We interviewed participants and extracted the themes that emerged from their responses. INTRODUCTION: We compared the themes between the CI and the Control group and identified the themes that appear in the CI group only. The participants in the CI group reported feeling engaged due to the designed interactivity (N C I =14). Participants also reported that reading individual messages was less overwhelming than being presented with an entire article and created suspense of how the conversation would unfold (N C I =9). Participants appreciated the CI being a realistic simulation because this allowed them to feel comfortable discussing a sensitive topic (N C I =8). They also felt immersed in the situation and motivated to help the target (N C I =15). These benefits favorably contrasted with the limitations of the traditional SH training that participants had previously experienced. In contrast to our expectation that the virtual interaction with a SH target would increase empathy, the quantitative results revealed that there was no significant difference between the conditions on empathy. INTRODUCTION: Our study makes three contributions. First, we identify design principles from prior literature for effective training and demonstrate how to implement a subset of these principles within an intelligent CI. Second, our results provide a deeper empirical understanding of how our interface design affects a learner's experience relative to the status quo approach for the purpose of SH training. Lastly, we provide design implications for building intelligent interfaces that aims to arouse empathy and support experiential learning. Our work is original because we reveal insights on how our interface can complement the current practices through systematic analysis, and initiate thought-provoking discussions on how to improve the proposed design and the training. We anticipate that the results and the implications generalize to other training programs (e.g., ethics, inclusiveness, and security training), contexts dealing with sensitive issues (e.g., stigmatic diseases), and domains that value empathetic responses from users (e.g., medical crowdfunding).", "relatedWork": ": SH refers to unwelcome sexual advances, requests for sexual favors, and other verbal or physical harassment of a sexual nature . Effective interventions are critical for reducing the prevalence and severity of SH. Our research focuses on advancing the use of training as an intervention for SH prevention . Our work complements other HCI research and interventions that encompass sexual misconduct problems including dating and domestic violence , stalking , and online harassment . Sexual Harassment Prevention Training: SH prevention training seeks to achieve two goals: 1) inform learners about anti-harassment policies and resources, and 2) educate learners about appropriate conduct and improve attitudes towards SH prevention . Achieving the second learning goal is known to be more challenging but also less studied in the research community . A consistent finding in the literature is that training designed to promote empathy toward the target of SH improves a learner's attitude towards SH . Diehl et al. showed that reading a SH case from a target's perspective increased empathy and reduced the acceptance of SH misconception compared to reading the case from a perpetrator's perspective . Schewe and O'Donohue found that presenting empathy-arousing materials decreased men's self-reported likelihood of committing sexual abuse . Empathy is also related to experience-taking, an imaginative process of spontaneously assuming the identity of a character in a narrative and simulating that character's thoughts, emotions, behaviors, goals, and traits . A story written in first-person, where the main character relays a story from his or her point of view, is effective for experience-taking. Prior work shows that first-person narratives lead to favorable changes in participants' behavior and attitudes toward the character's group and positive perceptions of the learning experience . Sexual Harassment Prevention Training: The form of the instructional method is critical for arousing empathy and achieving the desired outcomes of SH training . Providing multiple methods for training, such as video-based episodes combined with case analyses in text, correlates with increased sensitivity to SH scenarios . However, studies on how to design effective instructional methods are limited . Existing research focuses on text and videos and these methods have shown success in clarifying the gray area of unwanted sexual behavior and improving knowledge . However, such methods have had little impact on changing actual behavior and even lead to adverse effects such as reinforcing gender stereotypes . Researchers suggest that attitudinal change requires more interactive or experiential training . Sexual Harassment Prevention Training: HCI researchers have primarily focused on creating technology that prevents SH in-situ such as developing panic buttons to draw attention of bystanders or notify emergency contacts , crowdsourcing maps to show locations of SH incidents , and evaluating recording probes that collect contextual data on negative behaviors . However, how to design technology that delivers effective SH prevention training has received little attention in the HCI community. Our work contributes to this limited body of literature by reporting on the design and evaluation of a conversational agent for SH prevention training. Leveraging Conversational Interfaces for Sexual Harassment Prevention Training: A conversational interfaces (CI), an interface that allows a user to interact with a computer as if it were a conversational partner , has been increasingly leveraged in training and education as well as in other domains such as healthcare . Previous studies showed that the technology has the potential to assist attitude learning, which involves cognitive, affective, and behavioral aspects. Regarding the cognitive aspect, prior works have revealed the effectiveness of the CI in memory retention , critical thinking, and inquiring mindsets . A CI is known to improve students' affective learning outcomes and influence users' behaviors through distraction and encouragement . Leveraging Conversational Interfaces for Sexual Harassment Prevention Training: Prior work has also investigated the use of a CI for storytelling. Emile was created to discuss social theories in first-person narrative. A Freudbot was designed to represent Sigmund Freud, a famous historical figure in psychology, and informed his theories and biographical events in Freud's voice. These studies reported that students endorsed the idea of using the interface as a promising direction in online education. Our work builds on these prior successes by extending and studying the use of a CI for SH prevention training. The goal is not only to acquire knowledge on the topic, as in prior uses of the interfaces, but also to arouse learners' empathy towards the targets of SH and change attitudes about what type of behaviors are considered as SH.", "rq": ["rq1. what strengths and weaknesses do learners perceive in the use of the ci for sh prevention training?", "RQ2. Does the experience through the CI increase empathy and improve attitude towards SH?", " rq3. what limitations do learners perceive in traditional sh prevention training?"], "id": "dev_23"}
{"intro": ": Bots deployed in online communities are a combination of tools designed to serve a specific purpose and social actors intended to join conversations . They are designed to do many things that humans had previously done or would otherwise do, but are also created with social elements in mind -their own names, grammatical styles, and sometimes even personas. Many are run alongside rather than within sites, a concept that Geiger calls \"Bespoke Code\" . In certain situations, bots can create and contribute their own content to a community in patterns designed by their creators. To the outside observer, limited affordances on certain sites allow cleverly designed bots even to pass as human for extended periods of time . Beyond their variable humanity, bots give us new capacities, particularly by amplifying our efforts in speed or scale. They help us collect data , attract attention for a cause , and detect and respond to certain behaviors . At scale, bots can even help shape or sway political conversations . INTRODUCTION: In this paper we explore the variety of types of social actions that can be taken by bots on Twitch 1 , a growing platform that reports more than 140 million unique users 2 and hosts thousands of diverse communities. As we find in our analysis, Twitch bots are extremely active participants in Twitch chatrooms; though the overwhelming majority of accounts that participate on Twitch are human, the average bot sends well over an order of magnitude more messages than the average human, making them important actors in the space. While recent research has found similar patterns of participation for both malicious and user-invited bots in spaces like reddit and Twitter , Twitch is both a new context for the study of bots and a space with a different conversational structure than Twitter or reddit, with bots participating in a public chatroom rather than a threaded conversation or Twitter network. We show here Twitch bots' importance to the social discourse on Twitch both through analysis of their rates of participation across different types of communities and through description of the types of engagement they have with their communities. INTRODUCTION: In order to guide our exploration of the roles of bots in Twitch communities, we aim to answer the following research questions for a number of different types of communities on Twitch: INTRODUCTION: (1) How frequently do bots send messages on Twitch? (2) What kinds of language do bots on Twitch use, and for what purposes? (3) What do bots and users say to each other? INTRODUCTION: The first of these questions addresses whether bots on Twitch are active participants in social spaces, placing their social dynamics in conversation with prior work . The second question supplements previous work that identified patterns of bot language in different contexts, e.g., a particular subreddit . While some work has looked at users' desired features for bots in community-style social platforms , most language-specific analysis of bots has been done on networked spaces like Twitter, or specific spaces on a single platform. Here we analyze the full breadth of communities on Twitch, identifying ways that bot usage varies across types of communities. The third question addresses the complexity of human-bot interactions on Twitch. Prior work has found that bots have had a variety of roles, both in completing particular automated tasks (e.g., ) and in holding human-like conversations with users (e.g., ), and in this work we aim to situate Twitch bots in this space. We answer each of these three questions across different sizes of communities and across communities built around different types of content, identifying how community characteristics contribute to bot behaviors. INTRODUCTION: We begin this paper with a brief description of the Twitch platform and then review relevant work. Next we describe prior research that has identified roles among humans online, focusing specifically on the methods that have been used. Third, we briefly review some of the literature on chatbots online and consider how the methods used to study human roles online might be applied to the study of bots. Following our review of the literature, we identify the functions for which bots have been developed on Twitch and present example interfaces for management of the two most popular and oldest third-party bots on Twitch, which have set the standard for bot designs. In the main section of this paper we quantify the influence of bots on conversations using methods influenced by structural role theory and based on prior analysis of human roles to identify what bots types of messages send, how frequently they send each type, and how much they interact with regular users. We conclude with a discussion of opportunities for further development of bots' social roles on Twitch and beyond. INTRODUCTION: The Social Roles of Bots 157:3", "relatedWork": "", "rq": ["(1) how frequently do bots send messages on twitch?", "(2) what kinds of language do bots on twitch use, and for what purposes?", "(3) what do bots and users say to each other?"], "id": "dev_24"}
{"intro": ": The Internet promotes a public sphere where people gather to exchange ideas, form opinions, and mobilize social movements . Discussions in online chat spaces like Messenger, Telegram, and WhatsApp allow people to share different perspectives and opinions, free from time and place constraints. In certain online chat spaces, the guarantee of anonymity can facilitate greater openness about opinions and experiences . Because of these advantages, online chats have emerged as a channel for discussing diverse social issues and driving social change . INTRODUCTION: However, the fact that these spaces can host discussions does not guarantee that they will properly function as a segment of the public sphere . A long history of empirical work has shown that rational debate and deliberation do not always occur in online discussions. Many people do not actively participate in discussions . People join groups and seek information consistent with their own perspectives, which can make it difficult for them to understand or respect others' contrasting viewpoints . Due to these problems, consensus-reaching can be difficult in online discussion . Despite the above, consensus reaching is highly important for situations in which a society is required to make a decision regarding an issue with major social consequences (e.g., How should self-driving cars make decisions in complicated situations?, Who owns the copyrights for AI created art?, What kind of harmful online content should be moderated?) . It benefits both community members who have a stake in the outcomes of these decisions and society as a whole if a consensus is reached through iterative and deliberative discussions that are perceived as legitimate and fair , and attempts at such a discussion are referred to as 'society in the loop' . INTRODUCTION: Existing studies tend to pay attention primarily to discussion results, which are measured on the basis of whether or not a consensus has been reached. This perspective leads discussions toward being regarded as a means of obtaining a majority consent . However, rather than the mere results of a given consensus, there are significant elements which constitute deliberative discussion including authenticity, substantive balance, diversity, and reasoning processes . Thus, in this work we do not assess the success or failure of a discussion based on whether an agreement has been arrived at, instead distinguishing between deliberative consensus and mere agreement. We investigate whether the discussion includes both a deliberation process that matches the above criteria and an outcome where discussants actually agree with or concede to a consensus (authenticity) . INTRODUCTION: The HCI and CSCW community has explored methods for prompting constructive and balanced discussion. Previous studies have developed systems to enable reasoned argumentation and a balanced and valid perspective and to help human moderation . Furthermore, a multi-turn argumentation system for crowd workers has been shown to improve data accuracy along with worker engagement . Our work draws inspiration from this prior work, building on findings related to effective discussion facilitation, but translates these findings into the integration of a computerized \"facilitator\"-a conversational agent-into a discussion platform rather than transforming or adding elements of the platform's front-end interface. We treat this chatbot as a member of the host community . In line with recent work , we argue that chatbot agents can foster positive group dynamics by playing specific social roles that human agents may not want to perform or may be naturally disadvantaged in performing relative to a chatbot. INTRODUCTION: What role can chatbot agents play to promote deliberative discussion? Unlike official discussions managed by professional moderators , many informal discussions between people with common interests in online spaces take place without moderators, i.e., group chats or chatrooms. In situations where a moderator might have been able to manage a heated conversation, the absence of such a moderator can intensify the natural drawbacks of unstructured, unthreaded discussions . Moreover, absent a moderator monitoring a discussion, the right or power to speak may not be evenly distributed among the participants , potentially leading to a \"spiral of silence\" . Moderators distributing the right to speak and structuring discussion may induce more even and active participation , given a shared group goal of achieving consensus, enabling more effective deliberative discussion and allowing groups to reach a more authentic consensus. INTRODUCTION: In this paper we present findings from the process of designing and testing a chatbot to facilitate deliberative discussion. We propose \"DebateBot\", which is designed to (1) structure discussion and (2) request opinions from reticent discussants. DebateBot structures discussion based on the thinkpair-share framework, which helps to maintain opinion independence and strengthen reasoned arguments (Figure 1 : S1-5) . It also encourages participation from lurkers and thus can solicit a broader variety of opinions (Figure 1 : F1-3). INTRODUCTION: In our tests we focused on discussion topics related to ethical dilemmas (i.e., the trolley problem of self-driving cars and the rights of AI), in which consensus-reaching and deliberative discussion are requisite. We predicted that the chatbot agent could facilitate deliberative discussion by encouraging more active and more balanced participation, greater opinion diversity, and clearer arrival at a mutually agreed-upon consensus. To evaluate the feasibility of the chatbot agent, we conducted a 2 (discussion structure: unstructured vs. structured) \u00d7 2 (discussant facilitation: unfacilitated vs. facilitated) experiment. In the structured condition, the chatbot agent structured discussion to encourage independent thinking and facilitate members' understanding of different perspectives using methods based on prior research including a think-pair-share strategy . Participants in the unstructured condition engaged in free discussion without a predefined format. In the facilitated condition, DebateBot encouraged participants who had been less involved in the discussion to express their opinions; this intervention did not occur in the unfacilitated condition. We ran experiments with 12 groups of five or six members each (N = 64). We measured deliberative discussion based on authentic consensus reaching (discrepancy between group's and individual's opinions), group behavior (active participation, even participation, lexicon diversity), and discussants' attitudes (opinion alignment, opinion authenticity, communication quality, and usefulness). We also collected and analyzed users' qualitative feedback. INTRODUCTION: We found the following: INTRODUCTION: \u2022 In general, a chatbot-moderated discussion structure positively affects the quality of the discussion. Facilitating lurkers to speak drives increased opinion alignment, equality of contribution, and group members' perceived satisfaction. \u2022 There was no difference in the overall magnitude of participation across the four conditions, but the distribution pattern of participation was different. Participants in the facilitated group participated more equally in the discussion. INTRODUCTION: \u2022 Participants in structured discussions produced more diverse opinions (i.e., lexicons), generating a breadth of opinions. However, discussant facilitation did not accelerate this effect. This might be because one group, under the facilitated and structured condition, exhibited a unanimous prior opinion; this may have prevented the emergence of diversity. \u2022 In the facilitated and structured discussion condition, the highest proportion of participants reported that the group's consensus matched their personal opinions, resulting in authentic consensus reaching. INTRODUCTION: Based on these findings, we discuss the design implications of the online chat system for deliberative discussion. The main contributions of this work are as follows: INTRODUCTION: (1) We present a chatbot that we designed and built to enable deliberative discussion by structuring discussion and facilitating even participation. We demonstrate that the agent can perform the role of moderator in the group discussion process. (2) We present findings from an evaluation of deliberative discussion in terms of active and even participation, opinion diversity, and authentic consensus reaching based on behavioral log data, finding significant impact from the use of the chatbot agent. (3) We discuss the implications of a chatbot agent that can facilitate online discussion and present considerations for future work. INTRODUCTION: It should be noted that the work we present here may not be appropriate for certain sensitive and divisive issues such as racial, sexual, religious, or political topics, as the power dynamics and emotional intensity of these topics could be beyond the facilitation capabilities of the system we present here ; for some topics within these categories, it is unclear whether a negotiated consensus is even the desired outcome . For these topics, a more specialized intervention may be required.", "relatedWork": ": This study aims to explore the feasibility of a text-based chatbot agent as a moderator in online discussions. We first look at how and where chatbots have been applied, then identify their advantages over other systems. Next, we explore the factors that enable deliberative discussion and their effects in face-to-face and computer-mediated contexts, and discuss how these may be integrated into the design of the chatbot agent. Chatbots in Group and Community: Research related to chatbots has mainly focused on dyadic chatbots, where users and chatbots have one-on-one conversations. Studies related to dyadic chatbots have focused on their applicability to various domains such as health care , customer support , news consumption and user research . The effectiveness of dyadic chatbots has mainly been assessed by manipulating message-level variables such as conversational style , empathic responses , typeface , and self-disclosure . Recent research has explored potential roles for chatbots in multiparty interactions involving groups and community interactions . Multiparty chatbots can play a role in a group by performing specific functions. For example, a task assistance chatbot can automate routine tasks. They can arrange group schedules , manage tasks , and help collaborative information-seeking . Chatbots in Group and Community: On the other hand, in addition to these task-based agents, chatbots also perform social roles by engaging in group dynamics and interacting with group members. In empirical research, researchers identified the social role of bots on the Twitch community, such as engaging users and running mini-games . An analysis of14,822 comments on Reddit community revealed that bots are seen to perform functions including administration of content (e.g., scheduling and automization of postings), provision of fun (e.g., playing of games), ensuring functionality and quality (e.g., translating language), supporting community (e.g., pre-banning black-listed users, welcoming new comers), and archiving . Experimental work has shown that chatbots that promote discussions in social chat groups by encouraging reticent members to speak and organizing opinions have helped members contribute more evenly to the discussion, leading to improved satisfaction . In another study, compared to a voice-only agent, an embodied agent had a positive effect on the interaction between group members by conveying a sense of presence . Finally, in another study that used research-through-design methods, a chatbot raised and grown by a community changed the way members interacted, and eventually the chatbot became accepted as a community member . Chatbots in Group and Community: These studies provide solid evidence that a chatbot can shape a group or community by playing a particular social role. So far, however, too little attention has been paid to how to apply these types of chatbots for deliberative discussions. If the lack of a moderator hinders deliberative and productive discussion , we might ask whether a conversational agent can partially perform the role of a human moderator, leading to a more deliberative form of discussion. Moreover, conversational agents can more deeply permeate group dynamics than many other interfaces due to their interactive and integrated nature. This integration has driven our decision to choose a chatbot as the format for an intervention into deliberative discussion, as we believe that the effects of a given approach may be greater when presented through a virtual agent than in a more socially-distant front-end interface. In particular, adding a single agent in a situation where multiple parties interact (as in a discussion) can be more intuitive and comfortable than adapting to a new interface. Based on the applicability and advantages of chatbots in the group interaction context, this study explores whether they can promote deliberative discussion. Structured Discussion: Structured discussion enables deliberation by promoting reasoned arguments , reducing deviation from the topic , and enabling independent thinking . In deliberative discussion, it is crucial to support claims with both evidence and reasoning and to understand other participants' opinions before engaging in full-scale debate . While it is easy to express opinions spontaneously without elaboration in many online contexts, constructive discussion is only possible if arguments are based on solid rationales established prior to the discussion . This is consistent with Cohen's concept of reasoning, an important component of deliberative democracy. Cohen stated that in deliberative discussion, arguments must be based on reasonable and logically sound evidence. High-quality discourse can be achieved and rational decisions can be made when debaters conduct discussions based on reason and proceed with debate in a structured manner , particularly when independent judgments are encouraged rather than overshadowed by majority opinion (groupthink) . Structured Discussion: A number of studies applied structured discussion to facilitate online group communication by introducing multiple stages by, for example, allowing users to exchange opinions and achieve goals productively by conducting discussions in an order provided by the system. LeadLine enables structured discussion by allowing people to create predefined scripts . LiquidFeedback introduces four stages--admission, discussion, verification, and voting--to support online deliberative processes for policy-making . SolutionChat provides a flexible structure that allows moderators to use a personalized structure and control step transitions . These studies provide supporting evidence for the effects of structured discussion. However, these studies have structured the discussion at the level of the graphical user interface, and none has verified the feasibility of a conversational agent that structures a multi-stage discussion like a human moderator. Designing the stages of deliberative discussion that enable reasoning into the protocol of a chatbot can facilitate deliberative discussion. In synchronous discussion, chatbots can structure discussions by guiding discussants to the discussion stages considering a predetermined time. Equality and Diversity: One of the basic elements of deliberative discussion is that every participant has equal standing . Deliberative discussion requires an equilibrium of substantially equal opportunities for people with different perspectives to present their opinions . However, it is often observed that equal participation does not often occur in online spaces. The influence of minority opinions can be repressed, and decision-making can be dominated by influential users; online discussions with a more democratic power balance can be difficult to hold . Equality and Diversity: Unequal participation in online discussions can have two interrelated consequences: a \"spiral of silence\" and social loafing. When a person is on the side of a minority opinion, a spiral of silence can arise because of fear of receiving bad evaluations or being isolated from others . Since expressing opinions is a social act that reflects a social climate and not simply an independent action, it is possible to express agreement with dominant opinions even when they are not in accord with individual opinions. Social loafing, or a reduction of individual input, can occur when users are collaborating in a group, particularly when incentives to contribute are low . In this case, a form of social loafing may occur when a user believes that there is little reason for them to contribute to a deliberative discussion. Reducing individual input within a group lowers the motivation of other members and has a long-term negative effect on the group and organizational level . Equality and Diversity: Although uneven participation among the users has been criticized as an obstacle to positive group dynamics, far too little attention has been paid to solving this problem using technology. Our design aims to overcome these challenges by encouraging members who are less involved in discussion to express their opinions. We incorporate this principle into the design of the chatbot, allowing it to identify members in real time who are passive in expressing their opinions and encourage them to participate, potentially leading to a greater diversity of opinions and making arrival at a representative understanding more likely. Thus, we focus on the following research questions: Equality and Diversity: \u2022 RQ1. How can a chatbot be designed to facilitate deliberative discussions? \u2022 RQ2. Can a chatbot designed to structure discussion and facilitate discussants have a positive effect on the deliberative discussion in terms of consensus reaching (behavioral and perceived opinion alignment), opinion expression (active participation, even contribution, outspokenness), discussion quality (lexicon diversity, deliberative quality), and discussant satisfaction (task cohesion, communication efficiency/fairness/effectiveness)?", "rq": [" rq1. how can a chatbot be designed to facilitate deliberative discussions?", "rq2. can a chatbot designed to structure discussion and facilitate discussants have a positive effect on the deliberative discussion in terms of consensus reaching (behavioral and perceived opinion alignment), opinion expression (active participation, even contribution, outspokenness), discussion quality (lexicon diversity, deliberative quality), and discussant satisfaction (task cohesion, communication efficiency/fairness/effectiveness)?"], "id": "dev_25"}
{"intro": ": In the recent big data era, scientific experiments need to handle massive amounts of heterogeneous data . While data-intensive experiments open up the possibilities for interesting discoveries (such as through statistical analysis and applying advanced machine learning algorithms), there are several challenges with complex, data-intensive computation and the analysis process, including dealing with failure handling, optimal task scheduling, big data visualization, distributed job execution and real time execution monitoring . The effective analysis and management of complex, multi-dimensional, and high volume data is challenging for an individual and often requires collaboration with multiple scientists . In any case, scientific research often demands collaboration among scientists from multiple domains and with diverse expertise . INTRODUCTION: Given the collaborative nature of modern complex scientific experiments, recent research identified Computer-Supported Collaborative Work (CSCW) technologies as necessary to support scientific experiments that require collaboration among multiple researchers . Jirotka et al. determined that, while the relationship between scientific experiments (i.e., e-Science) and CSCW is relatively nascent, they together could yield significant benefits in answering complex research questions and in important knowledge discoveries . With this motivation, we studied the concept of collaboration or groupware systems in the context of Scientific Workflow Management Systems (SWfMSs) for aiding with complex scientific experiments among multiple scientists via realtime collaboration. In this paper, we present several challenges and differences with collaborative SWfMSs in contrast to text or graphics editing groupware systems, and present a general framework for collaborative SWfMSs that leverages CSCW technologies to support scientific experiments. INTRODUCTION: A scientific workflow is a facilitation or automation of a process as a part or whole during which the targeted data are passed from one computational step to another for certain actions or processing as per some set of pre-defined rules or instructions . A SWfMS automates a scientific workflow life cycle: composition, deployment, execution, and analysis , which is discussed in detail in Section 2. While SWfMSs are widely used in recent years for handling and managing the overall execution of complex scientific experiments , none of them directly support collaborative work among multiple users; hence users need to follow several time consuming manual steps for any required collaboration on a given data analysis task . For example, for a collaborative design of a scientific workflow, a user first builds a part of a workflow (e.g., a sub-workflow), exports it from the local workflow engine and shares it with a collaborator for possible updates on the sub-workflow. Around 3910 such scientific workflows have been shared among 10665 members (as last noted in August 2018) for collaboration in myExperiment a shared social space for scientific artifacts. The manual collaboration process is repeated a number of times to complete building the entire workflow comprising of several sub-workflows. This manual back and forth process for collaboration is often very time consuming, does not support real-time editing, and is often impractical as the collaborating group size increases over time. INTRODUCTION: While the above statistics and scenario reveals the importance and necessity of collaborative SWfMSs, designing a real-time groupware system for workflow collaboration is non-trivial and differs from text or graphics editing groupware systems in a number of ways: i) Different Roles, scientific experiments often require adequate access control policies for sharing the workflow components, data products and provenance information among researchers with varying roles and in the context of scientific data analysis, the varying roles might include domain user, pipeline composer, tool developer, data specialist, and so on depending on a given use-case scenario (we present further details on varying roles in Section 5.3); ii) Collaborative Job Scheduling, collaborative job scheduling is required to orchestrate and efficiently schedule the independent workflow execution requests of researchers ; iii) Collaborative Job Management, in addition to the primary requirements of workflow job execution, monitoring, or failure handling, collaborative SWfMSs need to have a feedback system to orchestrate the overall data analysis process among the collaborators; iv) Plugin Architecture for Collaboration, for effective collaboration among research groups, a collaborative SWfMS must allow easy and real-time plugins of workflow tools; and, v) Collaborative Data Visualization, a collaborative SWfMS should facilitate collaborative data visualization to fully exploit collaborative data analysis. INTRODUCTION: To address these challenges and requirements, we present a framework towards an effective design of a collaborative SWfMS for scientific data analysis. Our proposed framework adopts a plugin based architecture for workflow tools. As a proof of concept of the proposed framework, we also implement a collaborative SWfMS SciWorCS. As our proposed framework is not restricted to any particular research domain, we evaluate it with use-cases from two different research areas Designing Groupware Systems to Support Complex Scientific Data Analysis 9:3", "relatedWork": ": In this section, we first present related work on CSCW in aiding with scientific experiments (i.e., in Section 3.1), and we then discuss recent work for supporting collaborative data analysis with SWfMSs (i.e., in Section 3.2). CSCW to Support Scientific Experiments: Several recent researches assert the necessity of CSCW in supporting complex scientific experiments that require collaboration among multiple researchers . Jirotka et al. from their investigation studies presented that, while the relation of scientific experiments (i.e., e-Science) and CSCW are relatively nascent one, they exhibit significant potentials in answering complex research questions and in important knowledge discovery . Hence, over the past few years several research studies have been conducted in understanding human behavior . Besides some of the study targeted on discrete aspects of collaborative data analysis systems, such as consistency management or locking schemes . However, to the best of our knowledge none of the previous study addressed the overall architecture comprising different primary requirement or components for a collaborative data analysis system. Hence, our study and proposed architecture is different than the existing studies in the sense that we formulate the discrete research problems towards designing an overall architecture towards collaborative data analysis. CSCW to Support Scientific Experiments: A number of studies have been conducted in recent years for gaining in depth understanding of Designing Groupware Systems to Support Complex Scientific Data Analysis 9:5 scientific work practices, such as how scientific experiments are conducted, how research artifacts are shared, and how scientists interact with tools and technologies . While such investigations often target different areas (e.g., the Electronic Medical Record (EMR) and Breast Cancer Screening ), they generally aim to provide important insights into the challenges and design implications of CSCW systems for collaborative scientific experiments . As we are proposing a high-level architecture for a collaborative data analysis platform, the insights from the previous studies are useful for identifying the requirements to integrate with our proposed architecture and towards designing a domain specific collaborative data analysis platform for EMR, Breast Cancer Screening, and so on. Towards Collaborative Data Analysis: A Scientific Workflow Management System (SWfMS) automates the process of life cycle phasescomposition, deployment, execution, and analysis of a scientific workflow . Large-scale scientific experiments often take advantage of SWfMSs for modeling the overall data analysis and manipulation process comprising of different computational steps for input data loading, transformation, aggregation, and so on where SWfMSs provide the framework for supporting the specification, modification, execution, failure handling, and monitoring of the data-intensive tasks . With the increase of data complexity and volume, extensive research has been done in this domain resulting in a number of proposed SWfMSs architectures and corresponding implementations. Some of the modern popular SWfMSs are: Galaxy , Taverna , Kepler , Towards Collaborative Data Analysis: Pegasus , VisTrails , Triana , VIEW , Chiron , and GridNexus . However, to the best of our knowledge none of the SWfMSs supports collaboration directly and so require manual effort in contrast to our proposed architecture for supporting real-time collaboration for data analysis and scientific experimentation. Lu et al. studied several motivations and opportunities for collaborative SWfMSs from the perspective of large-scale and multidisciplinary research projects. A number of methods have been proposed for consistency management of shared workflow in a collaborative environment. Zhang et al. studied the concept of a turn based locking scheme in the context of collaborative SWfMSs for facilitating consistency management. In such a setup, each collaborator generally has only Read access to the shared workflow. Collaborators request and compete for the floor for carrying out any update or transaction on the workflow (e.g., Read & Write access). Fei et al. and Zhang et al. presented locking schemes by allowing only descendent module locks (e.g., descendent nodes of the workflow DAG ). Towards Collaborative Data Analysis: Sipos et al. used two lock modes -User and System locks. Fei et al. proposed a lock compatibility matrix for a set of six pre-defined modes of locks. Besides, techniques have also been studied for extending the single-user Grid portals to a collaborative environment . Towards Collaborative Data Analysis: While the locking schemes for consistency management is one of the primary requirements of a collaborative system , the requirements of collaborative SWfMSs are often more than that . For example, those studies did not consider several important aspects such as collaborative job scheduling, collaborative job execution, collaborative visualization, and user interaction for problem solving. Hence, in our study we addressed those requirements as well for a successful collaborative data analysis platform, which can significantly contribute towards further improvement in the research domain. Towards Collaborative Data Analysis: Table 1 provides a summary of the proposed architecture in comparison to some of the existing related research. The table shows that, while existing research targeted different discrete components, our proposed architecture addresses all of the primary requirements towards the effective design of collaborative data analysis platform.", "rq": [" rq 1: how can we design collaboration in scientific workflow management system?", " rq 2: how can we implement a real-world collaborative swfms that is functional and performant by supporting consistency management, sub-workflow execution, visualization in various formats and so on?", "rq 3: how can we utilize our collaborative platform for different scientific analysis domains?", "rq 4: how does the proposed architecture impact the network overhead?", "rq 5: how do scientists perceive real-time collaboration in data analysis?"], "id": "dev_26"}
{"intro": ": Previsualization (previs) is a collaborative process of planning scenes and shots within the pre-production stages of filmmaking. Traditionally, this process has been performed with drawings, concept images, sketches, etc. , and it is not until recently that previs has been performed with 3D animation tools and software. The use of computer graphics-based (CG) technologies for providing visual effects within filmmaking is a well-established practice. However, the costs of these technologies are substantial, therefore it is important to carefully plan shots that require the expertise of CG professionals . With recent advancements in Virtual Reality (VR) technologies, the film industry sees a shift where planning for different scenes and takes can be done in a more immersive and tangible way. VR enables a user to be present in virtual environments resembling specific locations, and thus may help filmmakers to work creatively in a familiar setting. Furthermore, remote work is becoming increasingly common in the film industry and VR can be the ideal solution to foster collaboration within these settings. The advantage of using online multi-user VR is that it may enable a sense of being transported to real environments where co-workers can socially immerse with their colleagues. Remote collaborative previs may thus not only be an important tool for creativity and communication, but also for saving the time, expenses and environmental costs of travelling. INTRODUCTION: The main research question addressed in this paper is: How useful and familiar can VR technologies be for remote collaboration in previsualization? INTRODUCTION: To research this topic, we describe and evaluate a tool that provides an immersive and collaborative previs environment where filmmakers can create, discuss and validate different takes, shots and entire scenes. The tool features a VR interface where the intended users do not need advanced computer literacy to understand and master the functionalities. A within-subjects experiment was conducted, where the participants (professional filmmakers, primarily from the Stockholm Academy of Dramatic Arts) performed previs sessions in the proposed collaborative setup and in a control solo setup. In this paper, we analyze the results from our experiments to assess the impact of, and provide design insights on, remote collaborative VR technology that enables previsualization of film scenes.", "relatedWork": ": In face-to-face interaction, communication can be achieved in a delay-free and multi-functional way, as is explained in , where Clark and Brennan claim that grounding, i.e. finding common ground, is important for how communication works effectively. Thus, the costs of constraints of mediums can affect formulation, production, and understanding. Collaboration calls for similar grounding as for general communication in order to work effectively. The importance of shared visual space, mental models, context, and speech is evident in earlier research , where the context and understanding of how to collaborate and what to collaborate on can be made clear. In , Fussel, et al., accounts for four types of visual information that is important for grounding in collaborative contexts: participants' heads and faces, participants' bodies and actions, shared task objects, and shared work context. Similarly, having a shared visual space in collaborative work environments makes participants' more likely to let their actions speak for themselves instead of having to explain verbally, simultaneously . RELATED WORK: Technological solutions for remote collaboration have taken many different forms. From letters, telephone, video-conference systems to more advanced forms of technology that are now starting to show potential for creating efficient and natural forms of collaboration . However, most of these authors also claim that the lack of developed technology can hinder good collaboration. Poor field-of-vision in interfaces and lack of asymmetry in controls are two examples of how the design of technical solutions could have been standing in the way of usable interfaces for interactive collaboration . This is something that VR technologies can be better suited for, as the immersive qualities of virtual headsets and its controls are extensive enough to facilitate grounding in collaborative environments. Advances in VR technologies has led to decreased prices and a more widespread usage of the technology , which might represent clear opportunities for remote collaboration purposes. VR can be seen as a way of achieving near perfect co-presence with other people . Co-presence is an especially important aspect for attaining grounding in virtual 3D environments . However, there are still problems with VR that prevents the medium of fully delivering on the promise of full copresence. In , Anthes et al., raises a number of issues on the state of VR technologies. It is clear that representation of users is still a problem as a result of lack of information on facial expressions, eye-gazing, and body movement. Nevertheless, recent advancements are attempting to tackle these problems with the use of eye-tracking inside VR headsets, gloves that can represent fingers, etc. Thus, user representation is likely to improve in the near future . As such, the affordances of elements in a VR environment needs to be carefully decided upon, when designing for VR. In , Ellis makes clear that affordances in VR should mimic the real world as much as possible, as the affordances of real artifacts are expected to have the same affordances in the virtual environment. Furthermore, in the virtual environment, extended affordances can be developed, as the virtual environment can in its nature facilitate this . RELATED WORK: In this paper, we focus on designing collaborative VR technologies that enable previsualization, a pre-production stage within filmmaking. Previsualization is a process where filmmakers create visual prototypes of scenes in a film that are otherwise difficult to visualize. Different use-cases are e.g. scenes with visual effects, expensive set constructions or digital set extensions. While hand-drawn floor plans and storyboards are still the dominating previsualization technique within creatives, high-budget productions commonly make 3D animated visualizations of the film, predominantly using 3D modelling and animation software such as Autodesk Maya 1 or Blender 2 . However, this process is not only time consuming and costly, it also delegates creative control over the previs to external animators. The possibilities to use real-time technologies such as game engines to provide more interactive and user friendly interfaces have been attempted before. The main promise of such technology is the ability for the creative team of a film-production to create the previs by themselves. In the work by , a previs system was implemented using Unreal engine together with various custom built input devices for puppeteering characters and camera. The study argues that animation and camera control are the most important areas for previs. Several other studies have explored Mixed Reality (MR) interfaces for previs. These interfaces are however restricted to camera work (although has basic key-framing functionality), and and thus does not exploit the possibilities to previsualize character movements in real time. RELATED WORK: In , a VR previs system is presented where the user can create low resolution animations by adding and editing key frames on a timeline. The system used a rotation sensing headset (Oculus DK2) and a game pad for input, which limits the immersion and familiar interaction mechanisms included in later hardware. The system closest to ours is presented in . By evaluating their system on 6 expert users from film and theater (surprisingly none being a director or photographer), they found that their tool was practical for real-world applications. Like us, Muender et al., uses room scale VR with positional tracking, and a miniature approach where the users move scale models and cameras. Unlike us, they only create snapshot still-images of stiff characters, and they do not use a collaborative setting. We will contribute to the state-of-the-art in this field by performing a larger study with a greater number of film professionals, and by investigating the usefulness of distributed collaborative previs in VR.", "rq": ["the main research question addressed in this paper is: how useful and familiar can vr technologies be for remote collaboration in previsualization?\n it can be argued that the reason for why some participants enjoyed and preferred the solo condition to a slightly higher extent could have been due to several effects: how well the participants knew each other?"], "id": "dev_27"}
{"intro": ": Remote collaboration technology can enable a user at a local work place to quickly receive help from another expert user in a remote location. For example, a video call allows the remote guest user to quickly understand the situation of the local host user. In remote collaboration it is important to consider how the local host user can capture and broadcast a view of their surroundings. However, video calls have many limitations such as sharing a small field of view (FOV), limited resolution, or fixing the view of the remote guest user to that of the local host user. To overcome such limitations, it could be more efficient if the remote guest user could immerse themselves in a view of the local host user's environment. Virtual Reality (VR) technology enables this by having the user wear a Head Mounted Display (HMD) that provides an immersive viewing experience with a wider FOV compared to a standard phone or monitor. INTRODUCTION: Using VR technology, 360 views of the surroundings can be shared from a panorama camera. Alternatively, other systems allow sharing a 3D reconstruction of a real world scene using a depth sensor and/or photogrammetry. Both of these techniques allow sharing the local host user's environment to a remote guest user, but each has some limitations. Sharing 360 panorama views can provide a high quality view without consuming a large amount of bandwidth but it is a 2D presentation that provides limited depth perception. In contrast, sharing a 3D reconstruction supports depth perception as well as the ability to navigate through the 3D model. However, the quality of 3D reconstruction and the amount of bandwidth required to transfer it are directly proportional to each other. So a high-quality 3D reconstruction of the user's environment would require a significant amount of bandwidth and is difficult to update in real time. INTRODUCTION: In this paper, we present a novel Mixed Reality (MR) remote collaboration system (see Figure 1 ) that combines 360 and 3D reconstructions into one. This creates a system that aims to merge the advantages of the individual approaches while minimizing the limitations stated above. INTRODUCTION: Compared to prior work, this paper makes a number of novel and significant contributions: INTRODUCTION: (1) A novel MR Remote Collaboration technique that merges 360-views and 3D Reconstruction. (2) The first user study that compares 360 live panorama and 3D reconstruction based MR remote collaboration systems. (3) The first user study that explores the benefits and implications of combining 360-view and 3D reconstructed scene into a hybrid MR remote collaboration system.", "relatedWork": "360 Video Sharing Remote Collaboration: Recently, researchers started to explore how 360 panorama camera can be used instead of a standard camera for remote collaboration. This allows the local host user to capture and broadcast the 360 surrounding view to the remote guest user who could turn their head while wearing the HMD. For example, JackIn Head was a remote collaboration system using 6 cameras constantly capturing videos from different angles and processing them into a 360 high-quality spherical video image to live stream to another user wearing an HMD to view. The system is constructed as a headband that allows easy wearability on the head for the local host user. Tang et al. created a 360 video chat system with a similar set up on the local host user side. In their system, they used a 360 camera on a monopod fixed to a user's backpack to broadcast the 360 surroundings to the viewer watching it on a tablet device. Most recently, the Shared Sphere system used a 360 panorama camera attached to a Microsoft HoloLens to capture and share the user's surroundings. With this system, both local host and remote guest users could look around independently while sharing visual communication cues through MR visualisation. RELATED WORK 360 Video Sharing Remote Collaboration: These systems provide easy access to the 360 surroundings of the local host user by the remote guest user, who can look around independently. However, the viewing position of the remote guest user is strictly controlled by the local host user. So the remote guest user will not be able to look at a certain corner of a room or behind any occluded objects by walking closer, unless the local host user goes there.", "rq": ["(1) how does the remote collaboration medium affect the task performance of collaborative object searching task?", "(2) how does the remote collaboration medium affect the user experience including usability, sense of being together, and motion sickness?"], "id": "dev_28"}
{"intro": ": Crowdfunding platforms, such as Kickstarter and Indiegogo, have gained popularity among new entrepreneurs by providing the opportunity to collect funding from millions of common people with almost no initial investment. These web platforms allow entrepreneurs to present their ideas using project descriptions, pictures, and videos. Naturally, video plays an essential role in crowdfunding campaigns, particularly for its storytelling power . INTRODUCTION: While a video is crucial in convincing people to donate for crowdfunding campaigns, creating an appealing video is a challenging task for novice entrepreneurs . Making a professional video involves several elements such as storyline, script, camera movements, editing, post-production editing, and so on. Most importantly, there are many audience persuasion factors, which are critical to optimize when making a campaign video persuasive to the audience. These factors are challenging to apply in videos without professional training in advertising and marketing. Unfortunately, novice entrepreneurs -while experts on their products -often do not even know what factors make a video generally persuasive, much less, what factors would make a video most persuasive for their specific audience. INTRODUCTION: Past research identified many of these persuasion factors that can make campaign videos appealing to the audience . Although these findings are valuable to researchers and advertising professionals, they do not help inexperienced entrepreneurs to effectively optimize their videos. The impact of these factors depends on campaign type, and often, their impacts are not intuitive. For instance, a complex representation of a fashion product is interpreted as evidence of fine craftsmanship by the general audience. Conversely, a video showing the complexity of a technology product, does not work favorably for the campaign. In this case, the audience assumes the product is difficult to use and it negatively impacts their overall impression of the campaign . Without any true guidance or examples of best practices, the implication of such persuasion factors are hard for novice entrepreneurs to understand. INTRODUCTION: Traditionally companies consult advertising agencies for creating persuasive product videos. However, the majority of the entrepreneurs on crowdfunding platforms are beginners and cannot afford such resources due to a limited budget. As an alternative, novice entrepreneurs attempt to learn using past campaign videos as examples, seek suggestions from peers and family members , and look for tips and strategies on the web . Many entrepreneurs depend on free counseling from film experts to compensate for their lack of experience in making videos . Since Kickstarter does not allow creators to search through failed campaigns, novice entrepreneurs even go through third-party tools and blogs to compare and contrast ideas of their campaign videos. Unfortunately, this process can take three to six months of extensive work and can still result in ineffective campaign videos. INTRODUCTION: The goal of this paper is to understand whether and how we can develop assistive tools to help novice entrepreneurs learn how to apply persuasion factors to make effective campaign videos for their target donor audience. To this end, we focused on two main hypotheses based on the literature from HCI, and cognitive and learning science. First, given that novice entrepreneurs have difficulty predicting how combinations of persuasion factors will impact the success of their campaigns, we hypothesize that a tool that assists them in exploring effects of these factors on campaign outcomes through a process of structured interactivity will help them to a) learn the impact of these factors and, b) apply them in making their own videos more persuasive. Second, given that people learn new concepts better by thinking deeply about the concept and by generating materials by themselves, we hypothesize that a tool that guides novice entrepreneurs, in a step-by-step manner, to actively think about the critical aspects of persuasive campaign videos and to generate the planning materials of their videos by themselves will result in more appealing and creative plans for their videos. INTRODUCTION: In this paper, we developed a functional prototype of VidLyz, an assistive web-based tool which consists of the following two modules: an interactive interface module that helps novice entrepreneurs learn the nuances of persuasion factors and enables them to make a comprehensive plan for their campaign video with the help of positive and negative example videos, interpretable explanations and measurement scales of persuasion factors, crowd-sourced feedback, and prediction models towards the success of the campaign (H1). From our second hypothesis, we designed another module, called the guided planning module, that guides novice entrepreneurs to actively think of the campaign video from the perspective of their own target audience and specific product category (H2). INTRODUCTION: To evaluate the effectiveness of the VidLyz tool, we conducted an in-lab user study with 45 participants and interviewed five previous campaign creators with different backgrounds and experiences. The primary objective of our evaluation was the following: 1) whether VidLyz can assist in learning of the implication of persuasion factors and 2) whether this learning can help them make better plans for their campaign videos. To this end, we created two different versions of our VidLyz tool: 1) a non-interactive version (a simple version without any interactive properties or guided active thinking) and 2) a comprehensive version (highlighting the interactive features and incorporating the guided planning module). We also recruited participants in the control group, which included no tool but a list of example campaign videos categorized based on the final outcome (success/failure) of their corresponding campaigns. INTRODUCTION: We randomly assigned each version of the VidLyz tool to 15 different participants and asked them to explore the tool to understand how persuasion factors can impact the effectiveness of campaign videos for prospective donors. In the end, all participants had to make their own plans for a campaign video of their pre-assigned product using a storyboard (a pre-production planning tool widely used by advertising agencies and film makers to make low-fidelity, easily customizable plans for videos). INTRODUCTION: Results show that the comprehensive version of the VidLyz tool helped novice users gain a deeper understanding of the relative importance of the persuasion factors. The combination of the interactive interface and the guided planning module helped participants create coherent and persuasive storyboards for their proposed campaign videos. Overall, their storyboards were suitable for their target audience, which is a key element for an effective campaign video. A follow-up user study showed that crowd workers found the storyboards of the comprehensive group to be persuasive. Finally, semi-structured interviews with participants and five prior and one future campaign owners informed us of the aspects of the VidLyz tool that can be improved in the future to better assist novice entrepreneurs in making their campaign videos persuasive.", "relatedWork": "", "rq": [" rq1: can vidlyz assist novice entrepreneurs in learning about the significance of persuasion factors in making effective campaign videos from example videos, crowd-sourced feedback, and interpretable explanations?", "rq2: can this learning assist them in making a well-structured plan for their persuasive campaign videos?\n(1) what are the challenges you may face in the process of making a persuasive campaign video?"], "id": "dev_29"}
{"intro": ": Meetings are a primary mode of work , but many employees find them frustrating and even counter-productive when good meeting practices are lacking or violated . The violations of general meeting norms and disrespectful behaviors have been shown to be negatively correlated with meeting effectiveness and satisfaction . In 2020, the \"stay at home\" orders and travel restrictions of the COVID-19 pandemic dramatically accelerated the use of the video-conferencing meetings for work. By March 2020, daily usage of video-conferencing services such as Zoom and Microsoft Teams had increased by 300% and 775% respectively, and video-conferencing apps jumped to the top of the Apple app store. 1 Although video-conferencing has the potential to reduce the cost and effort behind organizing travel, space, and scheduling of in-person meetings 2 , the \"fractured ecologies\" of videoconferencing can aggravate negative outcomes and marginalize some members of the meeting . Video-conferencing has consistently presented communicative challenges and introduced distractions which can lead to ineffective and non-inclusive meetings . A primary goal of remote collaboration tools should be to support the most effective meetings possible for all participants. Cutler et al. conducted a large scale e-mail survey on remote meeting effectiveness (N=4,425) at a technology company (pre-COVID- 19 ) and showed that online meeting effectiveness correlates with meeting inclusiveness, participation, and comfort in contributing. They identify a large potential financial benefit to companies that can achieve these goals, and an opportunity to establish and maintain a workplace culture in which everyone feels free to contribute. There are clearly opportunities for technological solutions that assist attendees in feeling more included and improving meeting effectiveness by helping them understand their own and others' core meeting dynamics. INTRODUCTION: This paper reports on an exploratory study with in situ work teams to identify the challenges they face in video-conferencing based meetings, and proposes a post-meeting feedback system to address the issues. In particular, we aimed to provide insights on the following research questions: (1) What aspects of meetings do videoconferencing attendees need help with?; (2) How can we leverage AI systems to make video-conferencing meetings more inclusive and effective?; (3) How should AI-extracted meeting features (including content, behavioral measurements, and sentiment) be categorized and visualized in a feedback dashboard?; and (4) What concerns exist regarding data privacy and accuracy for such systems? INTRODUCTION: Our work addresses these research questions through a series of user studies and design iterations. Via an initial exploratory requirement analysis survey of 120 information workers, we identified the communicative signals (e.g., participation, facial sentiment) which are important in improving meeting effectiveness and inclusion. INTRODUCTION: We conducted a longitudinal user study to record in situ videoconferencing meetings from eight teams over a four-week period. We used the insights from the requirement analysis survey to create a wireframe prototype of a post-meeting dashboard and 16 participants from the user study teams evaluated the design and helped us further refine the components. Finally, we developed an AI sensing system to quantify these meeting dynamics features and created personalized, interactive, post-meeting dashboards for the participants. Through surveys (N=23) and interviews (N=9), we found that participants were able to become more aware of the group dynamics by reviewing the dashboard. Our study shed light on the privacy concerns participants had regarding such insights within the dashboard. The dashboard also helped participants identify and recollect important events of the past meetings. Our findings also showed that participants perceived that the dashboard would improve meeting effectiveness and inclusivity. In addition, participants expressed that actionable suggestions were more helpful than data visualizations alone. The main contributions of this work are as follows: INTRODUCTION: \u2022 We developed MeetingCoach, an AI-driven dashboard that provides both contextual and actionable insights based on meeting behaviors. \u2022 We implemented both behavioral (e.g., participation) and topical (e.g., questions) meeting dynamics features in our feedback system using state-of-the-art AI. \u2022 We identified and implemented shared and private design approaches for different feature components based on users' preferences from two design iterations and evaluations. \u2022 We demonstrated that MeetingCoach helped improve behavioral awareness and recollection of past meeting events, and bears the potential to improve perceived effectiveness and inclusivity. \u2022 We proposed design guidelines explaining the need for actionable suggestions, reminders or highlights based on timing, and multi-modal feature implementations to be adopted for future video-conferencing feedback systems.", "relatedWork": "2.1 Factors in Meeting Dynamics: Meeting effectiveness includes both task processing and interaction efficiency by a team . Dickinson and McIntyre emphasized the importance of goal specification, entailing identification and prioritization of tasks and sub-tasks, in agendas and other meeting resources. Even with clear goals, though, interaction efficiency has a clear impact on both outcomes and satisfaction. Balanced, active, and equal participation have been found to improve team performance . Depending on the type of meeting, equal participation may not always be applicable or feasible, but in a collaborative decision-making discussion, participation from all members ensures at least the exchange of opinions and a sense of \"being heard\", which ultimately improves team satisfaction . Turn-taking patterns also influence team performance and satisfaction, as some members may dominate the discussion without realizing they are doing so, reducing time for other members to voice their opinion or expertise . Lawford found that rapport building through verbal and non-verbal signals was an important factor in effective and inclusive discussions. To ensure coordination and rapport, affect management has been found to play an important role in a team's success . Barsade has shown that a member's positivity can improve the mood of the whole team, making it more inclusive and improving the quality of decision-making. Cannon-Bowers et al. discussed the importance of effective strategy formulation to consider alternative courses of action in case of disagreement or task failure. Non-verbal gestures, through head nodding and shaking, indicate signs of agreement or disagreement, and levels of interest, acknowledgement, or understanding . RELATED WORK 2.1 Factors in Meeting Dynamics: While the face-to-face views of video-conferencing intuitively seem to support the above, they have been found to constrain attention to the non-verbal signals and the overall progress of the meeting . Sellen showed that having video did not improve the interruption or the turn-taking rate for video-conferencing meeting participants compared to audio-only ones. This implies that even though video is important in online meetings, it cannot fully resemble in-person meeting dynamics. Especially during long meetings, additional support for monitoring meeting progress and participation may be needed. Taking into consideration these concerns, we designed and developed an automated feedback system to summarize meeting content and attendee behaviors, with the goal toward improving meeting dynamics over time. Feedback Systems for Videoconference Meetings: Researchers demonstrated the impact of feedback systems on meeting dynamics and discussion outcomes for in-person, text chat, and video-conferencing meeting setups . Feedback on participation , turn-taking , interruption , agreement , and valence , have effectively improved group discussion dynamics. These studies show that the timing (e.g., realtime, post-meeting) and the design (e.g., number of features, visualization strategies) of the feedback are important in effectively modulating collaboration behaviors in a group discussion. Feedback Systems for Videoconference Meetings: Researchers explored feedback systems with affective, behavioral and topical group discussion features. Dimicco et al. presented a real-time, shared-display feedback system measuring speaking contributions from audio recordings, visualized as bar graphs during a co-located meeting. They showed that effective visualization can help improve the group discussion, even though shared visualization can also motivate behavioral changes due to social pressure . Nowak et al. provided feedback on vocal arousal and explored the impact on oneself and one's partners behavior during a negotiation-based task conducted over the phone. They found that real-time feedback can be difficult to process during an ongoing task and can negatively impact user performance. Feedback Systems for Videoconference Meetings: Therefore, even though real-time feedback has been found to be effective in modulating behaviors during a discussion, it can also be distracting and cognitively demanding . Samrose et al. presented CoCo, an automated post-meeting feedback system providing summarized feedback on talk-time, turn-taking, speech overlap and sentiment through a chatbot for a video-conference group discussion. They showed that post-meeting feedback can effectively make successive discussion more balanced. Through a longitudinal study in a video-conference learning environment, EMODASH , an interactive dashboard providing feedback on affective meeting features, improved behavioral awareness over time. Instead of showing numeric or categorical feedback on linguistic features, Tausczik and Pennebaker provided real-time and individualized actionable suggestions in text chat group discussions. Their findings showed that individualized suggestions helped teams shape their behavior; however, too much information in the feedback can be cognitively taxing. Suggestion-oriented feedback has been found effective in behavior modulation , and could be useful post-meeting. As we will later explain, our design incorporated an individualized and suggestion-oriented approach to a post-meeting feedback system. While identifying the feedback features for our dashboard during our requirement analysis, we prioritized features from these prior systems, such as talking time and turn-taking, but with an eye toward reducing cognitive load. Feedback Systems for Videoconference Meetings: Beyond the meeting context, researchers have developed a number of interfaces that allow users to view emotional or affective signals captured by self-report, diaries or sensor-based systems. These have been used in several domains, such as self-reflection , data exploration and information retrieval , stress management , and studying interpersonal dynamics . Data portraits can help people understand more about themselves and other people . However, there is still a lot left to be understood about how to best represent complex and subjective data, such as emotions or group dynamics. Affective data is often highly dimensional, multi-modal, and continuous, all difficult when designing useful visualizations. There are also important privacy concerns raised by creating digital systems and artifacts that encode highly personal information . Feedback Systems for Videoconference Meetings: The feedback needs of organizational teams conducting videoconferencing meetings require special attention, as these teams are relatively stable over time and the members need additional support in tracking the progress and the outcomes of their meetings . As video-conferencing discussions can be prone to distraction and multitasking , we hypothesize that a meeting feedback system that helps members reflect on meeting goals and progress could be a useful tool. Feedback on the non-verbal behaviors can also help with effective and inclusive videoconference meetings. The Matrix to a Model of Coordinated Action (MoCA) presented by Lee and Paine is an elaborate framework that explains a complex collaborative environment by seven dimensions. Within the context of MoCA, the post-meeting feedback dashboard that we propose is characterized as a long-term asynchronous periodic event for small teams placed in different locations. Feedback Systems for Videoconference Meetings: In this study, we observe the meeting challenges and the needs of several in situ work teams, and propose and test technological solutions for them. Meetings have evolved from engaging inperson, to fully computer-mediated (all members join remotely via audio/video/chat), and hybrid (some members join remotely to group/s who are together in person), and each have their distinct character . This study focuses on the fully-computermediated meetings of teams in which all members were remote due to COVID-19's mandatory requirement to work from home. All teams used the same video-conferencing system. We followed an iterative, human-centered design process to address our research questions. Our approach was comprised of two main phases. In the first phase, we performed a preliminary investigation via survey to understand the current challenges and needs for online meetings, and gathered design requirements for our technology probe. Informed by our findings from the preliminary study, in phase 2 we conducted two design iterations through a longitudinal study of actual remote, recurring team meetings. In the following sections, we describe the details of the requirements analysis and the longitudinal studies.", "rq": [" (1) what aspects of meetings do videoconferencing attendees need help with?", "(2) how can we leverage ai systems to make video-conferencing meetings more inclusive and effective?", "(3) how should ai-extracted meeting features (including content, behavioral measurements, and sentiment) be categorized and visualized in a feedback dashboard?\n and (4) what concerns exist regarding data privacy and accuracy for such systems?"], "id": "dev_30"}
{"intro": ": The growing proliferation of wearable sensors that measure biosignals has begun to open new doors for leveraging the real-time measurement of activity such as heart rate, skin conductance, and brain activity, to improve our daily lives. While major inroads have been taken to investigate the implications of physiological sensors for intrapersonal outcomes, such as health management, we are only beginning to see a glimpse of the potential for the sharing of physiological data in interpersonal, social contexts. For instance, step tracking devices such as the FitBit have enabled users to engage in social fitness competitions, while heart rate-sensing smartwatches like the Apple Watch have introduced haptic heartbeat sharing. As new modes and means for sharing and understanding our data emerge, it becomes increasingly critical to understand the implications of revealing our biosignals to 77:2 \u2022 F. Liu et al. INTRODUCTION: others. What are the social and psychological consequences of the ability to share our physiological data? How can we inform system design and policy that account for people's preferences and help them become informed participants in the use of physiological sensing systems? INTRODUCTION: Users of ubiquitous technology already share sensed data such as location and activity streams with others, in order to help them communicate and connect with each other . Shared biosignals similarly have the potential to support interpersonal communication. For instance, biosignals such as heart rate are known to change with our mental states, and have been used in the field of Affective Computing to predict and reduce moods such as stress and frustration in order to increase well-being . Our affective states inherently provide social information about our needs, attitudes, and intentions ; thus, biosignal-based affective technologies could provide new ways to convey this information and support social interactions. By expressing ourselves with biosignals, we have the potential to communicate our subjective experiences, and ultimately better understand and connect with one another. However, little is known about when, to what extent, and with whom individuals are likely to want to share their biosignals. INTRODUCTION: The present work explores one specific implication of ubiquitous physiological sensing technologies: the opportunity they afford for sensed and shared expressive biosignals to serve as social cues in communication contexts. Given the relative novelty of expressive biosignals, and the little empirical work that has investigated their social impact, we take a broad, exploratory approach to better understand how individuals would utilize and respond to a system that allows for the real-time sharing of their physiological responses. Using a combination of Experience Sampling Methodology (ESM) and semi-structured interviews, we investigate users' sharing patterns, including the contexts most likely to trigger or inhibit sharing, motivations underlying sharing decisions, and the communicative and interpersonal consequences of those decisions. We contribute a study that reveals how people share their heart rate through their natural communication channels, finding that heart rate can be used for interpersonal expression of emotion, daily activities, and playfulness, depending on contexts and relationships between users. We present a set of design implications based on our findings that suggest new directions for the development and integration of expressive biosignal systems into social interactions.", "relatedWork": "S 2.1 Biosignals Sharing Systems: A number of systems have been built to sense and monitor biosignals; however, most of these systems have focused on applications for individual use. For instance, popular commercial wearable heart rate monitors, such as the Fitbit or Mio watches, and several research systems have used heart rate to support fitness and physical health . Affective Computing research has expanded biosignals to social applications (in addition to health), detecting emotional and psychological states for social skills training and virtual tutors . However, these applications still target individual understanding and monitoring of physiological data. RELATED WORKS 2.1 Biosignals Sharing Systems: Few works have investigated biosignals systems that allow for sharing in social and communicative contexts. These include systems for supporting interpersonal relationships and collaboration , increasing interactivity and encouragement in physical activities such as marathons , and facilitating engagement in presentations and entertainment . All of these systems focused on very specific use cases and events, and were tested over short periods. Solv\u00e1k and colleagues sought to build on these prior efforts by investigating biosignals sharing in a more natural setting over a longer period of two weeks. They deployed a technology probe (a laptop that provided visual and aural feedback of heart rate) in the homes of five couples and analyzed their reactions to the probe, finding that heart rate was used as information about emotional states and fostered connection between household members . A recent study by Hassib and colleagues expanded this work by going beyond couples' homes and deploying HeartChat, a mobile heart rate chat application, in the wild with seven pairs of close friends or partners. They similarly found that heart rate sharing was able to foster connection and awareness, and that heart rate acted as both an emotional and contextual cue . However, in both of these past works, participants had limited control over sharing, and described situations in which they might not be willing to share heart rate because it was \"too personal,\" awkward, or not understandable. Authors from both works suggest that sharing one's heart rate could thus potentially undermine impression management. RELATED WORKS 2.1 Biosignals Sharing Systems: The present work furthers this line of research by deploying a heart rate sharing system on users' mobile phones in order to understand the everyday contexts in which users are most willing or unwilling to share their heart rate. Our system prompts users to make a decision about sharing in order to give them control over when, with whom, and how to share their heart rate with others. Additionally, sharing is conducted through existing messaging applications in order to provide a natural way through which heart rate can be communicated. Our work allows us to explore heart rate sharing at a deeper level, by investigating not only the contexts in which people would be willing to share their heart, but why they might share or not share:", "rq": ["RQ1: When and why would people be willing or unwilling to share their heart rate with others?"], "id": "dev_31"}
{"intro": ": The growing proliferation of wearable sensors that measure biosignals has begun to open new doors for leveraging the real-time measurement of activity such as heart rate, skin conductance, and brain activity, to improve our daily lives. While major inroads have been taken to investigate the implications of physiological sensors for intrapersonal outcomes, such as health management, we are only beginning to see a glimpse of the potential for the sharing of physiological data in interpersonal, social contexts. For instance, step tracking devices such as the FitBit have enabled users to engage in social fitness competitions, while heart rate-sensing smartwatches like the Apple Watch have introduced haptic heartbeat sharing. As new modes and means for sharing and understanding our data emerge, it becomes increasingly critical to understand the implications of revealing our biosignals to 77:2 \u2022 F. Liu et al. INTRODUCTION: others. What are the social and psychological consequences of the ability to share our physiological data? How can we inform system design and policy that account for people's preferences and help them become informed participants in the use of physiological sensing systems? INTRODUCTION: Users of ubiquitous technology already share sensed data such as location and activity streams with others, in order to help them communicate and connect with each other . Shared biosignals similarly have the potential to support interpersonal communication. For instance, biosignals such as heart rate are known to change with our mental states, and have been used in the field of Affective Computing to predict and reduce moods such as stress and frustration in order to increase well-being . Our affective states inherently provide social information about our needs, attitudes, and intentions ; thus, biosignal-based affective technologies could provide new ways to convey this information and support social interactions. By expressing ourselves with biosignals, we have the potential to communicate our subjective experiences, and ultimately better understand and connect with one another. However, little is known about when, to what extent, and with whom individuals are likely to want to share their biosignals. INTRODUCTION: The present work explores one specific implication of ubiquitous physiological sensing technologies: the opportunity they afford for sensed and shared expressive biosignals to serve as social cues in communication contexts. Given the relative novelty of expressive biosignals, and the little empirical work that has investigated their social impact, we take a broad, exploratory approach to better understand how individuals would utilize and respond to a system that allows for the real-time sharing of their physiological responses. Using a combination of Experience Sampling Methodology (ESM) and semi-structured interviews, we investigate users' sharing patterns, including the contexts most likely to trigger or inhibit sharing, motivations underlying sharing decisions, and the communicative and interpersonal consequences of those decisions. We contribute a study that reveals how people share their heart rate through their natural communication channels, finding that heart rate can be used for interpersonal expression of emotion, daily activities, and playfulness, depending on contexts and relationships between users. We present a set of design implications based on our findings that suggest new directions for the development and integration of expressive biosignal systems into social interactions.", "relatedWork": "S Social Meaning of Heart Rate: Past research has shown that biosignals are inherently ambiguous and open to multiple interpretations , which could subsequently affect the way they are shared. For the purposes of this study, we focus on heart rate, which people tend to associate with underlying emotional and psychological states , yet is known to elicit diverse perceptions of others depending on the context. For instance, Merrill and Cheshire demonstrated that an individual's elevated heart rate is typically associated with negative mood, such as being upset or anxious, which can affect how others trust one another, depending on the situation and relationship with that person . In addition, the heart has been associated with feelings of closeness-for instance, the sound and feeling of one's heartbeat are both considered intimate cues . Solv\u00e1k and colleagues suggest that heart rate sharing could even be seen as a form of emotional self-disclosure, which may only be desired between individuals who have a close relationship . Altogether, these works suggest that the relationship between individuals and the context in which heart rate is accessible plays a key role in determining how heart rate is interpreted and understood by others with whom it is shared, and subsequently how it can be meaningfully expressed through sharing. Our research extends these works by investigating heart rate sharing in a breadth of contexts, giving users the opportunity to decide if and how they want to share to others, as well as how sharers and recipients alike manage or resolve the ambiguity of heart rate. We thus explore the following research questions: RQ2: How can people meaningfully express their heart rate to others? Sharing and Ubiquitous computing: Though research around biosignals in ubiquitous computing tends to focus on individual monitoring, several works in this field have explored the sensing and sharing of other types of user data. For instance, a number of researchers have investigated preferences and practices around location sharing , including sharing behaviors based on hypothetical ESM requests from contacts to share location , and willingness to share with different types of contacts . Other ubiquitous systems have been built to record and share streams of user activity. Ubiquitous healthcare, for instance, is a growing field with multiple areas of application, including activity tracking of elderly people to inform physicians and family of their daily life activities and physiological states . Systems that track and share personal data, particularly physical activity, through social awareness streams like Twitter are also commonly used to connect with friends and family . Some systems have also monitored and publicly displayed user activity levels for the support of collaborative tasks and work Sharing and Ubiquitous computing: 77:4 \u2022 F. Liu et al. Sharing and Ubiquitous computing: environments . However, many of these systems focus on individual sharing behaviors and preferences, and have generally not explored the interpersonal consequences and interactions that might result from sharing. Sharing and Ubiquitous computing: Our work expands on past work on sharing user data ubiquitously by investigating the sharing of physiological data-specifically heart rate sharing on mobile phones in everyday contexts. Further, we consider not only users' sharing behaviors, but also how sharing affects their subsequent interactions with others with whom they share: RQ3: What are the interpersonal consequences of sharing heart rate with others?", "rq": [" rq2: how can people meaningfully express their heart rate to others?"], "id": "dev_32"}
{"intro": ": The growing proliferation of wearable sensors that measure biosignals has begun to open new doors for leveraging the real-time measurement of activity such as heart rate, skin conductance, and brain activity, to improve our daily lives. While major inroads have been taken to investigate the implications of physiological sensors for intrapersonal outcomes, such as health management, we are only beginning to see a glimpse of the potential for the sharing of physiological data in interpersonal, social contexts. For instance, step tracking devices such as the FitBit have enabled users to engage in social fitness competitions, while heart rate-sensing smartwatches like the Apple Watch have introduced haptic heartbeat sharing. As new modes and means for sharing and understanding our data emerge, it becomes increasingly critical to understand the implications of revealing our biosignals to 77:2 \u2022 F. Liu et al. INTRODUCTION: others. What are the social and psychological consequences of the ability to share our physiological data? How can we inform system design and policy that account for people's preferences and help them become informed participants in the use of physiological sensing systems? INTRODUCTION: Users of ubiquitous technology already share sensed data such as location and activity streams with others, in order to help them communicate and connect with each other . Shared biosignals similarly have the potential to support interpersonal communication. For instance, biosignals such as heart rate are known to change with our mental states, and have been used in the field of Affective Computing to predict and reduce moods such as stress and frustration in order to increase well-being . Our affective states inherently provide social information about our needs, attitudes, and intentions ; thus, biosignal-based affective technologies could provide new ways to convey this information and support social interactions. By expressing ourselves with biosignals, we have the potential to communicate our subjective experiences, and ultimately better understand and connect with one another. However, little is known about when, to what extent, and with whom individuals are likely to want to share their biosignals. INTRODUCTION: The present work explores one specific implication of ubiquitous physiological sensing technologies: the opportunity they afford for sensed and shared expressive biosignals to serve as social cues in communication contexts. Given the relative novelty of expressive biosignals, and the little empirical work that has investigated their social impact, we take a broad, exploratory approach to better understand how individuals would utilize and respond to a system that allows for the real-time sharing of their physiological responses. Using a combination of Experience Sampling Methodology (ESM) and semi-structured interviews, we investigate users' sharing patterns, including the contexts most likely to trigger or inhibit sharing, motivations underlying sharing decisions, and the communicative and interpersonal consequences of those decisions. We contribute a study that reveals how people share their heart rate through their natural communication channels, finding that heart rate can be used for interpersonal expression of emotion, daily activities, and playfulness, depending on contexts and relationships between users. We present a set of design implications based on our findings that suggest new directions for the development and integration of expressive biosignal systems into social interactions.", "relatedWork": "S Sharing and Ubiquitous computing: Though research around biosignals in ubiquitous computing tends to focus on individual monitoring, several works in this field have explored the sensing and sharing of other types of user data. For instance, a number of researchers have investigated preferences and practices around location sharing , including sharing behaviors based on hypothetical ESM requests from contacts to share location , and willingness to share with different types of contacts . Other ubiquitous systems have been built to record and share streams of user activity. Ubiquitous healthcare, for instance, is a growing field with multiple areas of application, including activity tracking of elderly people to inform physicians and family of their daily life activities and physiological states . Systems that track and share personal data, particularly physical activity, through social awareness streams like Twitter are also commonly used to connect with friends and family . Some systems have also monitored and publicly displayed user activity levels for the support of collaborative tasks and work Sharing and Ubiquitous computing: 77:4 \u2022 F. Liu et al. Sharing and Ubiquitous computing: environments . However, many of these systems focus on individual sharing behaviors and preferences, and have generally not explored the interpersonal consequences and interactions that might result from sharing. Sharing and Ubiquitous computing: Our work expands on past work on sharing user data ubiquitously by investigating the sharing of physiological data-specifically heart rate sharing on mobile phones in everyday contexts. Further, we consider not only users' sharing behaviors, but also how sharing affects their subsequent interactions with others with whom they share:", "rq": [" rq2: how can people meaningfully express their heart rate to others?"], "id": "dev_33"}
{"intro": ": Virtual conferences are rapidly becoming the dominant medium for online education, remote collaboration, and casual meetings with families and friends. However, gaze awareness is not conveyed accurately in virtual conferences, so it is difcult to determine who is looking at whom from video feeds. Moreover, users often turn of their cameras in video conferences, due to low network bandwidth, shared environments, or concerns about privacy. This leads to similar challenges as for audio conferences, in which people can only see each others' still profle photos. Motivated by these limitations, we wonder: What if we could augment virtual conferences in commodity hardware by using interactive 3D photos to add proper gaze tracking? Prior art such as True-view , GAZE-2 , and Multi-View has leveraged multiple cameras or eye trackers to obtain users' gaze directions and synthesize view-dependent images in video-mediated conversations. Additionally, seminal work such as Photoportals , MMSpace , Sirkin et al. , and TeleHuman has investigated a shared large display, kinetic displays, or a cylinder display to convey gaze awareness in remote group conversations. INTRODUCTION: Besides, commercial software like Memoji 1 and Loom.ai 2 directly map user's facial keypoints to control points of a 3D avatar for enhancing video conferencing experiences. With the recent advances in eye tracking and neural rendering, we investigate the following questions: What if we do not have access to eye trackers and special displays? How can we design a virtual conferencing system to accommodate users' concerns about privacy and limited bandwidth? Can we enhance virtual conferences with gaze-aware 3D photos for a greater level of engagement? INTRODUCTION: Towards these goals, we design, deploy, and evaluate GazeChat (Fig. 1 ), a virtual conferencing system, which conveys gaze awareness with augmented 3D photos. Our focus is on bringing realistic gaze awareness to virtual meetings. Diferent from previous work like Memoji and Loom.ai, we render the relative gaze rather than absolute gaze: rendering the eyes to reveal gaze awareness information rather than just replicating the actual eye positions. GazeChat consists of four components: a WebRTC 3 confguration to support videoconferencing and logging, a real-time eye-tracking module inspired by WebGazer.js to recognize gaze targets, deep-learning modules to infer depth maps and synthesize novel photos by redirecting the gaze, and a rendering module implemented with the three.js 4 . In terms of bandwidth, GazeChat only adds a small overhead of gaze data and a one-time packet of 22 images to conventional audio conferences. INTRODUCTION: To evaluate GazeChat, we conducted four user studies with 16 remote participants (ages 21-38, 7 female and 9 male). In our analyses of video recordings, post-activity questionnaires, and post interviews, we found that GazeChat can efectively engage participants in small-group conversations by visualizing gaze awareness. gaze awareness provides more eye-contact feeling than classic video and audio conferencing, can improve the conversation experience, bring greater social presence and richness, and provide better user engagement than audio conferencing while saving bandwidth and ofering privacy protection compared to videoconferencing. Our main contributions are: INTRODUCTION: (1) Conception, development, and deployment of GazeChat, a virtual conference system that can convey gaze awareness in augmented 3D photos. (2) A low-cost, low-bandwidth, in-situ pipeline to turn users' profle pictures into animated, gaze-aware 3D photos on ordinary laptops without special hardware. (3) Reporting evaluation results and refections about the opportunistic use of GazeChat in virtual conferences (VC)benefts, limitations, and potential impacts to future VC systems. (4) Open-sourcing 5 . Our system is web-based and crossplatform compatible, making it easier to adopt for future research. We plan to make our software available to facilitate future development in VC systems with real-time neural rendering of nonverbal cues.", "relatedWork": ": We review prior art on multi-user experience in distributed collaboration, gaze tracking, gaze redirection technology, and how gaze awareness is integrated into virtual conferences. Multi-user Collaboration in Distributed Environments: Distributed multi-user collaboration has been widely researched from the perspective of locomotion, shared proxies, and lifesize reconstruction, as well as for diferent purposes including communication , presentation , and object manipulation . Your Place and Mine creates experiences that allow everyone to use real walking for locomotion in collaborative VR. Three's Company presents a three-way distributed collaboration system that places remote users either on the same side or around a round table. Besides, Three's Company provides non-verbal cues like body gestures through a shared tabletop interface. Remote users' arm shadows are displayed locally on a tabletop device, which is benefcial for collaborative tasks with shared objects. Tan et al. focus on presentation in large-venue scenarios, creating a live video view that seamlessly combines the presenter and the presented material, capturing all graphical, verbal, and nonverbal channels of communication. The concept of Blended Interaction Spaces is proposed to provide the illusion of a single unifed space by creating appropriate shared spatial geometries. TwinSpace is a generic framework discussing brainstorming and presentation in cross-reality that combines interactive workspaces and collaborative virtual worlds with large wall screens and projected tabletops. SharedSphere is a wearable MR remote collaboration system that enriches a live captured immersive panorama-based collaboration through MR visualization of non-verbal communication cues. Multi-user Collaboration in Distributed Environments: Immersive collaborative virtual environment (ICVE) and Augmented Reality (AR) are widely used to develop new forms of teleconferencing, which often leverages multiple cameras setup and 3D reconstruction algorithms. EyeCVE uses mobile eyetrackers to drive the gaze of each participant's virtual avatar, thus supporting remote mutual eye-contact and awareness of others' gaze in a perceptually coherent shared virtual workspace. Jones et al. design a one-to-many 3D teleconferencing system able to reproduce the efects of gaze, attention, and eye contact. A camera with projected structure-light is set up for reconstructing the remote user. Billinghurst and Kato developed a system that allows virtual avatars and live video of remote collaborators to be superimposed over any real location. Remote participants were mapped to diferent fducial markers. The corresponding video images were attached to the marker surface when markers are visible. Room2Room is a telepresence system that leverages projected AR to enable life-size, face-to-face, co-present interaction between two remote participants by performing 3D capture of the local user with RGBD cameras. Holoportation demonstrates real-time 3D reconstructions of an entire space, including people, furniture and objects, using a set of depth cameras. Gestures are preserved via full-body reconstruction and headset removal algorithms are designed to convey eye contact. Multi-user Collaboration in Distributed Environments: Prior art values the importance of immersion and non-verbal cues especially for eye contact information. Various devices are included such as cameras, markers, big screens, and headsets. We design GazeChat to investigate how we can use minimal hardware to provide essential information for distributed communication. Eye Tracking: There have been extensive research focusing on developing eyetracking devices such as the Tobii eye tracker and on using webcams for eye tracking. Such methods typically involve an explicit calibration phase and are less accurate than infrared eye trackers . One of the early-stage appearance-based methods employed video images for neural networks . Recent work like Lu et al. introduced an adaptive linear regression model that requires sparse calibration however is sensitive to head movement . Later Lu et al. overcame this by using synthetic images for head poses, however, need extensive calibration . Another trend of research takes advantage of image salience to estimate gaze for calibration purposes , and salience is only a rough estimate of where a user is looking. Alnajar et al. designed a webcam eye tracker that supports self-calibration, though still requires users to look at the \"ground truth\" gaze patterns . Similarly, PACE and TurkerGaze also predicts gaze information through webcam. Diferently, GazeChat focuses on providing region-level gaze awareness instead of identifying the pixel-level gaze information. We support adapting webcam-based eye tracking technology for GazeChat use as well as eye-tracking device such as the Tobii eye tracker. Conveying Gaze Awareness in Collaborative Tasks: Buxton started a series work researching shared space in remote collaboration since decades ago , especially discussed how eye contacts behave in such kind of videoconferencing . Sellen et al. present Hydra, a prototype for supporting four-way videoconferencing. Three picture-in-picture devices were used to represent three remote participants. Separate devices also native support diferent view points. Hydra raises the common motivation for conventional videoconferencing and has strong impacts for following work like MMSpace . Additionally, deep discussion on personal space and social space was made and diferent principles were proposed for mediaspace, meaningspace, and meetignspace . Conveying Gaze Awareness in Collaborative Tasks: To better describe gaze information in the context, we use the term \"gaze awareness\" to represent the information we want to convey during videoconferencing. Gaze awareness is related to gaze direction information. It is an ability to perceive an accurate spatial relationship between an observing person and the object, that is being observed . In this work, we focus on gaze awareness related to person. Many prior work visualizes gaze awareness for various purposes. \"An eye for design\" breaks down attributes of eye movements and is inspiring. Eye-write and the follow-up work \"Efects of Shared Gaze\" emphasize the effects of gaze awareness on a shared screen. In the meantime, \"Look together\" enhances collaborative search via gaze. Gaze is a complementary modality to be included in videoconferencing and is efective for multimodal communication . EyeCVE uses mobile eye-trackers to drive the gaze of each participant's virtual avatar, thus supporting remote mutual eye contact and awareness of others' gaze in a perceptually coherent shared virtual workspace. LookAtChat used symbols to show gaze awareness without changing original video feed. Jones et al. design a one-to-many 3D teleconferencing system able to reproduce the efects of gaze, attention, and eye contact. A camera with projected structure-light is set up for reconstructing the remote user. Conveying Gaze Awareness in Collaborative Tasks: Inspired by previous work, GazeChat integrates gaze awareness into virtual conferences as well as separating personal space and social space. We will elaborate on the design and validate the work. Gaze Correction and Redirection: To enable gaze redirection, the traditional approaches are typically based on 3D modeling by ftting eye texture and shape against 3D morphable models, but they are not ideal for handling images with eyeglasses and the high variance of facial details. Some others render a scene containing the face of a subject from a given viewpoint to mimic gazing at the camera. Gaze Correction and Redirection: Various hardware setups have been explored for gaze correction including hole in screen, long distance, and half-silver mirror. The hole in screen concept is about drilling a hole in the screen and placing a camera. Long distance uses a screen at a far distance while placing the camera as close as possible . Half-silver mirror allows a user to see through a half-transparent mirror while being observed by a well-positioned camera at the same time. This idea was adapted in ClearBoard and Li et al.'s transparent display . Despite their advantages in terms of system complexity and costs, such solutions are rarely used outside of laboratory due to the availability of hardware. In the meantime, quite a few 2D videobased (or image-based) approaches are proposed for eye contact including eye correction with a single camera and multiple cameras while applying image-based approaches like texture remapping and image warp . However, the technology was not sufciently accurate to avoid visual artifacts . 3D video-based solutions including 3D reconstruction is another trend for maintaining eye contact while the head is reconstructed. RGB camera , depth camera , Kinect , or motion capture system are used for 3D reconstruction. Eng et al. propose a gaze correction solution for a 3D teleconferencing system with a single color/depth camera. A virtual view is generated in the virtual camera location with hole flling algorithms. Nourbakhsh also used one webcam to apply gaze redirection for one-to-one video conferencing . Compared to single camera setup, multiple cameras are popularly used for providing gaze in videoconferencing. Gaze Correction and Redirection: The deep learning era gave rise to various learning-based methods . These methods mostly train neural networks that predict the fow feld for warping the eye pixels in the original image, and additional techniques such as inpainting and latent space interpolation have been proposed to improve improve the visual quality and redirection precision. However, these methods still fall short of reliably generating to data in the wild, with large variations in head poses, gaze angles, and lighting. A crucial reason for the lack of success for many learning-based method is the limited training data, since it is very difcult to collect a large amount of high-quality eye gaze images with correctly labeled gaze angles. Gaze Correction and Redirection: The First Order Motion model estimates unsupervised keypoints from the input images and predicted a dense motion feld to warp the source features to the target pose. Thanks to its unsupervised nature, this method benefts from a much larger training data set and produces results compelling visual quality. Although it is not specifcally designed for the task of gaze redirection, we manage to repurpose the FOM model to generate the redirected eye gazes at desired angles. Eye Contacts and Gaze Visualization Applied in Video-mediated Conversation: True-view was implemented with two cameras (one on the left and the other on the right). The synthesised virtual camera view image at the middle viewpoint is generated to provide correct views of each other and the illusion of close proximity. GAZE-2 utilizes an eye tracker with three cameras. The eye tracker is used for selecting a proper camera closest to where the user is looking. GAZE-2 prototypes an attentive virtual meeting room to experiment with camera selection. In each meeting room, each user's video image is automatically rotated in 3D toward the participant he is looking at. All the video images are placed horizontally so the video image turns left or right when the corresponding camera is chosen. Likewise, MultiView is a videoconferencing system that supports collaboration between remote groups of people with three cameras. Additionally, MultiView allows multiple users to be co-located in one site by generating a personal view for each user even though they look upon the same projection surface, which they achieve by using a retro-refective material. Photoportals groups local users and remote users together through a large display. All users are tracked and roughly reconstructed through multiple cameras and then rendered within a virtual environment. MMSpace provided realistic social telepresence in symmetric small group-to-group conversations through \"kinetic display avatars\". Kinetic display avatars can change pose and position by automatically mirroring the remote user's head motions. One camera is associated with one transparent display. Both camera and display can be turned to provide corresponding video input image and output angle. Sirkin et al. developed a kinetic video conferencing proxy with a swiveling display screen to indicate which direction in which the satellite participant was looking for maintaining gaze and gestures to mediate interaction. Instead of rendering a video image on a rectangular display, a cylinder display is proposed in TeleHuman with 6 Kinects and a 3D projector. Eye Contacts and Gaze Visualization Applied in Video-mediated Conversation: GazeChat is designed to be used with a minimum requirement of a laptop/PC and a single webcam. While multi-view cameras and external hardware may yield better eye tracking and 3D rendering solutions, such systems typically require very high computational power and exclusive hardware setups. Since it is possible for users with low-cost video conferencing setup to learn to interpret gaze direction to a very high degree of accuracy , we decided not to apply extensive image-based manipulation on video streams but rather to focus on the design of a widely accessible online system to empower video conferencing users with real-time visualization of eye contacts.", "rq": [" we wonder: what if we could augment virtual conferences in commodity hardware by using interactive 3d photos to add proper gaze tracking?\n we investigate the following questions: what if we do not have access to eye trackers and special displays?"], "id": "dev_34"}
{"intro": ": Efective communication is important in everyday social interactions. Within many organisations, large investments are made by training employees to communicate better. It is also well recognized that non-verbal communication plays a signifcant role in the competency of communication styles in a wide range of contexts . Most training interventions rely on human trainers to provide feedback to learners, but this is costly, labor intensive, subjective and heavily reliant on the skill and experience of individual trainers. Research within the domain of afective computing and social signals processing have started to explore the potential of augmenting or replacing human trainers through the use of automated recognition of nonverbal signals with promising results . However, most studies have focused on a narrow range of channels. They also tend to focus on evaluating the performance of one individual, rather than considering the interplay of signals between communicators. INTRODUCTION: Our previous work has explored which multimodal signals best predict human ratings of communication skills in the context of TV interviews and developed a usable feedback display to provide participants with information about their performance . Efective media skills are important for many organisations including commercial companies, political parties and non-profts, since performance in this context can have huge implications for organizational reputation and outcomes. To our knowledge, none of the previous afective computing interventions for communication skills have focused on this specifc domain. INTRODUCTION: In the current paper, we report an experiment which was conducted to assess the impact of the feedback intervention we had developed on the efectiveness of training to improve media interview performance. We present a controlled between-groups pre-post experiment study where half of the trainees received standard media skills training and half received the standard training augmented with tailored feedback based on automated recognition of facial expression, vocal signals, hand movements and 'honest signals' . We compared performance before and after training across both groups using subjective measures of performance and using measurements of the participants' displayed social signals. The methods used here have potential to be adapted to support real world training interventions for media skills. Longer-term, the results are relevant to the development of an automatic training feedback system to help learners self-refect upon their performance.", "relatedWork": ": The social signal processing (SSP) domain aims to understand and interpret social interactions using nonverbal cues . Signal expression depends highly on context. To recognize the signifcance of an expression researchers must note where an expression is displayed, when it is displayed and who the presenter is . Later, researchers included the signifcance of why and how a cue is expressed . Research in this feld has been successful in capturing postures , gestures , vocal behaviour and inferring emotions from facial expression and eye movements . The contexts which have been investigated includes job interviews , healthcare , public speaking and in the classroom . Earlier research investigated social signals in isolation (i.e. facial expression only during an interaction); however, research has demonstrated that multimodal analysis is more informative of understanding naturalistic interactions. Van den Stock and colleagues (2007) investigated emotions associated with body expression and found that when investigated in isolation, the recognition of emotions is incorrectly recognized and cannot be interpreted . It is noted that this is a result of visual integration of such cues which are necessary for adaptive behavior when responding to others . RELATED WORK: Augmentation of social interactions requires the use of sensor and visual displays that provide trainees with real-time feedback on nonverbal behaviours. The purpose of this is to increase trainees awareness of their use of nonverbal signals and improve the quality of their behaviour in any given context. The behavioral feedback method has been used to provide the user with real-time feedback that is suited to the user, the context and the scenario . This method of feedback provision includes observational learning, operant conditioning, social cognitive theory, perception, refection and action . Several studies have investigated the efcacy of this method . Even though these studies found promising results, researchers did not investigate whether this method was distracting. In contrast, a study found that visual displays during an interaction was not distracting . However, research in cognitive functioning postulates that an increase in visual load is cognitively taxing and could impact trainees overall performance. RELATED WORK: Studies using technology enhanced training have been successful in improving social skills or communication skills . Researchers developed My Automated Conversation CoacH (MACH). MACH is a social skills training platform which allows users to communicate with a virtual character. MACH captures facial expression and speech and generates information on the users use of nonverbal cues. Similarly, a study by Damian and colleagues found that this technique was useful in improving job interview training in underprivileged adolescents. Another group of researchers developed a feedback system called ROC Speaking Framework . Researchers found that feedback of social signals during job interview training signifcantly improved in comparison to traditional methods of training. Similar results were found when attempting to improve communication skills in those with social impairments , public speaking , medical students , job interviews . However, no studies investigate whether social skills can be improved using automated feedback in the context of media skills training.", "rq": ["1. can communication skills be improved by providing automated feedback in the context of media interview training?", "2. are there diferential training efects for social signal feedback when tested after 6 months?"], "id": "dev_35"}
{"intro": ": Mockups are widely recognized in Human-Computer Interaction (HCI) as invaluable tools for communicating and evaluating design ideas. A mockup can help ground descriptions of UI functionality and can serve as a \"boundary object\" that allows designers to communicate with developers and other stakeholders. Mockups are useful throughout the User Interface (UI) development lifecycle, from exploration to refnement. However, most tools for mockup creation are built for the earlier (exploratory) stages of UI development. INTRODUCTION: There are several challenges when creating mockups as communication tools in the later stages of UI development-for example, to propose changes to a UI that already works or to describe a desired behavior in a UI that contains an error. First, most tools for creating mockups cannot import assets or behaviors from existing UIs, and it can be tedious to replicate the intricate details of a working UI in a mockup. Second, it can be difcult to communicate how an existing UI should change because it is not easy to point out the diference between the existing behavior and the mockup's behavior-particularly when the change is nuanced or dynamic . Third, mockups that propose changes to existing behaviors often need to be mixed fdelity -with highfdelity representations of existing components and low-fdelity renderings of proposed changes-but few mockup tools support this. These limitations led to our research question: How can we make communicating about changes to existing UIs easier and more efective? INTRODUCTION: In this paper, we introduce CoCapture, an interactive system that enables users, like UI designers, to easily create and then accurately describe dynamic UI behavior mockups. These mockups could represent changes the users want to propose or questions they want to ask about an aspect of the existing UI. With CoCapture, users frst record the existing UI behavior by demonstrating an example interaction on the existing UI (Fig. 1 , Step 1). Building on this scene, users can further create dynamic behaviors via demonstrations that manipulate DOM elements (Fig. 1, Step 2) and remix these demonstrations as a frst-class animation object (Fig. 1, Step 3) through direct manipulation and low-fdelity sketching. To help accurately specify the visual changes, users can write Natural Language (NL) descriptions in CoCapture that contain hypertext references to specifc aspects of the mockups (e.g., specifc DOM elements, new animated efects) (Fig. 1, Step 4 ). INTRODUCTION: We conducted two within-subjects studies to evaluate the communication efectiveness of multiple aspects of CoCapture: the efort of creating visual context and the accuracy and clarity of the description. In these studies, we asked \"requester\" participants to describe a UI behavior and \"helper\" participants to read the descriptions that requester participants generated. Our results show that compared to traditional sketching and communication tools, the requester participants using CoCapture spent less than a third of the time on text writing, and their descriptions of UI behavior were signifcantly more accurate. Additionally, the helper participants reported that the descriptions in CoCapture were more accurate, concrete, vivid, and easier to follow. INTRODUCTION: The key contribution of CoCapture is a novel interactive method that combines the DOM element-based recording technique with a demonstrate-remix-replay approach. This makes it easier to prototype on pre-built UIs and to describe user needs regarding dynamic UI behaviors more accurately than is possible with existing approaches. With CoCapture, users can efortlessly explore diferent possible designs, capture feeting ideas, and communicate with others about behavior ideas on existing interfaces. Specifcally, our contribution includes: INTRODUCTION: \u2022 A set of novel interaction designs and techniques that allow users to capture, demonstrate, remix, and then describe the Yan Chen, et al., Yan Chen, Sang Won Lee, and Steve Oney UI behaviors they want to add or inquire about on an existing UI via direct manipulation. \u2022 CoCapture, a system that integrates all these techniques to make communicating about changes to existing UIs easier and more efective. \u2022 Evidence showing that CoCapture can help designers more easily create UI behavior descriptions that are easier to understand and follow compared to those created by existing approaches.", "relatedWork": ": As Myers et al. explain, interactive behaviors defne the \"feel\" of a UI (as opposed to its \"look\"). Tools like VisBug and Poirot help designers quickly change the look of their UIs. We focus on communicating about the feel of the UI. This process often consists of two tasks: making visual references and referring to the visual references. In this section, we review related work and techniques in these felds. Creating UI Prototypes and Mockups: Systems like SILK and DENIM lower the overhead cost of prototyping by recognizing designers' sketches as interface elements and implementing the idea of wireframing, respectively. However, they do not support creating prototypes in later stages of UI development. More recently, tools like Rewire and Poirot have made prototyping new designs easier by enabling the users to directly edit elements of existing examples. However, they do not support interactive UI behavior editing, which is more difcult than designing static layouts, as the behaviors are complex to demonstrate and designers have access to limited tools . Commercial tools like Figma and Adobe XD can ease the creation of interactive behaviors but assume their users would reconstruct existing interfaces from scratch, making it hard to scale. Other layout-capturing tools such as WebToLayers 1 and PageLayers 2 automatically convert websites to Photoshop documents. However, they only support static layouts; they do not preserve the DOM structure, element constraints, or dynamic UI behaviors. Crowdpowered systems like Apparition and SketchExpress allow designers or even non-experts to more rapidly create or reconstruct a prototype than they could with existing tools, but these systems also fall short of recreating particularly complex interfaces. Unlike these systems, CoCapture helps create interactive mockups in the later stages of UI development, proposing changes to a UI that already works or describing desired behaviors in a UI that contains an error. These UIs can be arbitrarily complex, requiring efort to create mockups that replicate existing functionality. Compared to layout-capturing tools, CoCapture also captures the DOM structure, allowing designers to easily add behavior mockups on existing interfaces. This gives them the ability to immediately envision the new behaviors and complete the process of creating a mockup as a reference. Visual References as Shared Context in Communication: Many prior studies have reported that people often include screenshots, drawings, or sketches as visual context in communication. These studies have explored questions of how designers communicate desired interactive behaviors to engineers , how In-foVis novices describe data visualization , how programming novices explain PC game behaviors to the computer , and how end-user developers communicate about application extensions with other developers . However, they also consistently found participants' responses to be vague, ambiguous, or imprecise, suggesting future systems should provide a tight feedback loop in which users see immediate results to refne ambiguous descriptions. Visual References as Shared Context in Communication: Creating visual references can help ground communication when discussing visual design and providing feedback. In a face-to-face or video conference setting, we can use pointing gestures in shared visual spaces to make references to visual information that is difcult to express with words. Much work has studied methods for referring to visual content in communication, including text annotation , remote gestures , and awareness widgets in diferent computer-supported cooperative work contexts such as authoring and groupware . They have shown that referring methods can facilitate mutual understanding by reducing verbal efort and its associated complexity . The ability to leverage non-verbal communication is an important factor in decreasing the efort of writing clear messages . Visual References as Shared Context in Communication: In programming communication, systems like chat.codes and Callisto use deictic code pointing techniques to facilitate creating code references and connections with text descriptions that help developers discuss code. Codeon is an in-IDE support environment to help requesters and helpers exchange code context easily. MarmalAid allows users to start a real-time conversation on a geometric location in a 3D workspace. Building on these approaches, we aim to address the problem of referring to dynamic and interactive visual references for more efective communication. Record, Replay, and Manipulate Existing Interfaces: A core technical part of CoCapture's system is the record and replay (R&R) technique, which is used to record an existing behavior once and then replay it repeatedly and automatically without user interaction. Prior work has used this technique for various purposes. Systems such as Scry , Telescope , Unravel , Doppio , FireCrystal , and WebCrystal use this approach to help people understand existing UI behaviors. Systems like Chronicle , Timelapse , and MobiPlay record meta-data (e.g., operations, code editing) and allow users to easily capture the rich data of application behaviors. Our techniques enable designers to not only record arbitrary web interface behaviors, but also to easily add new designs on top. Record, Replay, and Manipulate Existing Interfaces: To ease the creation of new behaviors, FrameWire decreased the efort of communicating new interactive designs by automatically extracting interaction fow from paper prototype video recordings. Many other recording augmentation systems have been developed to help efectively prototype new digital content, such as CHI '21, May 8-13, 2021, Yokohama, Japan Montage and Augmented Reality (AR) experiences like Proton , or to provide video feedback, like VidCrit . Park et al. developed a technique that enables users to edit text content in a text-based recording while preserving the recording's overall consistency . CoCapture also allows its users to easily add new behaviors over recordings, but instead of simply supporting overlaid visual annotations or user comments anchored to specifc parts of the content, it allows users to edit existing elements through direct manipulation. Record, Replay, and Manipulate Existing Interfaces: The feld of Programming by Demonstration (PbD) has used similar techniques to augment users' ability to perform tasks with which they often lack expertise. Rousillon and Sugilite allow their users to record and edit the operations via domain-specifc languages. CoCapture also supports a set of mockup creation operations that allow designers or even novice users to edit the recording and simulate the desired interactive behaviors.", "rq": [" these limitations led to our research question: how can we make communicating about changes to existing uis easier and more efective?", "q1: can designers ask a more accurate ui behavior question using cocapture than with a text-based communication tool (e.g., email)?", "q2: can they also create the questions more quickly?\n q3: can helpers easily understand the questions in cocapture?"], "id": "dev_36"}
