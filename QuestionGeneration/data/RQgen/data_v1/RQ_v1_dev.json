{"intro": "", "relatedWork": "BACKGROUND AND RELATED WORK: With the recent developments in many of the sub fields of conversational AI, including machine learning, dialog management and NLU, many different conversational AI systems have emerged . BACKGROUND AND RELATED WORK: In industry, this technology has been incorporated into search engines, mobile devices, and personal computers. In search engines such as Google and Bing, conversational AI is used to create the feeling of having a conversation with the search engine, enhancing the experience. In mobile devices and personal computers, one use of conversational AI is to create virtual assistants. Some of the biggest virtual assistants on the market today are Apple's Siri, Google Assistant, Amazon Alexa and Microsoft Cortana . These assistants also have the capability of acting as chatbots where they keep a turn-based dialog (a dialog where the user and the bot take turns in asking and responding to queries) with the user. There also exist conversational interfaces that only focus on this type-dialogbased conversation such as XiaoIce and Replika . These dialogs use what is known within conversational AI as intents and entities to understand the user's goal behind the query. In other words, an intent is what the user wants to achieve with the query, and an entity is the key information for answering the intent. BACKGROUND AND RELATED WORK: Recently a number of different platforms have been made available to simplify the creation and integration of conversational interfaces for developers. The most popular ones are: Google's Di-alogFlow (formerly api.ai) 1 , IBM's cloud-based bot service Watson Conversation 2 , Amazon Lex 3 and the Microsoft Bot Framework 4 . These platforms come equipped with several different technologies used for NLU, dialog management, response generation and other aspects . BACKGROUND AND RELATED WORK: Since conversational AI is a new field, systematic approaches to overview and categorize it are still in their infancy. Patil et al. makes a general comparison of features and functionalities between some of the commercial platforms, giving an overview of what platform one might choose for developing a conversational AI system. There have also been more specific studies conducted which compare the NLU and conversational abilities of these types of platforms. Canonico and De Russis compare the NLU performance of these platforms have in terms of usability, pre-built intents (a number intents already existing in the NLU tool) context etc. McTear describe the two main conversation models \"oneshot queries\" and \"slot-filling dialogues\". He compares different platforms' ability to handle follow up questions in one-shot query scenarios and their mechanisms for slot-filling (a type of conversation where the bot asks specific questions to fill certain slots to fulfil a user intent). McTear also presents a number of problems that developers may face when creating conversational interfaces with these platforms. One of the main issues is that it might be difficult to know what functionalities a specific platform offers. There is also a difficulty in interpreting what functionalities might be common between platforms since there is no standard terminology. Venkatesh et al. describe a number of metrics that can be used to evaluate the overall performance of a conversational agent based on the annual competition Alexa Prize made for furthering conversational AI. They propose metrics such as conversational user experience, engagement, and conversational depth to measure the conversational abilities of entire conversational AI systems or chatbots . Shawar and Atwell describe metrics to specifically evaluate chatbot systems, a type of conversational AI interface. They argue that metrics for evaluating the abilities of these systems should be done based on the application and its domain and not solely on a standard. BACKGROUND AND RELATED WORK: One of the main issues with creating the metrics described above is the understanding of what a good conversation is. Clark et al. discuss that people generally describe conversations with conversational interfaces in terms of their performance and perceive them more as a device to be controlled. Indicating that people have a previous notion of how these systems will behave coming from a perception that infrastructure to support proper human-to-human dialogs do not exist. BACKGROUND AND RELATED WORK: The maturity assessment framework presented in this paper takes inspiration from three language proficiency frameworks: Common European Framework of Reference (CEFR, ), American Council on the Teaching of Foreign Languages (ACTFL, ), and the Interagency Language Roundtable (ILR, ). The goal of these frameworks is to assess the language competency of an individual for a particular language. All of these frameworks have a similar structure, distinguishing different, successive levels (e.g., in case of CEFR, a sixitem scale A1-C2), language-relevant skills (e.g., for CEFR, reading, listening, speaking, and writing), and a number of hints for assigning an individual to a level. While the contents of the framework differ, they all share this same basic structure, which we also found useful for inspiring the design of our framework. A number of papers have scientifically investigated these frameworks, studying their validity and the possibility to use them in an automated way .", "rq": [" rq1: what platforms exist for developing conversational ai systems?", " rq2: what are the features of these platforms?", "rq3: what are the levels of conversational maturity supported by the identified platforms?"], "id": "train_0"}
{"intro": ": Knowing a foreign language has many benefits and is often a requirement for academic and job opportunities . In China alone, over 300 million people are estimated to be learning English . While many inexpensive self-study resources exist for learning to read and write in a foreign language, opportunities to practice speaking skills are much more limited. Traditional classrooms can be inaccessible, expensive, and may offer only sparse practice opportunities to practice speaking . Intense in-person prep courses are often even more expensive and inaccessible. The lack of opportunity to practice spoken English means that many people may pass written requirements and yet struggle to communicate in a way required by academic training or job opportunities . There is a key need to provide effective education at scale for language learners to practice speaking. INTRODUCTION: Chatbots are a promising tool to address this. Speech recognition and natural language processesing (NLP) advances have significantly improved chatbot technology, especially in targeted domains . Chatbots can also help simulate the process of talking to another human in a more natural way than synthesized voices and potentially could offer additional benefits such as enhanced distributed cognition and social interaction abilities . New language learners are sometimes shy about practicing their spoken English around other people , but chatbots could provide a friendly, non-intimidating setting for spoken language practice. Chatbots may also be more engaging and fun than more traditional spoken language interfaces, such as listen-and-repeat. Perhaps for these reasons, there is emerging commercial interest in foreign language learning chatbot systems: for example, English Liulishuo is used by 150 million people worldwide . INTRODUCTION: Indeed, in other educational settings there is encouraging evidence that chatbots can promote engagement and learning gains . In particular, for factual knowledge learning, prior work found that over a week of optional usage, subjects using a chatbot interface did substantially better on the learning material than those using a classic flashcard app. However, chatbots may also increase the amount of time learners spend with the same material, impacting efficiency of learning. INTRODUCTION: This suggests that it is important to evaluate and understand the impact of chatbots on spoken language learning effectiveness and efficiency. In this study, we present the first, to our knowledge, experimental study of a standard listen-and-repeat interface versus a chatbot interface (EnglishBot) for spoken language learning. The learning materials are from the standardized English examinations IELTS and TOEFL , which cover a range of common scenarios international students could encounter in English-speaking universities. We recruited 56 native Chinese college students who had never worked or studied abroad in English speaking countries for more than three months to participate in two six-day betweensubjects studies (one with fixed usage and the other with free usage) comparing EnglishBot against a traditional listen-and-repeat interface. We conducted three assessments to carefully measure users' improvements on memorization of vocabulary, script translation ability, and unrehearsed speaking ability. INTRODUCTION: Our results show that compared to a traditional listen-and-repeat interface, EnglishBot was more engaging to interact with and promoted more vocabulary learning and speaking fluency and coherence, but did not affect grammatical range and accuracy, lexical resource , or pronunciation. This work makes three contributions: (1) We design a novel conversational interface for spoken language, combining recent advances in natural language processing and speech recognition. (2) We conduct two novel empirical studies evaluating an AI-powered conversational interface against a traditional listen-and-repeat interface for second language speaking under fixed and voluntary usage conditions. (3) In light of the success of chatbots in promoting engagement, vocabulary learning, and speaking fluency, we present design suggestions based on our findings for building the next-generation of conversational interfaces that are both engaging and effective for language learning.", "relatedWork": "2.1 Language Learning ITSs: ITSs provide adaptive feedback that depends on the user's response and/or a model of the user's knowledge state, rather than fixed feedback regardless of user input . Prior studies found general ITSs can be as effective as human tutoring , and that use of an ITS in a study was associated with greater achievement in comparison with teacher-led large-group instruction, non-ITS computer-based instruction, and textbooks or workbooks . The inclusion of sophisticated AI modules produced learning improvements of 0.3 to 1.0 standard deviations compared with students learning the same content in a classroom . RELATED WORK 2.1 Language Learning ITSs: German Tutor , later renamed to E-Tutor, was one of the first ITSs developed for foreign language learning. The focus was on building grammatical competence for introductory-level adult learners of German as a foreign language. German Tutor used NLP to parse learner responses to various exercises and provided metalinguistic feedback tailored to the learner's specific errors and perceived proficiency level. Empirical studies of German Tutor/E-Tutor found that students attend to feedback provided by the system , and metalinguistic feedback leads to greater learner uptake and self-corrections than simply highlighting mistakes for both grammatical and spelling errors . RELATED WORK 2.1 Language Learning ITSs: ITSs for adult Japanese foreign language learners, Nihongo-CALI and BANZAI, have been well-documented in the literature. Through a series of empirical studies, Nagata demonstrated that intelligent metalinguistic feedback provided by the ITSs led to significant improvements on Japanese language tests, as compared to traditional feedback that simply highlighted mistakes. These improvements also held when the ITS was used in a simulated self-study context . The prior work did not use chatbots in their ITSs for language learning. Chatbots and Student Learning: While ITSs are able to give more detailed and intelligent feedback to learners than traditional systems, historically such systems assume a constrained set of possible answers from the learner. Chatbots provide the promise of more open-ended interaction between system and learner, in which the learner can take more control over the direction of the conversation, and the system can accommodate a very large range of potential answers. Previous work has shown that chatbots can increase learner engagement and are effective for learning many subjects including factual information , math concepts , and physics . Chatbots and Student Learning: In language education settings, chatbots and conversational agents have been used with learners of all ages. Results have consistently shown that language learners find interacting with intelligent computer agents to be engaging and enjoyable . There is some evidence that such systems are more approachable to learners than speaking with human partners, and their use can reduce anxiety about communicating in a foreign language . Chatbots and Student Learning: Although chatbots and conversational agents may be engaging, their actual effectiveness at improving users' foreign language conversation skills has received less study. Selected studies have shown that learners interacting with these systems can produce similar levels of short-term learning in tests of isolated grammar functions, and general speaking proficiency, as interacting with human partners ; however, long-term learning has not been studied in detail, and comparisons with traditional non-intelligent systems are limited. Chatbots and Student Learning: Furthermore, the heightened levels of engagement found with chatbots may represent a short-term novelty effect. In one study, English learners' interest in conducting speaking tasks with a chatbot decreased significantly after the first task, whereas interest in conducting the same tasks with a human partner stayed at the same level through three tasks . Chatbots and Student Learning: Despite limited research on the pedagogical effectiveness of chatbots for foreign language learning, public interest in their development is high. In China, the English learning mobile app English Liulishuo incorporates a conversational agent with adaptive feedback for users to practice dialogues. Given the already high levels of interest in developing chatbots for foreign language learning, it is important to understand whether this increased engagement is also associated with improved foreign language skills in users, as with ITSs, or whether chatbot technology is better suited as a fun activity with limited pedagogical benefit for foreign language learners.", "rq": ["(1) When interface exposure is held constant, how does the inclusion of chatbot elements affect improvements in users\u2019 English abilities?", " (2) When users are able to determine their own interface exposure, how does the inclusion of chatbot elements affect improvements in users\u2019 English abilities?", " (3) How does the inclusion of chatbot elements affect user engagement with theinterface?"], "id": "train_1"}
{"intro": ": Chatbots are regarded as one of the most promising technologies and are increasingly applied in many domains. Because chatbots provide a fast, convenient, and low-cost communication channel, both scholars and practitioners are keen to develop effective chatbots to address the challenges of providing healthcare services. For example, a growing body of research demonstrates how chatbots can be useful for helping people maintain good lifestyles , collecting daily health information to share with healthcare providers , and guiding people to improve their general well-being . For instance, Wang et al. proposed a conversational agent to coach people to relieve their public-speaking anxiety through cognitive reconstruction exercises, and Fitzpatrick et al. 's Woebot system gives step-by-step guidance for users to think through their situation with cognitive behavioral therapy and was found to relieve users' depression. Other recent studies have applied a variety of conversational strategies and structures to promote behavioral change and to persuade chatbot users to act differently . Some of these systems have even been found to outperform human-human interaction in some scenarios. For example, Lucas et al. found that utilizing a virtual agent as an interviewer could promote users' depth of self-disclosure, and Xu et al. concluded that the use of interactive robot agents would probably enhance physical-therapy outcomes. Therefore, these prior works have demonstrated that chatbots can serve as an effective platform for delivering guidance and tutoring people. INTRODUCTION: Despite the success of utilizing chatbots to deliver guidance, there are still a number of challenges to overcome. For example, research points out that people easily become disengaged from using a chatbot , hampering them from long-term interventions. Moreover, people may overtrust solutions suggested by chatbots which could be inappropriate . In another study, Luria et al. found that people felt uncomfortable interacting with a chatbot which used the same personality to handle both low-risk (e.g., social chat) and high-risk (e.g., medical purpose) contexts. Thus, the authors suggested to design a chatbot that embodies multiple personalities, each of which are displayed in a unique social presence and have the expertise to focus on a single task. INTRODUCTION: Prior studies inspire us to overcome challenges by integrating human support into a chatbot system. More specifically, we may be able to make the best use of both human-based and chatbotbased approaches by co-embodying them into a single system. Indeed, studies have suggested that the integration of human support with chatbot interactions could promote user engagement and efficacy of using self-guided systems. For example, a recent study proposed a mediator chatbot that promotes deep self-disclosure from users and delivers the information to a human expert. More research is clearly needed on how individuals might respond differently to interaction with a chatbot alone vs. one incorporating human support. We are also interested in understanding how such differences affect user experience in the long run. To help fill the gap, we conducted a mixed-methods study with 35 participants. We deployed two chatbot designs, both of which delivered training in journaling skills . The first version of the chatbot guided participants in the journaling skills itself, while the second version integrated a human expert (coach) into its interaction when guiding the participants in the journaling skills. Over a period of four weeks, we tracked changes and differences in how each version impacted users' responses to and perceptions of the chatbot system, as well as their level of compliance with the guidance to practice journaling skills. INTRODUCTION: Our work makes several contributions to the CSCW and human-computer interaction (HCI) communities. It is among the first that investigated the effects of integrating a human expert to deliver guidance for practicing journaling skills. Our unique three-phase design of an experimental study with 35 participants contributes novel findings of how chatbot interactions with and without expert guidance elicited user interaction differently over time. More specifically, during the Training phase, participants' actual and perceived engagement with the chatbot providing expert guidance (HC) was significantly higher than that of the participants who interacted with their chatbot alone (OC); however, during the Free-will phase, the OC participants chose to continue practicing journaling significantly more than the HC participants. Second, triangulating system log analysis with interviews and surveys, we provide new insights into how the design of chatbot systems with and without human support affected user experience of such systems both objectively (e.g., in terms of the length and depth of journaling content) and subjectively (e.g., participants' perceived trust and intimacy with the chatbots). Third, our work also presented empirical evidence of using chatbots to practice journaling on improving participants' self-reflection. Since prior work shows better self-reflection could enhance people's awareness of their well-being, our work further provides Exploring the Effects of Incorporating Human Experts to Deliver Journaling Guidance through a Chatbot 122:3 design implications for applying chatbots in the healthcare domain and to support diverse training purposes.", "relatedWork": ": 2.1 Chatbot for Delivering Guidance Conversational agents (e.g., chatbots) are gaining considerable attention in many fields including healthcare and education . Research has shown that chatbots can assist users in tracking and monitoring their behavior (e.g., ) and feelings (e.g., ), which could further be used to solicit social support and self-reflection . Also, many studies designed chatbots to guide healthier habits or ways of thinking , such as better eating habits , exercise , ways of coping with stress , and self-compassion . For example, Park et al. incorporated a motivational interview technique into chatbot conversation to help users cope with stress, and found that their design facilitated conversations that improved self-reflection as well as stress management. Lee et al. designed a dialogue aimed at inspiring users to take care of a chatbot that was portrayed as having had a negative experience, and found that after doing this for two weeks, users' self-compassion increased significantly. Another line of research has shown that chatbots have the potential to help people improve their mental well-being by training their thoughts and behavior . For instance, Wang et al designed a public-speaking tutor using a chatbot system to coach users and reduce their public speaking anxiety. Hence, these studies have shown that chatbots could not only help track users' behavior but could also play a proactive role in training users to learn skills. RELATED WORK: Recent advancements in artificial intelligence (AI) are also enabling chatbots and other virtual agents to act more credibly like human beings, including during the provision of self-help information . Prior studies indicated that conversational interaction can increase trust and affect users' acceptance of recommendations from a conversational agent. Thus, the design of the interaction between them is important in enhancing users' willingness to adopt chatbot suggestions. Gabrielli et al. proposed a chatbot-based coaching intervention that successfully helped adolescents learn life skills, such as strategies for coping with bullying, and previous research found that their participants' trust and compliance with physical therapeutic suggestions were both higher when interacting with robot therapy partners than with a human expert. Moreover, research has shown that people tend to apply the social norms of human relationships to their interactions with computer agents. This tendency, known as the Computers Are Social Actors (CASA) paradigm , has informed the design of many computer agents . People may perceive intimacy and companionship with a computer agent , inducing changes in behavior change. For example, Ravichander et al. found that reciprocity occurred in human-chatbot interactions and that a chatbot's self-disclosure encouraged people's self-disclosure. Similarly, recent work by Lee et al. showed that a chatbot's self-disclosure improved participants' perceived intimacy with the chatbot and facilitated their self-disclosures in response to the chatbot's sensitive questions (e.g., failure experiences). RELATED WORK: However, several limitations of chatbot-based approaches remain, and in certain situations, chatbot-based approaches may be less beneficial than those provided by humans . For example, Howard et al. has pointed out that some people may trust robots too much, due to over-optimism about the viability of the solutions they suggest, and that this trust becomes a source of risk if robots make clinically suboptimal or inappropriate suggestions. In addition, for healthcare interventions that require long-term engagement , people may easily become disengaged from the use of self-guided systems, due to loss of motivation and/or failure to incorporate those systems' recommendations into their daily lives . Furthermore, an investment model shows that purely computer-based interventions are often much less effective than hybrid ones with some professional human input , in part because the latter tends to inspire their users to execute a higher proportion of their intervention requests. Integration of Human (Expert) Support and Chatbot-based Approaches: In prior works, human support has been provided via a separate communication channel external to the chatbot system, such as phone calls, text messages, and email . For example, there have been two main ways of providing human support to chatbot systems. The first is to deploy chatbots in between human-run sessions, to offer users unbroken access to materials and activities . Studies that have adopted such an approach regard chatbots as supplementary tools to support human expert's intervention; chiefly, by monitoring clients outside of their clinical sessions, and garnering information about them that may result in better treatment (e.g., ). Alternatively, it is possible to design a primarily chatbot-based intervention, augmented by human supporters who promote engagement and provide technical troubleshooting and clinical support when issues arise . Such an approach could be more efficacious than interventions by chatbots unsupported by humans . Integration of Human (Expert) Support and Chatbot-based Approaches: Recently, some researchers have suggested an integration of human support into chatbot interventions . For example, Schueller et al. reviewed prior studies of integrating human experts (e.g., coach and therapist) into behavioral intervention technologies, not chatbot-based, and suggested concepts to guide a deeper integration by capturing the trade-offs between client benefits and the available human resources. Alternatively, some prior studies use conversational agents to encourage users' collaboration and communication between people. Specifically, Kumar et al. designed a chatbot tutoring system which gave guidance for multiple students to facilitate collaborative learning among them. Duan et al. utilized a conversational agent to enhance non-native speakers' confidence in conversation with native speakers. These studies showed that chatbots could help mediate interactions between users, but we further explore the effect of applying chatbots to mediate suggestions for guiding users to learn skills. Integration of Human (Expert) Support and Chatbot-based Approaches: The foregoing review and Schueller et al. 's work calls for an integration of the support provided by chatbots and humans. However, previous works have indicated different designs for implementing multiple personas into a chatbot system. For example, Luria et al. conducted studies to examine multiple personalities for conversational agents under different contexts (e.g., low-risk and high-risk contexts). They found that users preferred to have an additional expert agent guiding a specific complex task instead of interacting with the same agent that handled both simple and complex tasks. Conversely, Chaves et al. found that users reported confusion when they engaged in multiple persona chatbots for an information gathering task in a single communication channel. Therefore, it is not clear if and how adding a human supporter into human-chatbot interactions could impact user experience and outcomes, which motivates our research.", "rq": ["RQ1: Do people interact with their chatbot differently if they have a human expert (HC) or not (OC) to guide them?", "RQ2: How do people perceive their interaction with the chatbot differently between the HC and OC conditions?", " Do people keep practicing journaling skills differently over time between the HC and OC conditions?"], "id": "train_2"}
{"intro": "", "relatedWork": ": We draw on work from studies of information seeking and search, conversational style, and embodied agents. Spoken Conversational Search: With the increasing popularity of voice-only interfaces, and increasing sophistication in natural language processing, conversational search has emerged as an active research area. In conversational search we have long-form interaction in natural language, asymmetry of role between user and intermediary, and a (possibly ill-defined) task. This contrasts with past work examining chitchat ; cooperative tasks between peers ; or slot-filling \u0142dialogue\u017e systems . Spoken Conversational Search: A few studies have examined the structure information-seeking conversations, mostly between people or otherwise in the absence of running software . There have also been attempts to describe what a conversation should look like . Studies with agents have been limited, however, by the agents' inability to hold a lengthy conversation . There has also been very little discussion of conversational style in a retrieval setting. Conversational Style: James Pennebaker et al. have extensively studied language, or linguistic, style matching (LSM), observing that increased style matching between humans was correlated with increased interest in the partner . Conversational Style: Tannen draws a distinction between \u0142high involvement\u017e (HI) and \u0142high consideration\u017e (HC) styles in social conversation. Differing from Pennebaker et al.'s LSM, these styles also include non-verbal or paralinguistic features. A high involvement style emphasises enthusiasm and interpersonal involvement: features include rapid speech, volume, questions, overlap, and reference to personal experience. A high consideration style, by contrast, emphasises independence and space and features longer pauses, hesitation, and less paralinguistic effect. These notions are also seen in, for example, Lakoff's \u0142camaraderie\u017e and \u0142distance\u017e strategies . In parallel with Pennebaker, Tannen further suggests that partners with opposing styles will find conversation frustrating. Conversational Style: There is little work on conversational style in information-seeking contexts, as opposed to social contexts. Tannen's two styles were adopted by Thomas et al. , who used audio recordings and transcripts from the MISC data to demonstrate that style could be characterised and computed automatically. They also found that differences in style have an effect on people's perception of conversations. We draw on this work in the present experiments. Style Matching: There is ample evidence of alignment in human-human conversation: that is, partners in conversation tend to converge on word choice, syntax, and even accents . There is some evidence of a similar effect when people interact with computers as well . As conversational agents become more sophisticated, we believe based on early evidence that linguistic style matching could influence trust and likeability of the agent for the human user. We know from user-centered design studies that people unconsciously apply human social rules when interacting with computers: they prefer systems which appear to manifest personalities similar to their own and agents that are more human-like . Therefore, it is reasonable to assume that conversational systems would be preferred if they exhibit conversation styles that are more similar to that of the user. We test this hypothesis in the present work. Embodied Conversational Agents: Voice-based conversational agents have become ubiquitous in the past few years. However, research into voice-only and embodied systems dates back several decades. Cassell and Bickmore pioneered the use of embodied conversational agents. The research has shown that embodied agents have several advantages over voice or text-only conversational agents. Embodiment helps users locate the source of the interaction and allows for a richer opportunity for the communication of non-verbal cues. An agent that has a physical presence also provides visual affordances, indicating where the user should focus their attention and receive cues from body and hand gestures, eye gaze and other expressions . When artificial conversational agents engage in more natural social behaviours (e.g., using social dialogue), it helps increase user trust . In this work we use an embodied conversational agent for these reasons. Embodied Conversational Agents: The present work builds on the above, but is different in several aspects. We report on spoken conversations which run for several minutes (as opposed to one or two turns); for this, we use an embodied agent and we track and adapt conversational style in real time. In contrast to past work on conversational style, which uses recordings or transcripts of human-to-human conversation, we draw from recordings of conversations with an actual software agent. We also focus on information-seeking conversation, which has been little-studied in this context.", "rq": ["RQ1: Do those styles first identified and measured in human-to human conversation\u00d0including in chit-chat and in infor mation seeking\u00d0also exist in information-seeking conversations with an embodied software agent?", "RQ2: Do participants\u2019 styles correlate with their perception of the agent?", "RQ3: Do participants\u2019 styles correlate with their perception of the agent?", "RQ4: Does it make a difference as to how the agent performs, or is perceived, if it attempts to align to the participants\u2019 conversational style?"], "id": "train_3"}
{"intro": ": According to the 2011 census, 54.6% of the Indian population is engaged in agriculture , but earn only 13.9% of the country's GDP . To address this gross mismatch, the Indian government aims to double farmer incomes in the next five years . It is well believed that access to information and expert advice is crucial in achieving this 170:2 \u2022 M. Jain et al. INTRODUCTION: goal . Such information includes the choice of seeds to sow, how to combat specific crop diseases, weather forecast based advisory, and optimal harvesting times. However, farmers in rural India often have limited access to such information . Even when the information is available, farmers are often unable to consume it due to illiteracy, as India has the lowest adult literacy rate in the world . INTRODUCTION: Several solutions have been proposed to solve the limited information access issue faced by farmers in the developing world. This includes forums for asking questions to experts and peers , peer education using participatory video , interactive voice response (IVR) systems , and social networks for farmers . Since 2004, the Indian government has been operating the Kisan Call Centre (KCC). The KCC is a toll-free call-centre to answer farmers' queries in 22 local languages daily between 6 am to 10 pm. However, it is difficult for the manually operated call-center to keep up with the massive demand. In June 2014 alone, 1.11 million calls were received by the KCC, out of which over 450,000 (~40%) went unanswered . Thus, it remains an open problem to build a system that satisfies the information needs of rural farmers. Systems meant to serve this population must be usable and acceptable by people with limited literacy, highly scalable, available around-the-clock, responsive, and have a manageable overhead for agricultural experts (referred as agri-experts). INTRODUCTION: As a potential solution, in this paper, we introduce an automated conversational agent, or chatbot, to provide farming related information through natural speech interactions. A chatbot offers several benefits that can potentially satisfy the above-mentioned requirements. First, speech is the most familiar mode of interaction that requires little learning or literacy. In fact, audio-based interactions are considered the preferred-sometimes the only usable-interactions for illiterate users . Interactions with an agent should enable farmers to formulate queries as if they were talking to another person. Second, conversational agent systems offer direct information access without the need to navigate complex information paths as often required by graphic user interfaces (GUI), and simplicity is considered a primary design requirement for low-literate users . Finally, from a system point of view, a chatbot is a scalable solution that can be accessed by any user at any time. Moreover, agri-experts can review user inquiries to the chatbot periodically and then continuously expand the chatbot knowledge base without high maintenance cost. INTRODUCTION: While recently the HCI community has developed an increasing interest in conversational agents and demonstrated their benefits , most prior works focus on literate, technologically-advanced users. In our work, we take the conversational agent on the ubiquitous smartphone to rural farmers in the developing world, broadening its scope to a new demographic. This new user population and usage require answers to questions concerning (a) how to encode farming related queries efficiently in a conversational system; (b) the robustness of speech and language technologies in the local language; (c) the acceptability and usability of chatbot technologies for rural farmers; and (d) interaction modality preferences of the farmer population. INTRODUCTION: To answer these questions, we designed FarmChat, a conversational agent to meet the information needs of rural Indian farmers. Recent work suggests that interface design should support semi-literate users differently from illiterate users . For semi-literate users, text can offer faster and unambiguous mode of interaction , while for illiterate users, the appearance of text negatively impacts their performance . Further, text output allows more flexibility to process information and persistent access to messages, which we identified as a design requirement in a formative study. Hence, we built and compared two interfaces of FarmChat: (1) Audio-only (input: speech; output: audio) and ( 2) Audio+Text (input: speech, button; output: audio, text, image). INTRODUCTION: Currently, FarmChat supports Hindi-the most widely spoken Indian language-and answers queries about potato farming as a use case for the study. The knowledge base embedded within FarmChat on potato farming was derived by analyzing the query logs from KCC and a formative study with 14 farmers and 2 agri-experts. Thereon, we ran a task-based user study with 34 farmers in villages around the city of Ranchi in the state of Jharkhand in eastern India. From the 626 inputs provided by the participants, we found that farmers appreciated FarmChat's precise and localized responses, showed great interest and trust on the information, and generally found a conversational agent easy to use, thus hinting that a chatbot has the potential to meet their farming-related information needs at scale. We also uncovered some interaction behaviors and issues that are important to consider when developing chatbots for this user population, including over-expectation of chatbot's capabilities, a tendency to imitate phone conversations with a human, and unfamiliarity with standard speech input and messaging interfaces. Moreover, we found that literacy level, prior experience with technology, and profession played crucial roles in the users' preferences between the Audio-only or the Audio+Text interface. We conclude with implications for designing chatbots for low literate and novice technology users. INTRODUCTION: Our main contributions are: (1) Proposing a novel speech-based conversational system to meet the information needs of low literate rural Indian farmers, wherein the chatbot intelligence was based on KCC logs and inputs from local agri-experts. (2) Comparing two chatbot interfaces with differing interaction modalities, and inferring that preference for an interface was highly dependent on the farmer's literacy level and prior technology experience.", "relatedWork": ": Our work is mainly informed by three areas of relevant research: UIs for low literate users, technologies to support agriculture related activities, and conversational systems. UIs for Low Literate Users: Designing user interfaces for low literate populations is a growing area of research . It spans multiple application domains, including agriculture , health care , citizen journalism , video search and social networking . Research has shown that users with low levels of literacy perform better with user interfaces which use minimal or no text and represent textual information using graphics/photographs and audio . Even interfaces that use graphics liberally, such as a job search web portal for illiterate users , rely on audio to provide descriptions and instructions. Voice as an interaction modality is well-suited for low literate users, as it is a natural means of expression. Voice-only citizen journalism portals , voice-based Q&A forums for rural farmers , and IVR systems are a few successful examples, relying heavily on speech for input and audio for output. With audio as the output modality, researchers have compared speech versus DTMF/keypad for input and obtained contrasting results with low literate users . Interestingly, most low literate users are numerically literate; hence, using numbers (both for input in keypad buttons and output as text) has been found to be acceptable . This has paved the way for multimodal interfaces that embed graphics, voice, and numbers for low literate users. UIs for Low Literate Users: Recent research highlighted the interaction differences between illiterate and semi-literate users and suggested to treat the two groups differently in interface design . Comparing them in tasks on Audio+Text versus Text-only interfaces, Findlater et al. found that text was important for semi-literate users since it offers a faster and less ambiguous mode of interaction. Importantly, text allows for opportunistic language learning. Interestingly, social factor also results in the preference of a text-based interface since it avoids the stigmatized perception of illiteracy . For illiterate users though, the appearance of text negatively impacts their task performance . Hence, we designed and compared two FarmChat interfaces: Audio-only and Audio+Text. Agriculture-related Technological Solutions: ICT4D research has contributed immensely in developing technological solutions to help farmers in developing regions with their information needs . Farmers are usually located in rural areas with low literacy levels; hence, a majority of the proposed solutions rely heavily on voice as an interaction modality. Two of the widely adopted approaches are automated calls providing agriculture-related knowledge and IVR systems. These are highly scalable solutions, but are limited to providing generic crop-related advice, which may not work for a majority of farmers due to variations in crop, soil type, climate, etc. Automated calls have been adopted by several governments around the world, including India's . Khedut Saathi took automated calls a step further, allowing farmers to forward the received audio message to five other phone numbers. IVR systems use a computer-based back-end with a keypad/voice-based input, and audio output to provide farmers with relevant information related to weather, fertilizers, and market prices . Accessing the hierarchical navigation is a major usability issue with IVR systems . Instead of restricting their system to audio alone, Digital Green focuses on creating videos by farmers and uses human-mediated instruction for disseminating these videos to other farmers. VideoKheti proposed a multimodal method for illiterate farmers to search specific videos. Agriculture-related Technological Solutions: Other solutions offer custom advisory services to farmers. The Indian government program KCC allows farmer to dial a toll-free number and get responses to their specific queries. Since the demand for such information is too large to be met by a manually operated system, most of the KCC calls go unanswered because the phone lines are usually busy . Avaaj Otalo proposed a voice forum for asking agriculture-related questions to experts and peers. It is an asynchronous system, meaning that responses are not given in real-time. Furthermore, questions can be answered by anyone, which may result in incorrect answers and distrust towards the system. Agriculture-related Technological Solutions: The above work suggests that to fully support the agriculture-related needs of farmers, constant, real-time access to specific information is needed. None of the systems in prior work achieve all of those criteria; FarmChat is an attempt to fulfill these requirements. Conversational Systems: The last decade has seen rapid growth in conversational agents (also called chatbots). Chatbots have appeared on a variety of mobile and ubiquitous platforms, including phones, smart speakers, VR/AR devices, smartwatches and even operating systems (Siri by Apple and Cortana by Microsoft). The term 'Conversational Agent' has come to mean a wide variety of systems with varying capabilities and purposes, with the underlying assumption that human interactions with the systems resemble normal conversations. Proponents of chatbots embrace their many strengths: e.g., user's familiarity with the conversational interaction, seamless natural-language interface across use-cases, offering direct information access and simplified navigational paths, and the promise of personalized and evolving intelligence . In spite of this rapid growth, chatbots are still in its nascent stage, as 84% of the Internet users have not used a chatbot yet . Conversational Systems: From an HCI perspective, Licklider's 'Man-machine symbiosis' was one of the earliest discourses that visualized humans interacting with machines in a natural manner. Although the HCI community has studied how conversational agents are used in different settings , no prior work has focused on low literate users. The closest to our work is a study with first-time chatbot users , who were technologicallyadvanced literate Indians knowing about chatbots, but had not used them before. Most works evaluating users' experience with chatbots have discovered a gulf between experience and expectation with respect to the capabilities of chatbots . Users were found to be disappointed and even frustrated with the current bots , and most chose to limit the usage of chatbots to simple tasks (e.g., setting alarms) . This suboptimal user experience can be attributed to the high expectations of expert users that these chatbot technologies currently target . In contrast, our work focuses on developing chatbots for low literate novice smartphone users who have little knowledge or preconception of the technology. Conversational Systems: To summarize, speech-based conversational interface has several potential benefits for our targeted farmers population. Besides little requirement for literacy, it offers a natural and familiar modality that does not require a user to learn new technical concepts or interaction methods. This could be important as rural farmers often have low technology literacy and self-efficacy. Meanwhile, knowledge base of the conversational system can be easily edited or customized by agriculture experts, thus offering a scalable solution for disseminating information and expert advice. However, it still calls for empirical understanding for the acceptability and usability of this new type of technology among the farmers population. Our study set out to fill this gap. Conversational Systems: Two sources of knowledge informed the development of FarmChat: farmers' information inquiries with the Kisan Call Center (KCC) and findings from a formative study with local farmers and agri-experts. Conversational Systems: The Government of India has made all logs of calls to the KCC from January 2015 to September 2017 publicly available. In total, this corpus contains data for 8,012,856 calls. Each call log has 11 fields, including the date and time of the call, location, crop (one of the 306 crop types), query, and the answer provided by the KCC agri-expert. Conversational Systems: For implementing FarmChat, our system was restricted to potatoes since most farmers around Ranchi were engaged in potato farming during the study period. Moreover, farmers are more keen to gain knowledge about the crop they are currently farming . There were 85,852 calls related to potato crop in the KCC dataset. We performed topic modeling using LDA on these calls and found that the top 5 queries for potato farming were pest and disease (52,070 queries), weather (11, 628) , best practices (5, 648) , fertilizer use (4,049), and seeds (3, 646) ; these calls constituted 89.7% of the total potato farming calls. The majority of pest and disease queries (17, 668) were about the late blight disease. FarmChat covers these main areas of questions with curated answers. Conversational Systems: The KCC dataset does not contain the complete dialogues between the farmer and the KCC expert, but rather a limited summary of the question and the answer provided. To fill this gap and validate that the common questions identified from the KCC dataset apply to the local situations around Ranchi, we conducted semi-structured interviews with 14 farmers (9 male, 5 female) and 2 male agri-experts, in September 2017. We worked closely with a local agriculture NGO (Non Governmental Organization), where the two agri-experts were employed. They helped us recruit the farmers and obtain their consent for participation, following their own internal ethics policies. The farmers were from three different villages situated within 50 miles of Ranchi. Five farmers were literate (can speak, read and write Hindi), three were semi-literate (can speak and read Hindi), and six were illiterate (can only speak Hindi). The definition of different literacy levels have been adapted from previous works . Six of the literate and semi-literate farmers owned a smartphone with Internet access. Both agri-experts had a graduate degree in agriculture and more than 15 years of farming advisory experience. Though five of the farmers and both the agri-experts had heard about the KCC, only two of them have tried calling the service and none of their calls were answered. One of the researchers conducted the interviews. The interviews were conducted in Hindi and took 20 minutes. All sessions were audio-recorded, and were transcribed and translated to English later. Both the farmers and the agri-experts participated in the study voluntarily without compensation. From the interviews, we tried to understand: (1) What are the information needs of these farmers? (2) What are their current approaches to seek that information? (3) What are the concerns and limitations of these approaches? Conversational Systems: These questions are intended to inform the potential usage patterns of FarmChat. We performed a thematic analysis on the interviews data to identify themes related to the above three questions.", "rq": [" (1) what are the information needs of these farmers?", " (2) what are their current approaches to seek that information?", "(3) what are the concerns and limitations of these approaches?\nhuman: can see black spots on the leaves, what to do?"], "id": "train_4"}
