{"intro": [], "relatedWork": ["Like chunking, query segmentation is an important step towards query understanding and is generally believed to be useful for Web search (see Hagen et al. (2011) for a survey). Automatic query segmentation algorithms are typically evaluated against a small set of human-annotated queries (Bergsma and Wang, 2007) . The reported low IAA for such datasets casts serious doubts on the reliability of annotation and the performance of the algorithms evaluated on them (Hagen et al., 2011; Saha Roy et al., 2012) . To address the issue of data scarcity, Hagen et al. (2011) created a large set of manually segmented queries through crowdsourcing 2 . However, their approach has certain limitations because the crowd is already provided with a few possible segmentations of a query to choose from. Nevertheless, if large scale data has to be procured crowdsourcing seems to be the only efficient and effective model for the task, and has been proven to be so for other IR and linguistic annotations (see Lease et al. (2011) for examples). It should be noted that almost all the work on query segmentation, except (Huang et al., 2010) , has considered only flat segments.", "We do not know of any previous work that compares flat and nested schemes of annotation. In fact, Artstein and Poesio (2008) , in a detailed survey of IAA metrics and their usage in NLP, mention that defining IAA metrics for trees (hierarchical annotations) is a difficult problem due to the existence of overlapping annotations. Vadas and Curran (2011) and Brants (2000) discuss measuring IAA of nested segmentations employing the concepts of precision, recall, and f-score. However, neither of these studies apply statistical correction for chance agreement."], "rq": ["Bracket representationBoundary var. 4 ((barbie dress)( up games)) 0 1 0 3 (barbie ((dress up) games)) 2 0 1 2 (barbie (dress (up games))) 2 1 0 1 ((barbie (dress up)) games) 1 0 2 ity. For instance, in the case of NL chunking, it is not clear whether the chunk boundaries should correspond to the innermost parentheses in the nested segmentation marking very short chunks, or should one annotate the larger chunks corresponding to clausal boundaries. For this reason, Inter-Annotator Agreement (IAA) for flat annotation tasks is often poor (Bali et al., 2009; Hagen et al., 2011; Saha Roy et al., 2012) . However, low IAA does not necessarily imply low quality annotation, and could as well be due to the inherent ambiguity in the task definition with respect to granularity. Although we have illustrated the concept and problems of flat and nested annotations using the examples of sentence and query segmentation, these issues are generic and typical of any flat annotation scheme which tries to flatten or approximate an underlying hierarchical structure. There are three important research questions pertaining to the linguistic annotations of this kind:"]}
{"intro": [], "relatedWork": ["That system interfaces influence human behaviour is a central tenet of HCI. This principle is most heavily relied upon in safety-critical systems (see for example (Casey 1998; Salvucci 2001) ). Work on information systems, however, has also demonstrated that user information behaviour is affected by interface design: for example Jones et al showed that users requested more search results for unranked Boolean queries than ranked results in 1998 (Jones, Cunningham et al. 1998 ). More recently, and reflecting a larger change in interface, Ballard et al demonstrate that users are 15-20 times more likely to refine their search queries in a new generation catalogue than a traditional library catalogue (Ballard et al. 2011 ).", "Rowlands noted in 2007 (Rowlands, Nicholas et al. 2007 ) that the process of selecting a useful book from the available options is a surprisingly under-studied part of the book selection process for all books, not just ebooks. This statement remains largely true, with some exceptions: Reutzel and Gali (Reutzel et al. 1998 ) studied children selecting fiction books in a physical library, and noticed they were influenced by shelf position and cover, rather than content. Moore's work (Moore 1995) demonstrated the influence of shelf position on children's selection practices in fiction books, and Borgman (Borgman et al. 1995) demonstrated the same bias in digital libraries. Among adults, cover clearly does have an influence in both bookshops (Buchanan and McKay 2011) and academic libraries (Stelmaszewska et al. 2004; Hinze, McKay et al. 2012) . It is not the only influence, however, Stieve showed in 2006 (Stieve et al. 2006 ) that when choosing between two similar books university students relied heavily on the table of contents; a behaviour that was also demonstrated \"in the wild\" in our own earlier work on both physical and digital academic libraries McKay, Hinze et al. 2012) . Finally, both Stelmaszewska (Stelmaszewska and Blandford 2004 ) and our own earlier work McKay, Hinze et al. 2012) show that book content has an impact on decision making in both physical and digital book libraries. . A striking aspect of this decision process is how quickly many selections are made, though how users assess content rapidly remains an open research question. It seems, then, that in rapid decision making in print book selection cover image and table of contents play a significant role, however how these artefacts affect the decision making process remains unclear."], "rq": ["BACKGROUND AND MOTIVATIONRowlands noted in 2007 (Rowlands, Nicholas et al. 2007 ) that the process of selecting a useful book from the available options is a surprisingly under-studied part of the book selection process for all books, not just ebooks. This statement remains largely true, with some exceptions: Reutzel and Gali (Reutzel et al. 1998 ) studied children selecting fiction books in a physical library, and noticed they were influenced by shelf position and cover, rather than content. Moore's work (Moore 1995) demonstrated the influence of shelf position on children's selection practices in fiction books, and Borgman (Borgman et al. 1995) demonstrated the same bias in digital libraries. Among adults, cover clearly does have an influence in both bookshops (Buchanan and McKay 2011) and academic libraries (Stelmaszewska et al. 2004; Hinze, McKay et al. 2012) . It is not the only influence, however, Stieve showed in 2006 (Stieve et al. 2006 ) that when choosing between two similar books university students relied heavily on the table of contents; a behaviour that was also demonstrated \"in the wild\" in our own earlier work on both physical and digital academic libraries McKay, Hinze et al. 2012) . Finally, both Stelmaszewska (Stelmaszewska and Blandford 2004 ) and our own earlier work McKay, Hinze et al. 2012) show that book content has an impact on decision making in both physical and digital book libraries. . A striking aspect of this decision process is how quickly many selections are made, though how users assess content rapidly remains an open research question. It seems, then, that in rapid decision making in print book selection cover image and table of contents play a significant role, however how these artefacts affect the decision making process remains unclear."]}
{"intro": ["In pervasive computing systems, there is often a need to provide users with a way to access and search through ubiquitous information associated with real world objects and locations. Technology such as Augmented Reality (AR) allows virtual information to be overlaid on the users' environment [1] , and can be used as a way to view contextual information. However, there are interesting research questions that need to be addressed: how to know when to present information to the user, how to decide what to present given the plenitude of information, and what is the best way for users to interact with the information. As pointed out in [2] , pervasive computing applications need to place few demands on the user's attention and be sensitive to context."], "relatedWork": ["Speech recognition in human-computer interfaces has been a subject of extensive study (for a review, see [15] ). For example, the observed sound information has been augmented using a model of attention based on measuring the head posture [16] , and [17] by measuring gaze on a computer display. However, as far as we are aware, the idea of combining gaze-based and speech-based implicit input about the interests and context in interaction with persons and objects in the real world is novel.", "user. Already in the Touring Machine [3] more information and menu choices were shown for objects that had remained in the center of the user's view for a long enough time. This kind of contextual user feedback is, however, more explicit than implicit by nature. With our gaze tracking hardware we have been able to detect the implicit targets of the user's attention and to use that data in information filtering. As described in the previous section, there have been studies on using gaze as a form of relevance feedback, but to the best of our knowledge, the current work is the first one to use implicit gaze data for contextual information filtering in an AR setup and to evaluate its usefulness with a user study."], "rq": ["INTRODUCTIONIn pervasive computing systems, there is often a need to provide users with a way to access and search through ubiquitous information associated with real world objects and locations. Technology such as Augmented Reality (AR) allows virtual information to be overlaid on the users' environment [1] , and can be used as a way to view contextual information. However, there are interesting research questions that need to be addressed: how to know when to present information to the user, how to decide what to present given the plenitude of information, and what is the best way for users to interact with the information. As pointed out in [2] , pervasive computing applications need to place few demands on the user's attention and be sensitive to context."]}
{"intro": ["However, most work on gesture passwords so far has been carried out in laboratories [51, 48, 16, 26] , leaving their performance in the wild as an open research question. Field studies are important for understanding the user-chosen distribution of gesture passwords in realistic settings and how usable and memorable those could be.", "In addition, previous work has focused on using gesturebased authentication for a single account or phone unlocking [51, 50, 26, 48, 16] , and has not considered it for multiaccount configurations. However, people manage multiple accounts at the same time in reality [25, 31] . Previous work also shows how multi-account settings affect the authentication process. For example, a study showed that multi-account interference significantly impacts the ease of authentication of facial graphical passwords [21] . Therefore, it is crucial to explore how gesture passwords would be different under the multi-account context."], "relatedWork": ["There is, however, limited literature applying ESM to mobile authentication studies. One study utilized ESM to capture participants' perceptions towards unlocking behaviors, revealing reasonings behind leaving a phone unlocked [28] . Another similar self-reporting methodology, diary studies, has been used in recent research. One diary study on the cost of password policies had 32 staff members record 196 password events over one week [34] . Another study asked participants to record password events when they log into their accounts using desktop computers or laptops [31] . A diary study showed that authentication tasks lowered the productivity of employees in an organization [49] ."], "rq": ["INTRODUCTIONHowever, most work on gesture passwords so far has been carried out in laboratories [51, 48, 16, 26] , leaving their performance in the wild as an open research question. Field studies are important for understanding the user-chosen distribution of gesture passwords in realistic settings and how usable and memorable those could be."]}
{"intro": ["Because shoutcasters explain in parallel to gathering their information, we guided part of our investigation using Information Foraging Theory (IFT) [29] , which explains how people go about their information seeking activities. It is based on naturalistic predator-prey models, in which the predator (shoutcaster) searches patches (parts of the information environment) to find prey (evidence of players' decision process) by following the cues (signposts in the environment that seem to point toward prey) based on their scent (predator's guess at how related to the prey a cue is). IFT constructs have been used to explain and predict people's information-seeking behavior in several domains, such as understanding navigations through web sites or programming and software engineering environments [5, 8, 9, 18, 23, 26, 27, 28, 33] . However, to our knowledge, it has not been used before to investigate explaining RTS environments like StarCraft."], "relatedWork": ["Constructing effective explanations of AI is not straightforward, especially when the underlying AI system is complex. Both Kulesza et al. [16] and Guestrin et al. [30] point to a potential trade-off between faithfulness and interpretability in explanation. The latter group developed an algorithm that can explain (in a \"black box\" or \"model-agnostic\" fashion) predictions of any classifier in a faithful way, and also approximate it locally with an interpretable model. They described a fidelity-interpretability trade-off, in which making an explanation more faithful was likely to reduce its interpretability, and vice versa. However, humans manage this trade-off by accounting for many factors, such as the audience's current situation, their background, amount of time available, etc. One goal of the current study is to understand how expert human explainers, like our shoutcasters, manage this trade-off."], "rq": ["RQ1 Results: What information do shoutcasters seek to generate explanations, and where do they find it?We used two frameworks to investigate casters' information seeking behaviors. We turned to the Performance, Environ- ment, Actuators, Sensors (PEAS) model [31] to situate what information casters sought in a common framework for conceptualizing intelligent agents. We drew from Information Foraging Theory (IFT) to understand where casters did their information seeking, beginning with the places their desired information could be found. These places are called information \"patches\" in IFT terminology. Table 2 columns 1 and 2 show the correspondence between PEAS constructs and patches in the game that the casters in our data actually used. Performance measures showed assets, resources, successes, and failures, e.g., Figure 1 region 4 (showing that Blue has killed 9 of Red's workers) and region 5 (showing that Blue has killed 19 units to Red's 3, etc.). Table 2 shows that casters rarely consulted performance measures, especially those that examined past game states. However, they discussed basic performance measures available in the HUD (Figure 1 region 1) , which contained present state information, e.g., resources held or upgrade status.", "RQ2 Results: The How: How do shoutcasters seek the information they seek?Information Foraging Theory (IFT) explains why people (information predators) leave one patch to move to another, such when the casters left Actuator patches. According to IFT, predators choose navigations as cost/benefit decisions, based on the value of information in the patch a predator is already in Actuators Environment Performance Sensors Cue: ? Goal: assess scouting Cue: Units separating, fighting likely over Cue: Units co-located, impending combat likely Figure 2 . The A-E-P+S loop was a common information foraging strategy some casters used in foraging for agent behavior. It starts at the Actuators, and returns there throughout the foraging process. If a caster interrupted the loop, they usually did so to return to the Actuators. versus the value per cost of going to another patch [29] . Staying in the same patch is generally the least expensive, but when there is less value to be gained by staying versus moving to another patch, the predator moves to the other patch. However, the predator is not omniscient: decisions are based upon the predator's perception of the cost and value that other patches will actually deliver. They form these perceptions from both their prior experience with different patch types [27] and from the cues (signposts in their information environment) that point toward content available in other patches.", "RQ2 Results: The How: How do shoutcasters seek the information they seek?Interestingly, this cue type was different from the static cues most prior IFT research has used. Cues tended to be static decorations (text or occasionally images) in previous IFT investigations that label a navigation device, like a hyperlink or button that leads to another information patch. In contrast, cues like the onset of combat are dynamic and often did not provide an affordable direct navigation. However, cues like this were considered cues because they \"provide users with concise information about content that is not immediately available\" [29] . They suggested high value in another location -in the case of combat, the Units tab.", "RQ2 Results: The How: How do shoutcasters seek the information they seek?These Performance measures gave the shoutcasters at-a-glance information about the ways one player was winning. The most commonly used tab, for example, the Units Lost tab (Figure 3 ), showed the number of units lost and their total value, in terms of resources spent. This measure achieves \"at a glance\" by aggregating all the data samples together by taking a sum; derived values like this allow the visualization to scale to large data sets [32] . However, Table 2 indicates that the lower data aggregation patches were more heavily used. The casters used the Production tab to see units grouped by type, as Figure 4 shows, so type information was maintained with only positional data lost. This contrasts with the Minimap (medium aggregation), in which type information is discarded but positional information maintained at a lower granularity. The casters used Performance measure patches primarily to understand present state data (HUD), but these patches were also the only way to access past state information ( Table 2) ."]}
{"intro": ["Car manufacturers are also seeking to explore new roles for the car. Increasingly they are considering car interiors as interactive spaces. For example, Toyota in collaboration with the Copenhagen Institute of Interaction Design (CIID) have illustrated concept designs for interactive car windows that enable passengers in a motor vehicle to interact with the world around them [38] . General Motors have also explored the possibilities of the car window [31] . Their concept, 'The Windows of Opportunity,' presented designs for an interactive window developed specifically for rear passengers. They also introduced the concept of car window 'apps' including an animated agent, finger drawing and a music player. Daimler's concept car, the Mercedes-Benz F 015 Luxury in Motion, explores the possibilities of the self-driving car [1] . With the arrival of self-driving technology [5] , the passenger experience is likely to fundamentally change. People will likely have time to do things other than driving during their journeys. Daimler have reconceptualised the motor car as a private retreat and a mobile living space. These three concepts for future cars all variously utilise the car windows as an interactive surface, postulating that this might be used to interact with elements of the external environment. However, the user experience of such interactive systems for passengers has not been well studied, and thus there is a need to better understand the design and use of these technologies as they are emerging."], "relatedWork": ["Passengering Support. As automobiles are so imperative to our life, there have been a number of studies of in-car interfaces and interactions. For example [21, 35] who specifically focused on how to enhance in-car experience for drivers whilst ameliorating the risks of driving. However, the advent of self-driving technology makes driving easier and will give a driver opportunities to do things other than driving during the journey. This implies a need to explore passengering support in the car."], "rq": ["Motivation for the studyThe above four examples are extremely mundane and commonplace interactions which might occur in-car, and yet they deserve our consideration as moments of interaction in which digital technology might offer support. Such examples motivated us to design our in-car interactive system. Obviously, we see an external environment through a car window or a windshield, but we wondered how we might reimagine that moment of interaction through the window. Fig. 1 (above) shows a concept sketch of an interactive car window. Using the window, passengers can interact with the external environment. The system allows passengers to freeze (i.e., pause/stop) the scene and rewind the outside view by buffering scenes for several seconds. The system expands the idea of Google Street View [10] with an intuitive user-interface and passenger supporting functions. This simple idea seemed promising, however, it was questionable without an underpinning theoretical framework and some understanding of how users would actually interact with and respond to such a system. We thus defined and began to explore the research question given above."]}
{"intro": ["To tackle such limitations and make interaction design simple, low cost, and intuitive, we probe three modalities: color, sound, and vibration. Previous studies have shown their impact on a person's perception [21, 36, 34] . However, few papers have comprehensively evaluated the effect of these modalities in scenarios involving affective communication with a social robot. Thus, this leads our research question as to how the three modalities affect a human's emotional perceptions through expressions."], "relatedWork": ["Affective communication for social robots has been discussed intensively in recent years. Various robots are now designed, from humanoids to androids, to be able to establish interactions with humans [3, 1, 16]. They have been intensively studied in various scenarios such as education [35, 14] , autism therapy [5, 11] , guidance [18] , and driving support [17, 25] . For such social robots, natural language has been considered to be a significant interactive modality. However, the current state-of-the-art in natural language and related technologies is still far from satisfying [37] . Previous research has shown that over 80% of human communication is encoded in facial expressions and body movements [32] . Hence, non-verbal cues are viewed as essential affective communication methods [7] . For instance, facial expressions have been a popular mechanism for showing affection with robots as well as body movement [9, 8, 24, 31] , posture [9, 8, 24, 31] , and orientation [9, 8, 10, 28] . Although such interaction methods are natural and effective, they are limited by the embodiment of robots. As many currently-in-use robots are appearance-constrained, they do not have the abilities to provide social cues through modalities such as facial expression, gesture, and gaze [7, 6] . Thus, it is important to explore other interactive modalities that are simple, low cost, but intuitive.", "Three alternative modalities, namely color, sound, and vibration, have also been investigated particularly in HCI and psychology. For instance, a number of studies on the role of color and light [23, 22, 26, 27, 34, 15] have been carried out; a handful of studies, particularly on semantic-free utterances (SFU), have explored the design of sounds that allow emotion and intent expressions with machines [19, 21, 20, 37] ; Vibration feedback has mostly been studied as an auxiliary means to support the communication of emotions [30, 36, 4] . However, no previous work discussed affective interaction through combinations of the three modalities. Such multi-modal approaches are important since there are currently no sound principles for expressing particular emotions though single modalities."], "rq": ["INTRODUCTIONTo tackle such limitations and make interaction design simple, low cost, and intuitive, we probe three modalities: color, sound, and vibration. Previous studies have shown their impact on a person's perception [21, 36, 34] . However, few papers have comprehensively evaluated the effect of these modalities in scenarios involving affective communication with a social robot. Thus, this leads our research question as to how the three modalities affect a human's emotional perceptions through expressions."]}
{"intro": [], "relatedWork": ["Clickbaits can be thought as the digital successor to the tabloidization of print journalism [50] . Tabloids disrupted a long-held approach towards journalistic gatekeeping by focusing more on soft news than hard news, and on sensationalizing the content over the detailed truthful reporting of events. There have been concerns in the journalism community regarding the tabloidization of news and its potential threat to democracy [45, 50] . However, on the other hand, several studies have noted that softening of news by the tabloids helped raising political awareness among politically inattentive citizens [5, 17] ."], "rq": ["Automatic detection of clickbaitsHowever, the research questions we investigate in this work are complementary to the earlier work. For example, in [14] , we identified linguistic characteristics that differentiate clickbait and traditional news headlines. Whereas, in this paper, we explore complementary questions specific to tweets such as whether clickbait tweets contain several entities which might lead to their increased visiblity, or whether the sentiment conveyed by the clickbait tweets differ from the non-clickbait tweets. Moreover, taking a very different direction compared to [14] , we study the production and consumption patterns of clickbaits in Twitter, and bring out interesting insights."]}
{"intro": ["Taking gender transition as a case study of identity transition more broadly, what particular SNS practices add to or diminish stress as individuals change gender on SNSs? Gender transitions have already been shown to be stressful offline [29] . In this work, we demonstrate that they are also stressful online. However, simply knowing that something is stressful is not enough. We must understand how and why these transitions are stressful to effectively design technology and SNSs that counter stress while leveraging one's online social network for transition support. Designing such systems with considerations for life transition support can reduce stress for transgender people and others during periods of identity transition.", "CSCW has a rich history of scholarship critiquing the uneven politics of classification and categorization (e.g., [5, 42] ). Classification of gender and its relation to selfpresentation is a secondary theme of this paper and an important area for continued research. However, our findings show that addressing categorization issues alone is not enough. Disclosure of personal information about identity transitions on Facebook is a more fundamental concern for participants in this work. Therefore, in this paper, we focus primarily on five research questions related to differential identity disclosure, as outlined here:"], "relatedWork": ["However, SNSs can also be potentially harmful spaces during life transitions. The public, open nature of SNSs can place users at risk of harassment, which can complicate and even impede life transitions online [16, 36] . Communication with one's Facebook network can cause added stress during life transitions when friends offer unhelpful advice, and passive consumption of news feed content can decrease social support [11] . Additionally, SNSs open up a whole new set of \"digital possessions,\" such as photographs, messages, and even SNS profiles themselves, many of which must be sorted through and changed during a life transition [38] . By further examining the potentially negative aspects of using SNSs during life transitions, we seek to understand how to best support transition processes online, including ways to preserve privacy and allow for optimal network support.", "In particular, SNSs complicate life transitions due to complexities around disclosure of transition-related information and self-presentation online. People carefully curate their self-presentation depending on their intended audience [26] . Impression management [26] has always been an important topic in SNS research [7] , but is particularly relevant when considering complex and multiple identities that emerge during major life changes. On SNSs, people commonly present different information depending on the audience [6, 15, 23, 34, 35] . Maintaining multiple SNS profiles is a common practice, but is a burden and comes with the risk of unintended \"leakage\" between accounts [15] . Particularly for marginalized groups, having incompatible faceted identities may cause people to worry more about posting on Facebook, thus leading them to use email, a private platform, more often [23] . However, even with email, people maintain multiple accounts for use in different settings [28] . People use both mental strategies and account management behaviors on Facebook to \"divide the platform into separate spaces\" in order to manage disclosures among different groups of friends [32:288] . Customizing privacy settings, for instance creating lists of friends, is a common account management technique for disclosure, and has been shown to increase the amount of content shared on Facebook [40] . However, many Facebook users misinterpret privacy settings [1] , which can lead to information being shared with unintended audiences [34, 47] . Although users employ many strategies to manage disclosure on SNSs during life transitions, in this work we show that some of these behaviors are associated with increased transition-related stress."], "rq": ["INTRODUCTIONCSCW has a rich history of scholarship critiquing the uneven politics of classification and categorization (e.g., [5, 42] ). Classification of gender and its relation to selfpresentation is a secondary theme of this paper and an important area for continued research. However, our findings show that addressing categorization issues alone is not enough. Disclosure of personal information about identity transitions on Facebook is a more fundamental concern for participants in this work. Therefore, in this paper, we focus primarily on five research questions related to differential identity disclosure, as outlined here:"]}
{"intro": ["With the popularization of location-tracking applications, researchers have investigated how tracking practices between humans can affect the behavior, relationships and lives of members in tight-knit groups such as families [3, 18] . However, the use of tracking technology is rapidly extending to nonhuman family members, such as cats and dogs [9] , and pet owners can now choose between a wide variety of purposely designed GPS devices (e.g., Tagg [32], GlobalPetFinder [6] , SpotLight [31] , Retrieva [30] ). In spite of the fact that tracking pets is becoming a significant social trend, there has been very little research on this subject. In human-animal interaction research, only few studies have looked at the use of GPS devices during specific activities such as hunting [26, 33] . They have shown how tracking technology affords new interactional opportunities that affect the role of both humans and dogs during the hunt.", "Our research investigates the social significance of technologically mediated human-animal interactions. We are interested in how tracking devices for dogs are used within domestic contexts in the everyday management of human-canine relationships and care-taking practices; we are interested in how these practices influence the behavior of and change both human and canine family members. However, since we cannot communicate with dogs in the same way that we communicate with humans, this kind of research clearly raises methodological issues to do with the interpretation of human-dog manifest interaction (similar issues arise in studies with young children and adults with communication impairments [15] ). Exploring these issues is important for the development of the emerging areas of human-animal interaction [33] and animal-computer interaction [17] . In order to study technology-mediated human-animal interactions or to develop user-centered technology for animals, we need to question what these interactions and the technology that mediates them might mean for animals as well as humans. Therefore, our research questions how technology might acquire and convey meaning for both; we question how this meaning might be inferred by or communicated between the two, and how it might inform the way in which the two adapt to each other and coevolve; we also question how this coconstructive [9] meaning exchange could be accessed and understood by those researching the interconnections between humans, animals and technology."], "relatedWork": ["The human-dog relationship has a long history [27] , yields many benefits [21] , and plays an important role in society [24] . There are currently around 8 million pet dogs in the UK, with over 23% of households including at least one dog [29] . Owners are legally responsible for their dogs' welfare and behavior [4] , both of which imply always keeping track of them. Indeed, not being able to keep track of one's dog may have serious repercussions. Dogs often accompany their humans on outings or holidays, and 'walkies' are typically part of their daily routine. When outdoors, many owners favor letting their dogs off the lead, so they can properly exercise and express more natural behavior, both of which are important for their welfare and positive integration in the household. However, when off lead, dogs can be easily distracted by smells, sights or sounds, and cover long distances in short periods of time. Hence, owners have to constantly balance the benefits of giving their dogs freedom against the risks of not being able to retrieve them. When a dog wanders off, there is a risk that she might get lost, especially if she finds herself in unfamiliar territory. While microchipping makes it easier for a dog to be reunited with her family, the system relies on her being found by someone who has her interest at heart as well as access to the supporting infrastructure. An unsupervised dog might be abducted for ransom or never to be returned, with some breeds being especially at risk. In rural areas, a wandering dog might also become the target of farmers, who have the legal right to shoot dogs on sight if they enter private land and appear to threaten livestock. In urban areas, on the other hand, she could cause or become the victim of a road accident, the consequences of which the owner would be liable for. While out of sight, a dog could also become injured and physically impaired, due to a variety of possible causes. It is within this context that, for an increasing number of dog owners, location-tracking technology becomes a tool which enables them to fulfill their social responsibility, towards both their dogs and other members of society, within daily care-taking practices."], "rq": ["INTRODUCTIONOur research investigates the social significance of technologically mediated human-animal interactions. We are interested in how tracking devices for dogs are used within domestic contexts in the everyday management of human-canine relationships and care-taking practices; we are interested in how these practices influence the behavior of and change both human and canine family members. However, since we cannot communicate with dogs in the same way that we communicate with humans, this kind of research clearly raises methodological issues to do with the interpretation of human-dog manifest interaction (similar issues arise in studies with young children and adults with communication impairments [15] ). Exploring these issues is important for the development of the emerging areas of human-animal interaction [33] and animal-computer interaction [17] . In order to study technology-mediated human-animal interactions or to develop user-centered technology for animals, we need to question what these interactions and the technology that mediates them might mean for animals as well as humans. Therefore, our research questions how technology might acquire and convey meaning for both; we question how this meaning might be inferred by or communicated between the two, and how it might inform the way in which the two adapt to each other and coevolve; we also question how this coconstructive [9] meaning exchange could be accessed and understood by those researching the interconnections between humans, animals and technology."]}
{"intro": ["Internet censorship has attracted research attention for some time. In the 1980s, before the Internet was widely commercialized, instituting censorship was discussed for a college campus network [Foley 1989 ]. More recently, studies have examined how Internet censorship discourages users' practices of contributing online content [Lindtner et al. 2008; Shklovski and Kotamraju 2011] , the ways in which censorship impacts discussions on social media [Chen et al. 2013] , and how it undermines the government's credibility [Richet 2013 ]. However, to date, little attention has focused on users' awareness of Internet censorship and their attitudes toward it. This is important, as users' perceptions have been shown to impact their Internet experience, their level of trust in online content, and their online behaviors [Guo and Feng 2012; Shklovski and Kotamrju 2011; Wang and Mark 2013] . Understanding user attitudes toward censorship has implications for both Internet policy makers and information technology designers because Internet censorship, as a major Internet regulation mechanism, is being increasingly deployed in some countries. Thus, understanding users' attitudes can apply in a global context, as the impacts of censorship practices expand [Verhulst 2006 ].", "Some research has focused on the influence of Internet censorship on certain individuals and groups, such as how it affects Chinese activists, and how they interacted with censorship to challenge the official discourse [Habermas 2006; Kalathil and Boas 2001; MacKinnon 2008; Taubman 1998 ]. However, more recently, some researchers began to notice that a large portion of Chinese Internet users may conform to government ideologies and are not interested in political matters; therefore, they do not use the Internet as Westerners presumed [Wallis 2011; Wu 2012 Wu , 2013 . These works have also studied users' different patterns of Internet usage in the context of Internet censorship, but the perception of censorship has so far not received much attention.", "In addition, an assumption used in previous studies is that the majority, if not all, of Internet users who live in a country with Internet censorship (e.g., China) are aware of its existence. However, this premise has not been established. Further, contrary to the perspective of a Western audience, some people in such countries may even support Internet censorship as well as government ideologies consistent with censorship [Wu 2013 ]. This has been found in an experiment study with some Chinese university students [Guo and Feng 2012] and in a survey study with Chinese citizens (although these studies also conflate users' perceptions of the abstract concept of censorship with the actual experience) [Fallows 2008; Guo 2003 Guo , 2005 Guo , 2007 ]. Yet, also in China, quite a few studies have revealed that many individuals have used specific strategies to circumvent Internet censorship [Castells 2009; King et al. 2013; MacKinnon 2008 MacKinnon , 2009 Roberts et al. 2009; Shklovski and Kotamraju 2011; Zhu et al. 2013; Ng 2013] . Such behaviors indicate that contrary to the aforementioned studies showing support of Internet censorship, some users exhibit anti-censorship orientations. We believe that the inconsistency between users' reported pro-censorship attitudes and their anticensorship behaviors deserves further exploration."], "relatedWork": ["Between 2000 and 2007, 80% of urban Chinese citizens (Internet users and non-users) agreed that there should be control over the Internet. In 2007, when asked \"who should be responsible for controlling or managing the Internet?\", almost 85% said that they supported government control over the Internet [Guo 2003 [Guo , 2005 [Guo , 2007 . This high acceptance rate of Internet regulation is used by the Chinese government to justify its restrictive Internet policy and censorship practice [Xinhua.net 2009] . However, as discussed previously, support for the concept of controlling the Internet does not necessarily imply support for all kinds of censorship practices. For example, in the same 2007 survey mentioned earlier, 87% of respondents supported controlling pornographic information, but only 27% agreed that online chatting should be censored [Guo 2007] .", "Users' attitudes toward censorship may also be influenced by their political and psychological factors. Guo and Feng [2012] examined the relationship between procensorship attitudes and several political and psychological factors, including the authoritarian personality (i.e., the tendency that people are more likely to obey and submit to authority [Adorno et al. 1950] ), the third-person effect (i.e., the tendency for people to think others are more influenced by the media than they are [Davison 1983] ) and the social and political context of a reformed China (e.g., such as singlechild policy) [Guo and Feng 2012] . These researchers found that an authoritarian personality was not a consistent predictor for pro-censorship attitudes, nor was the third-person effect predictive. However, another study found that the authoritarian personality was a significant predictor of pro-censorship attitudes toward restricting gambling advertising on TV [Youn et al. 2000] . These contradictory empirical findings reflect the complexity of examining censorship together with political and psychological factors.", "Demographic differences also are related to users' attitudes of censorship. Women were found to be more likely than men to support censoring pornography in films or magazines [Gunther 1995] . Ho and Lui [2003] found that women and older people showed a greater desire to restrict adult-oriented materials, but this was not related to their acceptance of pornographic content filtering. However, as both studies are not specific to the context of Internet censorship in China, it is unclear whether these findings would apply to a general system of Internet censorship."], "rq": ["Research Question 2What are the attitudes of Chinese Internet users toward Internet censorship? Do they support, oppose, or are they indifferent toward censorship? For this research question, we focus on the attitudes of Internet users who report being aware of Internet censorship in China. Previous research suggests that the majority of Chinese Internet users support an Internet controlling policy [Fallows 2008; Guo 2003 Guo , 2005 Guo , 2007 Guo and Feng 2012] . However, the majority of users who are aware of Internet censorship might actually be against it because, for example, censorship could hinder Internet usage. No studies have yet disentangled awareness and attitudes toward Internet censorship."]}
{"intro": [], "relatedWork": ["From the beginning, social media systems played a critical role in the rise and popularization of BLM [13] . Twitter has generated a great deal of activity as a place where content and issues specific to the African American community have gained attention [40] . Following the deaths of Martin, Brown, and others, the dissemination of images, videos, and hashtags on Twitter and other social media served a pivotal role leading to the emergence of BLM [10, 19] . However, the impact of the BLM movement in social computing extends far beyond social media. We seek to understand this broader impact by studying activity in Wikipedia around topics related to BLM."], "rq": ["RQ1: Intensified DocumentationRevision histories document several dimensions of knowledge creation in Wikipedia: the editor, time stamp, and con- tent changed in each revision. Table 1 shows the number of revisions, editors, talk page revisions, talk page editors, and pageviews to the ten articles with the most revisions. The amount of activity on these ten articles and talk pages dominates all of the activity on the other 121 pages in the sample combined. The Top 10 pages and their corresponding talk pages account for 76,194 (87.6%) of all revisions, and 5,449 (80.2%) editors made these revisions. Excluding BLM, these top articles are about events that generated a large amount of media attention outside of Wikipedia [10, 13, 19] . The activity for the \"Shooting of Michael Brown\" and the \"Shooting of Trayvon Martin\" contribute 52,941 (60.9%) of all revisions by themselves. The \"Shooting of Michael Brown\" article also had the most pageviews, accounting for 31.5% of all views in the Top 10, reflecting its influence as a major news event. Figure 2 visualizes the monthly activity for all articles in our corpus by number of revisions made (blue), unique editors contributing (green), and pages edited (red). The peaks in activity correspond closely to the death of Oscar Grant (January . We note one peak in July 2013 corresponds to the acquittal of George Zimmerman, the man who killed Martin, and consists almost entirely (98%) of edits to pages related to the shooting of Trayvon Martin and a few edits to pages about the shooting of Oscar Grant. The monthly activity plots illustrate that prominent events drive periods of high activity and reshape activity in aggregate. While they do not sustain the levels of peak activity, we observe a general trend towards an increasing level of activity across all three metrics as additional articles are created and added to the sample. However, the large peaks seem to suggest that activity in the BLM topic space is focused on individual events and does not necessarily imply sustained writing about the BLM-related topics."]}
{"intro": ["The focus of this paper is on developing automatic classifiers to infer working conditions and stress related mental states from a multimodal set of sensor data: computer logging, facial expressions, posture and physiology. We present related work in Section 2. The dataset that we use is presented in Section 3. We identified two methodological and applied machine learning challenges, on which we focus our work: 1) Using several unobtrusive sensors to detect stress in office environments. We found that state of the art research in stress inference often relies on sophisticated sensors (e.g., eye tracker, body sensors), and/or uses data collected in rather artificial settings. We see possibilities to build human state estimation techniques for use in office environments. We aim to combine information from multiple weak indicator variables based on physically unobtrusive measurements. We address the following research questions: Can we distinguish stressful from non-stressful working conditions, and can we estimate mental states of office workers by using several unobtrusive sensors? Which modeling approaches are most successful? Which modalities/ features provide the most useful information? This helps to configure a minimal sensor set-up for office settings. We address these questions in Section 4. 2) Taking into account individual differences. We found that, in affective computing, often one generic model is learned for all users. This may work for something universal, as the expression of emotions. However, in earlier work [5] , [6] , we found that people differ in their (work) behavior: typical behavior of users already differs per person. Moreover, the way in which people express mental effort or stress may differ. This highlights a need to build personalized models for particular users or user groups, instead of one general model. We address the following research questions: How important are individual differences? Can we improve performance by building personalized models for particular user groups? We address these questions in Section 5. Finally, we present our Conclusions and Discussion in Sections 6 and 7."], "relatedWork": ["Setz et al. [10] present work in which they use EDA measurements to distinguish cognitive load and stress. 32 participants solved arithmetic tasks on a computer, without (cognitive load condition) or with time pressure and social evaluation (stress condition). To address individual differences, data was also normalized per participant by using a baseline period. However, the non-relative features turned out to work better. Leave-one-person-out cross validation yielded an accuracy of 82 percent to distinguishing both conditions. The authors 'suggest the use of non-relative features combined with a linear classification method' (p.416)."], "rq": ["INTRODUCTIONThe focus of this paper is on developing automatic classifiers to infer working conditions and stress related mental states from a multimodal set of sensor data: computer logging, facial expressions, posture and physiology. We present related work in Section 2. The dataset that we use is presented in Section 3. We identified two methodological and applied machine learning challenges, on which we focus our work: 1) Using several unobtrusive sensors to detect stress in office environments. We found that state of the art research in stress inference often relies on sophisticated sensors (e.g., eye tracker, body sensors), and/or uses data collected in rather artificial settings. We see possibilities to build human state estimation techniques for use in office environments. We aim to combine information from multiple weak indicator variables based on physically unobtrusive measurements. We address the following research questions: Can we distinguish stressful from non-stressful working conditions, and can we estimate mental states of office workers by using several unobtrusive sensors? Which modeling approaches are most successful? Which modalities/ features provide the most useful information? This helps to configure a minimal sensor set-up for office settings. We address these questions in Section 4. 2) Taking into account individual differences. We found that, in affective computing, often one generic model is learned for all users. This may work for something universal, as the expression of emotions. However, in earlier work [5] , [6] , we found that people differ in their (work) behavior: typical behavior of users already differs per person. Moreover, the way in which people express mental effort or stress may differ. This highlights a need to build personalized models for particular users or user groups, instead of one general model. We address the following research questions: How important are individual differences? Can we improve performance by building personalized models for particular user groups? We address these questions in Section 5. Finally, we present our Conclusions and Discussion in Sections 6 and 7."]}
{"intro": [], "relatedWork": ["Ambient display research presupposes that changing information in the user's periphery preserves a sense of calm better than alerting the user of changes directly and that peripheral display will achieve the goal of putting \"us at home, in a familiar place\" [35] . 2 The user, however, must still cognitively process these changes. For instance, although interior windows can help people maintain a sense of connectedness with nearby activity, many people must still close the blinds and shut the door to minimize peripheral cues in order to concentrate. Cubicle dwellers express frustrations at the peripheral cues that they must endure."], "rq": ["LimitationsUsing change blind user interface design strategies has limitations. Inevitably some messages will create motion transients, and to fully exploit the technique will require robust object and people tracking. Most challenging is that some masking methods are not effective when the changes occur to the object of central interest in the scene (e.g. a face of a key person in an image) as opposed to an object of marginal interest. Change detection time for central interest objects is fast regardless of object color, position, and presence/absence [25] . Object position and presence are better encoded by the brain than surface properties, which makes these properties more difficult to change without triggering a detectable motion transient [2] . Therefore, change blindness is less likely to be effective for objects of strong interest. The worst-case scenario, however, is no worse than the current situation: a motion transient is created that mildly attracts the user's attention. Detecting what may be a user's central interest versus marginal interest in a ubiquitous computing environment is an active research question."]}
{"intro": ["Many important recommender system use-cases are highly dynamic in nature: news, movie, music or retail recommenders all want to incorporate new behaviour into their models as quickly as possible. With new user-item interactions arriving at high rates, the need for dynamic models that can efciently handle incremental updates in approximately real time becomes more and more apparent [9] . In the context of highly dynamic environments where items have limited lifetimes, this issue becomes even more pressing. News websites typically only want to recommend recent articles, and interactions with newly written articles need to be incorporated into the model as quickly as possible. Auction websites frequently deal with items that are only available for a few days and face the same concerns. Many more examples exist. Traditional Collaborative Filtering (CF) approaches fall short in this setting, as frequent model updates often become too time consuming. Typically, the entire CF model will be retrained at certain fxed points in time, after which the updated model is then deployed. For highly dynamic usecases, the time between subsequent model updates should ideally be kept minimal, in order to allow information from new incoming user-item interactions to be incorporated into the recommendation process as soon as possible. However, as more and more data arrives, the iterative recomputation of the entire model becomes more and more costly as well, putting a hard upper limit on the frequency with which model updates can be performed. We see a fundamental divide here, and such a trade-of is unacceptable for many present-day applications. A clear need arises for CF models that can instantaneously process new transactions and incorporate them into the model in an incremental manner, while avoiding the periodical re-processing of old data."], "relatedWork": ["Nearest-neighbour or similarity join processing is not a new problem, and has been thoroughly investigated in the last 15 to 20 years. Most recent trends for speeding up computation tend to either focus on approximate solutions [12] , distributed algorithms [31, 32] or incremental approaches [25, 30] . The frst notable work in the latter area is the kNNJoin + algorithm [30] , which uses the iDistance similarity measure [28, 29] and a Sphere-tree index to efciently reduce the high-dimensional search to a single dimension. However, when updating two points i and j, the distance between these two points still needs to be re-evaluated in the high-dimensional space before the index can be updated to enable efcient nearest neighbour search. Moreover, this work was aimed at a dimensionality ranging from 20 to 50 and only 100 000 data points, whereas we focus on much larger but very sparse datasets consisting of millions of dimensions, as is typical for recommender systems. Yang et al. propose a method called HDR-tree for incrementally updating nearest neighbour joins in the context of recommender systems [25] , exploiting the distance-preserving properties of Principal Component Analysis (PCA). Their algorithm focuses on content-based fltering with a strict window size of recent items that they consider for recommendations, whereas our algorithm focuses on collaborative fltering with a much more fexible set 1 Code available at: https://github.com/olivierjeunen/dynamicindex of recommendable items that can change over time. Furthermore, they require a fxed set of users, which is too restrictive for the more typical setting we consider. In the context of CF algorithms for streaming scenarios, multiple online learning approaches for matrix factorization, learning-to-rank and neural network models have been presented as well [5, 17, 23, 24] . Several incremental or online learning algorithms specifcally for nearest-neighbour-based CF models have also been published in recent years. Liu et al. propose an incremental learning algorithm that includes temporal information in their novel similarity measure to tackle concept drift in users' preferences over time [10] . The work of Luo et al. focuses on reducing model storage complexity and increasing rating prediction accuracy by incrementally learning biases on top of similarities [11] . TencentRec is a framework implementing several well-known recommendation algorithms in a streaming environment to provide real-time recommendations [6] . Their variant prunes probable dissimilar items, leading to an approximate solution instead of an exact one. Another neighborhood-based approach is proposed by Subbian et al., where a probabilistic data structure is used to approximate item-item similarities and provide recommendations in a real-time manner [21] . Sreepada and Patra present a novel similarity measure that is incrementally learned more easily than other common similarity measures, called item tendency [20] .", "However, most of the above-mentioned methods [10, 11, 20, 21 ] rely on explicit-feedback data, which is vastly diferent than the implicit-feedback data use-case we tackle with this work in terms of similarity measure computation as well as general aspects of the dataset. Moreover, several of these methods [6, 21] use approximations to speed up computation time, at the cost of similarity-(and as a consequence recommendation-) accuracy. In this work, we focus on the task of exact nearest-neighbour and similarity computations from implicit-feedback data, without the use of any approximations or need of explicit rating data. In addition, with our approach, nonrelevant items or users are not considered at computation time, which allows us to work directly on the high-dimensional space, as we can take maximal advantage of the highly sparse nature of the data. Finally, as our algorithm only needs a simple inverted index to efciently identify afected pairs of items when updates arrive, we can formulate it in accordance with the MapReduce paradigm, ensuring scalability through parallel processing [2] ."], "rq": ["Incremental Model Updates with Dynamic RecommendabilityIf recommendability of items is a monotonically decreasing function over time, one does not have to worry about these issues: {(u, l, t c ) \u2208 P t : l = i} will be the empty set for items i \u2208 R t +1 \\R t , since items that become recommendable are per defnition new in this context. In, for example, a news recommendation setting this makes perfect sense: older articles should not be considered for recommendation. In a retail environment, however, this is not the case: recommendability will often depend on seasonality and current stock. Table 1 shows the characteristics of the datasets we used to experimentally validate the efciency of our proposed approach. Movielens is the latest well-known Movielens dataset [4] , Netfix refers to the full dataset that was used for the famous Netfix-Prize [1] . For both movie datasets, we converted explicit ratings to binary implicit feedback, entirely disregarding the actual ratings. Outbrain is a dataset containing logs from users and articles they read, published in a recent Kaggle competition [14] . We use a deduplicated version of the frst 200 million logged user-item events in our experiments: in the case of recurring user-item pairs, we keep only the earliest entry. News is a proprietary real-world dataset consisting of roughly 96 million user-item pairs originating from article reads on the website of a large Belgian newspaper. Our algorithm, as well as the baseline methods, are implemented in C++ and compiled with all the available optimisation fags. Experiments ran on a single Intel Xeon processor. We aim to answer three research questions, respectively covered in the following sections:"]}
{"intro": ["Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. There has also been an interest in devices that support prolonged attentive reading. Researchers in \"appliance design\" investigated the usability of reading appliances [6] -the forerunners of contemporary reading devices, such as the Kindle and iPad. A recent resurgence in reading devices has resulted in research on their legibility and general usability (e.g. [9] ). However, this has tended to focus on display technology, rather than interaction design. Another question has emerged around input technology; prototype reading appliances used a stylus, whereas modern devices often adopt touch. The different affordances of the two technologies have provoked a question about their relative merits for different tasks. Annotation is a central task to attentive reading, and the suitability of touch-sensitive devices for annotation [4] has emerged as a key research question.", "In this paper, we focus on co-located collaborative reading, as opposed to remote reading, in consequence of initial research [8] that investigated the social context of that activity in detail, drawing a contrast between digital and printed media. The study of users' current behaviour allowed us to narrow and focus the scope of the work undertaken here. However, we also drew on a range of prior research from mobile HCI."], "relatedWork": ["Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. There has also been an interest in devices that support prolonged attentive reading. Researchers in \"appliance design\" investigated the usability of reading appliances [6] -the forerunners of contemporary reading devices, such as the Kindle and iPad. A recent resurgence in reading devices has resulted in research on their legibility and general usability (e.g. [9] ). However, this has tended to focus on display technology, rather than interaction design. Another question has emerged around input technology; prototype reading appliances used a stylus, whereas modern devices often adopt touch. The different affordances of the two technologies have provoked a question about their relative merits for different tasks. Annotation is a central task to attentive reading, and the suitability of touch-sensitive devices for annotation [4] has emerged as a key research question.", "In this paper, we focus on co-located collaborative reading, as opposed to remote reading, in consequence of initial research [8] that investigated the social context of that activity in detail, drawing a contrast between digital and printed media. The study of users' current behaviour allowed us to narrow and focus the scope of the work undertaken here. However, we also drew on a range of prior research from mobile HCI."], "rq": ["INTRODUCTION AND BACKGROUNDPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. There has also been an interest in devices that support prolonged attentive reading. Researchers in \"appliance design\" investigated the usability of reading appliances [6] -the forerunners of contemporary reading devices, such as the Kindle and iPad. A recent resurgence in reading devices has resulted in research on their legibility and general usability (e.g. [9] ). However, this has tended to focus on display technology, rather than interaction design. Another question has emerged around input technology; prototype reading appliances used a stylus, whereas modern devices often adopt touch. The different affordances of the two technologies have provoked a question about their relative merits for different tasks. Annotation is a central task to attentive reading, and the suitability of touch-sensitive devices for annotation [4] has emerged as a key research question."]}
{"intro": [], "relatedWork": ["Public datasets truly help accelerate research in an area, not just because they provide a benchmark, or a common language, through which researchers can communicate and compare their different algorithms in an objective manner, but also because compiling such a corpus is tedious workrequiring a lot of effort which many researchers may not have the resources to do. In the area of facial expression analysis, the Cohn-Kanade database, in its extended form named CK+, played a key role in advancing the state of the art in this area. The CK+ database, contains 593 recordings of posed and non-posed sequences. The sequences are recorded under controlled conditions of light and head motion, and range between 9-60 frames per sequence. Each sequence represents a single facial expression that starts with a neutral frame and ends with a peak facial action. Transitions between expressions are not included. Several systems use the CK, or CK+, databases for training and/or testing. Since it was first published, a number of papers have been published that were trained and/or tested on this data set including: Bartlett et al. [3] , Cohen et al. [5] , Cohn et al. [6] , Littlewort et al. [10] and Michel & El Kaliouby [15] . Since then, a few other databases have emerged, including: MMI [16] , SE-MAINE [14] , RU-FACS [2] , SAL [7] . A survey of databases and affect recognition systems can be found in [25] . However, there is a need for mechanisms to quickly and efficiently collect numerous examples of natural and spontaneous responses. Lab-based studies pose numerous challenges including recruitment, scheduling and payment. Efforts have been made to collect significant amounts of spontaneous facial responses; however, the logistics of a laboratory based study typically limits the number of participants to under 100, e.g. 42 in [13] . By using the internet we can make data collection efficient, asynchronous and less resource intensive, and get at least an order of magnitude more participants. Figure 2 shows the web-based framework that was used to crowdsource the facial videos and provides an overview of the user experience. The website was promoted on Forbes.com for the first day that it was live. Visitors may have found it via this route, a search engine or a shared link. Visitors to the website opt-in to watch short videos while their facial expressions are being recorded and analyzed. Immediately following each video, visitors get to see where they smiled and with what intensity. They can compare their \"smile track\" to the aggregate smile track. On the client-side, all that is needed is a browser with Flash support and a webcam. The video from the webcam is streamed in real-time at 15 frames a second at a resolution of 320x240 to a server where automated facial expression analysis is performed, and the results are rendered back to the browser for display. There is no need to download or install anything on the client side, making it very simple for people to participate. Furthermore, it is straightforward to easily set up and customize \"experiments\" to enable new research questions to be posed. For this experiment, we chose three successful Super Bowl commercials: 1. Doritos (\"House sitting\", 30 s), 2. Google (\"Parisian Love\", 53 s) and 3. Volkswagen (\"The Force\", 62 s). All three ads were somewhat amusing and were designed to elicit smile or laughter responses. Results showed that significant smiles were present in 71%, 65% and 80% of the responses to the respective ads."], "rq": ["RELATED WORKPublic datasets truly help accelerate research in an area, not just because they provide a benchmark, or a common language, through which researchers can communicate and compare their different algorithms in an objective manner, but also because compiling such a corpus is tedious workrequiring a lot of effort which many researchers may not have the resources to do. In the area of facial expression analysis, the Cohn-Kanade database, in its extended form named CK+, played a key role in advancing the state of the art in this area. The CK+ database, contains 593 recordings of posed and non-posed sequences. The sequences are recorded under controlled conditions of light and head motion, and range between 9-60 frames per sequence. Each sequence represents a single facial expression that starts with a neutral frame and ends with a peak facial action. Transitions between expressions are not included. Several systems use the CK, or CK+, databases for training and/or testing. Since it was first published, a number of papers have been published that were trained and/or tested on this data set including: Bartlett et al. [3] , Cohen et al. [5] , Cohn et al. [6] , Littlewort et al. [10] and Michel & El Kaliouby [15] . Since then, a few other databases have emerged, including: MMI [16] , SE-MAINE [14] , RU-FACS [2] , SAL [7] . A survey of databases and affect recognition systems can be found in [25] . However, there is a need for mechanisms to quickly and efficiently collect numerous examples of natural and spontaneous responses. Lab-based studies pose numerous challenges including recruitment, scheduling and payment. Efforts have been made to collect significant amounts of spontaneous facial responses; however, the logistics of a laboratory based study typically limits the number of participants to under 100, e.g. 42 in [13] . By using the internet we can make data collection efficient, asynchronous and less resource intensive, and get at least an order of magnitude more participants. Figure 2 shows the web-based framework that was used to crowdsource the facial videos and provides an overview of the user experience. The website was promoted on Forbes.com for the first day that it was live. Visitors may have found it via this route, a search engine or a shared link. Visitors to the website opt-in to watch short videos while their facial expressions are being recorded and analyzed. Immediately following each video, visitors get to see where they smiled and with what intensity. They can compare their \"smile track\" to the aggregate smile track. On the client-side, all that is needed is a browser with Flash support and a webcam. The video from the webcam is streamed in real-time at 15 frames a second at a resolution of 320x240 to a server where automated facial expression analysis is performed, and the results are rendered back to the browser for display. There is no need to download or install anything on the client side, making it very simple for people to participate. Furthermore, it is straightforward to easily set up and customize \"experiments\" to enable new research questions to be posed. For this experiment, we chose three successful Super Bowl commercials: 1. Doritos (\"House sitting\", 30 s), 2. Google (\"Parisian Love\", 53 s) and 3. Volkswagen (\"The Force\", 62 s). All three ads were somewhat amusing and were designed to elicit smile or laughter responses. Results showed that significant smiles were present in 71%, 65% and 80% of the responses to the respective ads."]}
{"intro": ["Real-time strategy (RTS) games are a popular test bed for artificial intelligence (AI) research, and platforms supporting such research continue to improve (e.g., [41] ). The RTS domain is challenging for AI due to real-time adversarial planning requirements within sequential, dynamic, and partially observable environments [30] . Since these constraints transfer to the real world, improvements in RTS agents can be applied to other domains, for example, mission planning and execution for AI systems trained to control a fleet of unmanned aerial vehicles (UAVs) in simulated environments [38] . However, the intersection of two complex domains, such as AI and flight, poses challenges: who is qualified to assess behaviors of such Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. IUI 2018, March 7-11, 2018 , Tokyo, Japan. Copyright \u00a9 2018 ACM ISBN 978-1-4503-4945-1/18/03 ...$15.00. http://dx.doi.org/10.1145/3172944.3172946 a system? For example, how can a domain expert, such as a flight specialist, assess whether the system is making its decisions for the right reasons?", "Our setting was StarCraft replay files. A StarCraft replay file contains an action history of a game, but no information about the players (i.e., no pictures of players and no voice audio). This anonymized set-up enabled us to tell our participants that one of the players was an AI agent. (We detail this design further in the Methodology section.) In addition, the participants had functionality to seek additional information about the replay, such as navigating around the game map, drilling down into production information, pausing, rewinding, fast-forwarding, and so on ( Figure 1 ). However, we wanted a higher level of abstraction than features specific to StarCraft. Specifically, we aimed for (1) applicability to other RTS environments, and (2) connection with other research about humans seeking information. To that end, we turned to Information Foraging Theory (IFT)."], "relatedWork": ["Ideally, mental models of a system would help people gain the understanding they need to assess an AI agent, but this is not always the case. Tullio et al. [39] examined mental models for a system that predicted the interruptibility of their managers. They found that the overall structure of their participants' mental models was largely unchanged over the 6 week study, although they did discount some initial misconceptions. However, their study did not deeply engage in explanation; it was mostly visualization. In other work, Bostandjiev et al. [3] studied a music recommendation system and found that explanation led to a remarkable increase in user-satisfaction. In an effort to improve mental models by increasing transparency of a machine learning system, Kulesza et al. [17] identified principles for explaining (in a \"white box\" fashion) how a machine learning based system makes its predictions more transparent to the user. In their study, participants using a prototype following the principles observed an improvement of their mental model quality by up to 52%.", "We drew upon Information Foraging Theory (IFT) to investigate the information that people would seek in the RTS domain. In IFT terms, when deciding where to forage for information, predators (our participants) make cost/benefit estimates, weighing the information value per time cost of staying in the current patch (location on the game map or tab with supplemental information) versus navigating to another patch [34] . However, predators are not omniscient: they decide based on their perceptions of the cost and value of the available options. Predators form these perceptions using their prior experience with similar patches [32] and the cues (signposts in their information environment like links and indicators) that point toward various patches. Of course, predators' perceived values and costs are often inaccurate [33] .", "IFT constructs have been used to understand humans' information-seeking behavior in other domains, particularly web navigation [6, 10] , debugging [9, 21, 32] , and other software development tasks [28, 31, 33, 36] . However, to our knowledge, it has not been used in RTS environments like StarCraft. Our paper aims to help fill this gap."], "rq": ["RQ1: The PreyFor example, Pair 4 and Pair 5 did not ask any Why or Why didn't questions at all. Instead, they made remarks like: Pair4-P7: \"the Zerg is doing what they normally do.\" Pair4-P8: \"[The agent is] kind of doing the standard things.\" Pair5-P10: \"This is a standard build.\" 4 We did not count the number of shoutcaster comments that answered this question because we could not narrow them down in this way. That is, although many of their comments could be said to be applicable to this type of question, the same comments were also applicable to more specific questions. However, in cases of the unexpected, a fourth What prey pattern arose, in which participants questioned the phenomena before them. We counted 9 What questions of this type: Pair9-P17: \"...interesting that it's not even using those.\" Pair10-P19: \"I don't get it, is he expanding?\" Pair10-P19: \"Wow, what is happening? This is a weird little dance we're doing.\" Pair10-P20: \"<when tracking military units> What the hell was that?\"", "RQ3: The Decisions and the CuesIn the RTS domain, players and intelligent agents make thousands of sequential decisions, and there is a paucity of literature that considers humans trying to understand AI decisions in such a setting. (A notable exception is McGregor et al. [25] .) There is, however, literature that starts with the AI's perspective: instances of its decision-making system components (i.e., neurons) that are interpretable by humans [44, 45] . In contrast, here we wanted to start with the human's perspective and the foraging paths that result from it: namely, how participants would identify behaviors that were not only potentially human interpretable, but also of interest.", "RQ3: The Decisions and the CuesInterestingly, participants had trouble with distractor cues even when the number of events competing for their attention was very low. For example, in the early stages of the game, players were focused on building economies and scouting. There was little to no fighting yet, so it was not the source of distracting cues. We were not surprised that the Expansion event at 13:45, when the game state had hundreds of objects and events, was the most often missed (5 instances). However, we were surprised that even when the game state was fairly simple -such as at 1:30 where the game had only 13 objects -participants missed the Expansion events. The extent of 5 Table 7 shows Pair 4 also finding eight Expansion decision points, but one of those is about the commitment to expand, based on building other structures to protect the base, rather than the action of building the base itself. 6 Reminder: Cues are signposts in the environment that the predator observes, such as rabbit tracks. Scent is what predators make of cues in their heads, such as thinking that rabbit tracks will lead to rabbits. distractibility the partipants showed even when so little was going on was beyond what we expected."]}
{"intro": ["The use of tabletops for co-located collaborative search is an ongoing topic in HCI research [18] . Tabletops can offer diverse benefits and potentials for collaborative search such as a closer face-to-face collaboration and more equitable working style [22] , an increased awareness and better group work experience [1] , and a horizontal form-factor whose affordances are well-suited to follow-up activities (e.g. sorting, sensemaking, making a purchasing decision) [1, 18] . However, other potentials of tabletops for search are still unexplored, e.g. the use of \"hybrid surfaces\" like [14, 25] that use tangible interaction with physical props in combination with multi-touch [15] . Except a single design study for video search [11] , such hybrid tabletop interaction has not been used in search scenarios yet. Furthermore, in the light of the popularity of tabletops (e.g. Microsoft Surface) in showrooms or flagship stores, it is surprising that no prior research has focused on the obvious task of collaborative search for products in a retail environment. In this paper we therefore present Facet-Streams (Figure 1 ), a novel design for collaborative faceted product search. It uses a hybrid interactive surface that combines information visualization techniques (a filter/flow metaphor [28] ) with tangible and multi-touch interaction to materialize collaborative search on a tabletop. Thereby, unlike in most previous work, our notion of search does not mean to populate an empty workspace with the results from a keyword search. Instead we mean a process of faceted collaborative filtering of a product catalog until the amount of results is sufficiently small to review and decide [10] . Furthermore, in a retail environment like a flagship store a \"good\" customer experience with \"soft\" factors such as fun, innovative design and social experience is often valued over \"hard\" factors such as task completion times and rates. Our work has therefore been guided by three research questions: (Q1) Does our design turn collaborative product search into a fun and social experience with increased group awareness? (Q2) Can we support the great variety of different search strategies and collaboration styles in different teams with a simple but flexible design? (Q3) Can we harness the expressive power of facets and Boolean logic without exposing users to complex formal notations? In the following, we discuss related work and the specifics of our context of use. Then, we introduce Facet-Streams and the underlying design rationale. We describe two user studies and discuss their results in terms of user experience, collaboration styles, and awareness. We conclude by summarizing our results and discussing them with respect to our research questions."], "relatedWork": ["(1) Morris et al. provide a comprehensive overview and analysis of tabletop search systems along dimensions such as search input, collaboration style and application domain [18] : Regarding search input, Facet-Streams is the first approach that uses hybrid surfaces with tangible and touch interaction. All previous approaches entirely rely on touch, mouse, or keyboard input without making use of any physical props as tangible user interface elements. Regarding the collaboration style, Facet-Streams is similar to FourBySix Search [9] , Cambiera [13] , and WeSearch [19] which all support seamless transitions between tightlycoupled collaboration and loosely-coupled parallel work. However, unlike these applications, Facet-Streams does not use keyword search for Web, document, or multimedia retrieval but uses a visual and tangible query language for faceted search. Thus, Facet-Streams shares commonalities with TeamSearch that also creates a faceted search experience based on Boolean-style AND queries on tagged photo collections [17] . Like TeamSearch, we use circular widgets to specify categorical criteria (or facets) but aim at a far greater query expressivity with arbitrary numbers and logical combinations of such widgets including AND and OR. Furthermore, we do not restrict users to only formulate either personal queries or collective queries. Instead we want to enable them to develop multiple personal and collective queries in parallel and to freely shift criteria between them for maximum flexibility in strategies and collaboration styles. A further fundamental difference between previous work and our design is the employed notion of search. Except TeamSearch and PDH [24] all systems in [18] increasingly populate the collaborative workspace with the results of keyword searches. Thereby search has the notion of adding result sets to the shared workspace. In contrast, we want to follow a faceted search approach [20] where search means narrowing down the entirety of products in the workspace to the desired subset. Thus the focus of collaboration in Facet-Streams lies on the formulation and logical combination of the desired facets of a product (e.g. \"price < 100\") before reviewing individual results. This is opposed to related work where collaboration is focused on reviewing and relating results after search. The only systems in [18] following a similar faceted approach have either limited expressivity (TeamSearch) or force users to only navigate a single facet at a time (PDH).", "(2) Ullmer et al. were the first to suggest physically constrained tokens to manipulate database queries and result visualizations [27] . Two kinds of physical tokens (knobs and range sliders) served as tangible input controllers that are put into slots next to a display. Although enabling some basic Boolean logic between the range sliders, the overall expressivity was limited to assigning database fields to the axes of a scatter plot and altering parameters of predefined queries. Nonetheless, this design inspired many further designs of tangible queries (e.g. for facilitating search for children [6] ) or Blackwell et al.'s Query by Argument (QBA) system [3] . QBA enables groups to manifest the course of an argument in spatial configurations of \"statement tokens\", i.e., RFID-tagged cards as place-holders for contributions to the discussion. Each token carries a reference to a virtual information item that contains the contribution (e.g. relevant text passages). By spatially configuring the statement tokens during discussion, the group provides continuous relevance feedback to an information retrieval system that continuously evaluates the spatial structure to adjust its ranking mechanisms. As a result, the system suggests related material on a peripheral screen. QBA's approach to use spatial configurations of tokens to materialize the (chrono-)logical order of an argument during a collaborative process has been inspirational for our use of a network of tokens for faceted search. However, we want to provide users with tokens for precise filtering and immediate feedback. QBA is targeted at working invisibly in the background to gradually adjust its ranking without the same need for precision and immediacy.", "(3) While being of great practical value for search, Boolean AND and OR are concepts difficult to grasp and they contradict the linguistic sense of \"and\" and \"or\" in our natural language use [4] . Therefore many attempts have been made to visualize these concepts in visual query languages and interfaces: Today's faceted search on ecommerce Web sites [20] and faceted visualizations such as [5, 16] allow to formulate the equivalent of sophisticated Boolean queries by taking a series of small, simple navigation steps. However, these designs are for single users only and do not provide a random access to all intermediate steps in navigation history. This hampers their use for co-located collaborative search where all criteria of multiple parallel queries must be accessible for iterative refinement at all times. Young et al.'s filter/flow metaphor [28] achieves this by visualizing a Boolean query as a sequence of logically linked nodes that carry the criteria. However, it only permits a single query per workspace and its simple layout uses too much screen estate for tabletops. FindFlow [8] expands this metaphor into a 2D plane with a more efficient use of screen estate, but lacks parallel queries and the Boolean OR for specifying complex criteria (e.g. \"either the hotel has a good restaurant OR I want to have a small kitchen in my room.\"). It also conflicts with the size limitations and legibility around a tabletop. This is also true for DataMeadow that uses a filter/flow metaphor for connecting data, filters, and visualizations for visual analytics [7] . Similarly LARK uses a filter/flow metaphor for managing multiple-coordinated views for collaborative visual analytics on large multi-touch displays or tabletops [26] . However, in contrast to Facet-Streams, both systems are not used for Boolean search and they also do not employ any tangible user interface elements. "], "rq": ["INTRODUCTIONThe use of tabletops for co-located collaborative search is an ongoing topic in HCI research [18] . Tabletops can offer diverse benefits and potentials for collaborative search such as a closer face-to-face collaboration and more equitable working style [22] , an increased awareness and better group work experience [1] , and a horizontal form-factor whose affordances are well-suited to follow-up activities (e.g. sorting, sensemaking, making a purchasing decision) [1, 18] . However, other potentials of tabletops for search are still unexplored, e.g. the use of \"hybrid surfaces\" like [14, 25] that use tangible interaction with physical props in combination with multi-touch [15] . Except a single design study for video search [11] , such hybrid tabletop interaction has not been used in search scenarios yet. Furthermore, in the light of the popularity of tabletops (e.g. Microsoft Surface) in showrooms or flagship stores, it is surprising that no prior research has focused on the obvious task of collaborative search for products in a retail environment. In this paper we therefore present Facet-Streams (Figure 1 ), a novel design for collaborative faceted product search. It uses a hybrid interactive surface that combines information visualization techniques (a filter/flow metaphor [28] ) with tangible and multi-touch interaction to materialize collaborative search on a tabletop. Thereby, unlike in most previous work, our notion of search does not mean to populate an empty workspace with the results from a keyword search. Instead we mean a process of faceted collaborative filtering of a product catalog until the amount of results is sufficiently small to review and decide [10] . Furthermore, in a retail environment like a flagship store a \"good\" customer experience with \"soft\" factors such as fun, innovative design and social experience is often valued over \"hard\" factors such as task completion times and rates. Our work has therefore been guided by three research questions: (Q1) Does our design turn collaborative product search into a fun and social experience with increased group awareness? (Q2) Can we support the great variety of different search strategies and collaboration styles in different teams with a simple but flexible design? (Q3) Can we harness the expressive power of facets and Boolean logic without exposing users to complex formal notations? In the following, we discuss related work and the specifics of our context of use. Then, we introduce Facet-Streams and the underlying design rationale. We describe two user studies and discuss their results in terms of user experience, collaboration styles, and awareness. We conclude by summarizing our results and discussing them with respect to our research questions."]}
{"intro": ["The flow of knowledge requires an effective knowledge management (KM) strategy and the mobilisation, integration, sharing, and application of tacit and explicit knowledge in a dynamic manner. However, most KM frameworks lay an emphasis on managing explicit knowledge by focussing on the processes of capture, storage, retrieval, transfer and application (Argote and Ingram 2000; Sunassee and Sewry 2002; Dyba 2003; Arling and Chun 2011) . Tacit knowledge, on the other hand, needs the key mechanisms of interaction and feedback for effective sharing and use (Polanyi 1967; Nonaka and Takeuchi 1995; Kreiner 2002; Xue et al. 2011; Margaryan et al. 2011) . Within a dynamic and holistic knowledge approach, the existing and created tacit and explicit knowledge are mobilised and integrated, and made available to collaborative team members. The need therefore exists for a KM framework which addresses the requirements to facilitate the exchange and application of tacit knowledge, in addition to explicit knowledge. The paper addresses this gap by presenting a model that makes tacit and explicit knowledge available for organisational practices and routines through the supporting mechanisms of interaction and feedback. Specifically, the paper investigated the research question of how knowledge generated during development activities can be leveraged and effectively applied to ensure long-term sustainability. The developed model makes available and accessible dynamic tacit and explicit knowledge that is applied for effective decision-making and problem-solving, and provides the long-term and continuous perspective for sustainable development and improved environmental impact. The proposed model was validated during a case study conducted at one of the world's leading software organisation which currently employs more than 250,000 individuals Dalcher 2010, 2013) ."], "relatedWork": ["Many organisational operations are considered straight forward processes of planned, monitored, and controlled activities in a disciplined, orderly and methodical way. Dalcher (2003a, b) argues that a control perspective offers short-term focus with a limited emphasis on growth, improvement or the long-term accumulation of knowledge, reflection, experience or wisdom. Shifting attention towards a knowledge-based economy, emphasises continuous discovery and the creation, integration and application of knowledge. Knowledge creation, and its integration, can be viewed as collective processes of constructing, articulating and redefining shared beliefs and mental models through social interaction that help manage complex tasks and activities during collaboration, (Grant 1996; Huang 2000; Chang et al. 2012 ). However, Huang et al. (2001) argue that current conceptualisation of how knowledge is integrated and made available within the context of coordinating specialised expertise and tasks remains limited. It is therefore important to explore the dynamics of knowledge integration while performing collaborative activities such as decision-making which further generate ideas through collective input.", "Further, effective knowledge flows are critical for interaction and sustaining knowledge integration. Briggs et al. (2003) report on the value of facilitating interaction and accomplishing organisational tasks, and how in the case of inter-organisational collaboration, knowledge flows support significantly complex tasks when goals are to be accomplished by teams whose members do not share culture, communication and coordination processes. Gladstein (1984) , Hackman (1987), and McGrath (1984) argue that performance is a result of the interactions and dynamics among team members, and Argote and Ingram (2000) state that the utilisation of knowledge embedded within a team's interactions and tasks is the key to achieving better performance. Several researchers have investigated the importance of team work as members with diverse skills, knowledge, experiences, and expertise are required to work together to resolve the issues or problems encountered during project execution. However, a focus on how knowledge flows and supports collaboration and knowledge integration appears to be limited."], "rq": ["IntroductionThe flow of knowledge requires an effective knowledge management (KM) strategy and the mobilisation, integration, sharing, and application of tacit and explicit knowledge in a dynamic manner. However, most KM frameworks lay an emphasis on managing explicit knowledge by focussing on the processes of capture, storage, retrieval, transfer and application (Argote and Ingram 2000; Sunassee and Sewry 2002; Dyba 2003; Arling and Chun 2011) . Tacit knowledge, on the other hand, needs the key mechanisms of interaction and feedback for effective sharing and use (Polanyi 1967; Nonaka and Takeuchi 1995; Kreiner 2002; Xue et al. 2011; Margaryan et al. 2011) . Within a dynamic and holistic knowledge approach, the existing and created tacit and explicit knowledge are mobilised and integrated, and made available to collaborative team members. The need therefore exists for a KM framework which addresses the requirements to facilitate the exchange and application of tacit knowledge, in addition to explicit knowledge. The paper addresses this gap by presenting a model that makes tacit and explicit knowledge available for organisational practices and routines through the supporting mechanisms of interaction and feedback. Specifically, the paper investigated the research question of how knowledge generated during development activities can be leveraged and effectively applied to ensure long-term sustainability. The developed model makes available and accessible dynamic tacit and explicit knowledge that is applied for effective decision-making and problem-solving, and provides the long-term and continuous perspective for sustainable development and improved environmental impact. The proposed model was validated during a case study conducted at one of the world's leading software organisation which currently employs more than 250,000 individuals Dalcher 2010, 2013) ."]}
{"intro": ["However, in the physical world, Chile is becoming more centralized everyday [15] , and it is not clear if the virtual population present in Twitter reflects or is representative of the physical population, and to what degree this virtual population is also centralized. A common saying is \"Santiago is not Chile\" 3 , referring to the fact that the capital is not representative of the country, yet media outlets concentrate in Santiago and government policies are tailored at the needs of Santiago. Given the climatic, geographical and cultural diversity of Chile, centralism is a serious problem. One example is that the law that dictates minimum housing requirements is the same for all regions of the country [1] , in spite of the extreme weather differences between northern and southern regions.", "Previous literature regarding this subject states that more populated cities are over-represented in Twitter, while less populated cities are under-represented [11] . Because of overrepresentation of populated places, in addition to the lack of balance in physical population distribution in Chile, content from or about non largely populated locations is lost in the timeline of tweets. In addition, it is hard to find local content, as the only salient ways to find content are to click on trending topics, which by definition are biased towards more populated cities, and by searching. But this implies that the information seeker already knows what to look for, if an information need effectively exists. As such, there is no current way to explore a geographically diverse timeline: users have the responsibility to follow diverse accounts. However, current interfaces do not allow users to see a diversity of tweets according to any criteria. Since Twitter recommends users (the \"who to follow\" functionality) and tweets (the \"discover\" tab) based on account connections and activity, users who do not have diverse connections will not receive diverse recommendations. Motivated by the situation described, in this paper we propose a methodology to address the following research questions:"], "relatedWork": ["There is no clear answer to the question what is Twitter? [9] . However, a wide spectrum of research areas have seen it from different perspectives. One of them is the geographical span of networks: previous work has found that, the stronger the network (defined in terms of reciprocity in connections, 1-way and 2-way interactions by mentioning others), the lower is its geographical span [13] . In terms of discussion, local events have more dense networks of discussion than global events, and central individuals in the network are also located centrally in the physical world [17] . A demographic study of user accounts from the the U.S.A. concluded that populated cities are over-represented, while less populated cities are under-represented in Twitter [11] ."], "rq": ["INTRODUCTIONPrevious literature regarding this subject states that more populated cities are over-represented in Twitter, while less populated cities are under-represented [11] . Because of overrepresentation of populated places, in addition to the lack of balance in physical population distribution in Chile, content from or about non largely populated locations is lost in the timeline of tweets. In addition, it is hard to find local content, as the only salient ways to find content are to click on trending topics, which by definition are biased towards more populated cities, and by searching. But this implies that the information seeker already knows what to look for, if an information need effectively exists. As such, there is no current way to explore a geographically diverse timeline: users have the responsibility to follow diverse accounts. However, current interfaces do not allow users to see a diversity of tweets according to any criteria. Since Twitter recommends users (the \"who to follow\" functionality) and tweets (the \"discover\" tab) based on account connections and activity, users who do not have diverse connections will not receive diverse recommendations. Motivated by the situation described, in this paper we propose a methodology to address the following research questions:"]}
{"intro": ["Verbal irony and sarcasm are a type of interactional phenomenon with specific perlocutionary effects on the hearer (Haverkate 1990) , such as to break their pattern of expectation. For the current report, we do not make a clear distinction between sarcasm and verbal irony. Most computational models for sarcasm detection have considered utterances in isolation (Davidov, Tsur, and Rappoport 2010; Gonz\u00e1lez-Ib\u00e1\u00f1ez, Muresan, and Wacholder 2011; Liebrecht, Kunneman, and Van den Bosch 2013; Riloff et al. 2013; Maynard and Greenwood 2014; Ghosh Guo, and Muresan 2015; Joshi, Sharma, and Bhattacharyya 2015; Ghosh and Veale 2016; Joshi et al. 2016b ). In many instances, however, even humans have difficulty in recognizing sarcastic intent when considering an utterance in isolation (Wallace et al. 2014) . Thus, to detect the speaker's sarcastic intent, it is necessary (even if maybe not sufficient) to consider their utterance(s) in the larger conversation context. Consider the Twitter conversation example in Table 1 . Without the context of userA's statement, the sarcastic intent of userB's response might not be detected."], "relatedWork": ["Existing work in computational models for sarcasm detection addresses a variety of different tasks. These include, primarily, classifying sarcastic vs. non-sarcastic utterances using various lexical and pragmatic features (Gonz\u00e1lez-Ib\u00e1\u00f1ez, Muresan, and Wacholder 2011; Liebrecht, Kunneman, and Van den Bosch 2013; Ghosh and Veale 2016; Joshi et al. 2016b; Muresan et al. 2016) , rules and text-patterns (Veale and Hao 2010) , specific hashtags (Maynard and Greenwood 2014) as well as semi-supervised approach (Davidov, Tsur, and Rappoport 2010) . Researchers have also examined different characteristics of sarcasm, such as sarcasm detection as a sense-disambiguation problem (Ghosh, Guo, and Muresan 2015) and sarcasm as a contrast between a positive sentiment and negative situation (Riloff et al. 2013; Joshi, Sharma, and Bhattacharyya 2015) . Apart from linguistically motivated contextual knowledge, cognitive features, such as eye-tracking information, are also used in sarcasm detection (Mishra et al. 2016 ). Schifanella et al. (2016) propose a multimodal approach, where textual and visual features are combined for sarcasm detection. Some studies present approaches for sarcasm detection in languages other than English. For example, Pt\u00e1\u010dek, Habernal, and Hong (2014) use various n-grams, including unigrams, bigrams, and trigrams, and a set of language-independent features, such as punctuation marks, emoticons, quotes, capitalized words, and character n-gram features, to identify sarcasm in Czech tweets. Similarly, Liu et al. (2014) introduce POS sequences and homophony features to detect sarcasm from Chinese utterances. Bharti, Babu, and Jena (2017) compared tweets written in Hindi to news context for irony identification. Most of these approaches have considered utterances in isolation. However, even humans have difficulty sometimes in recognizing sarcastic intent when considering an utterance in isolation (Wallace et al. 2014) . Recently, an increasing number of researchers have started using contextual information for irony and sarcasm detection. The term context loosely refers to any information that is available beyond the utterance itself (Joshi, Bhattacharyya, and Carman 2017) . There are two major research directionsauthor context and conversation context-and we briefly discuss them here."], "rq": ["Use of Numbers.Use of Rhetorical Questions. We also found that sarcastic utterances that use rhetorical questions (RQ), especially in discussion forums (e.g., IAC v2 ) are hard to identify. Oraby et al. (2016) hypothesized that sarcastic utterances of RQ type are of the following structure: They contain questions in the middle of a post that are followed by a statement. Because many discussion posts are long and might include multiple questions, question marks are not very strong indicators for RQ. et al. (2014) showed that by providing additional conversation context, humans could identify sarcastic utterances that they were unable to identify without the context. However, it will be useful to understand whether a specific part of the conversation context triggers the sarcastic reply. To begin to address this issue, we conducted a qualitative study to understand (a) whether human annotators can identify parts of context that trigger the sarcastic reply and (b) if attention weights can signal similar information. For (a) we designed a crowdsourcing experiment (Crowdsourcing Experiment 1 in Section 6.1), and for (b) we looked at the attention weights of the LSTM networks (Section 6.2)."]}
{"intro": [], "relatedWork": ["Meta-learning and algorithm selection have been studied extensively for supervised learning (Brazdil et al. 2003; Thornton et al. 2013 ), but much less for clustering. There is some work on building meta-learning systems that recommend clustering algorithms (Souto et al. 2008; Ferrari and de Castro 2015) . However, these systems do not take hyperparameter selection into account, or any form of supervision. More related to ours is the work of Caruana et al. (2006) . They generate a large number of clusterings using K-means and spectral clustering, and cluster these clusterings. This meta-clustering is presented to the user as a dendrogram. Here, we also generate a set of clusterings, but afterwards we select from that set the most suitable clustering based on pairwise constraints. The only other work, to our knowledge, that has explored the use of pairwise constraints for algorithm selection is that by Adam and Blockeel (2015) . They define a meta-feature based on constraints, and use this feature to predict whether EM or spectral clustering will perform better for a dataset. While their meta-feature attempts to capture one specific property of the desired clusters, i.e. whether they overlap, our approach is more general and allows selection between any clustering algorithms."], "rq": ["Question Q5: evaluating the clusterings on internal criteriaIn this section, we will investigate the trade-off between the ARI and two internal measures: the silhouette index (SI) (Rousseeuw 1987 ) and the density-based cluster validation (DBCV) score , both of which were also used in answering the previous research questions. The SI was chosen as it is well-known, and the extensive studies by Arbelaitz et al. (2013) and Vendramin et al. (2010) identify it as one of the best performing measures. The DBCV score was chosen as it is one of the few internal measures that does not have a spherical bias, and instead is based on the within-and between-cluster density connectedness of clusters. Although it does not have a spherical bias, the DBCV score comes with its own limitations; for example, it is strongly influenced by noise, and biased towards imbalanced clusterings (Van Craenendonck and Blockeel 2015) . Both of them range in [\u22121, 1], with higher values being better. Figure 4 shows how well the semi-supervised methods score on the internal measures for six datasets. In most cases, COBS performs comparable to its competitors. A notable exception is the parkinsons dataset, for which FOSC-OpticsDend produces clusterings that score significantly higher on both the DBCV score. Interestingly, the ARI of these clusterings is near zero. For parkinsons, the clusterings with the highest ARI score low on the internal measures. This, however, does not necessarily imply that the clustering does not identify any inherent structure (although this can be the case), it only means that it does not identify structure as it is defined by the silhouette score (i.e. spherical structure) or the DBCV score (i.e. density structure)."]}
{"intro": [], "relatedWork": ["In light of this, Wixon [16] argued that usability methods should be discussed as they are used in practise, rather than from an academic viewpoint. He further states that the usability evaluation methods are discussed in academia mostly in terms of qualities that are not relevant in practise. For example, usability tests are judged depending on how many flaws can be found with how many participants. However, in the practise, it is more important whether the method encourages participation, buy in, and collaboration by the development team. He calls for more case studies in real engineering, corporate, and political settings on how real products have been developed. Metastudies of such case studies can reveal more general findings. An example of a case study in practise is given by F\u00f8lstad et al. [17] . An important finding was that HCI practitioners tended not to evaluate their practice with regard to its impact on the development team and project leader."], "rq": ["Research MethodWe applied grounded theory [21] to analyse our data. Grounded theory is a systematic qualitative research methodology in the social sciences that emphasizes generation of theory from data gathered in the process of conducting research. Due to the small sample size and choice of projects studied, we cannot provide a theory. However, we used this systematic approach to handle the richness of the qualitative data we gathered. The main steps in the analysis were coding, memo writing, axial coding, sorting, and writing of findings. After each interview, we conducted open coding, meaning that we indexed the whole interview with codes as they came to mind, independently of previous findings. Memo writing served to condense the findings and identify the first results. Then, concepts and categories emerged from the codes. In the middle and at the end of the interviewing phase we conducted axial coding. In axial coding we looked through all interviews and codes and recoded all interviews such that the emerging categories were well covered. At the end of the process, we had 175 codes and 9 families. Some codes were too specific and did not belong to any family. The codes were then sorted graphically to establish which codes belong together and how they influence each other. We do not show the codes for spatial reasons. We describe the results in the main part of the paper, see Section 6, on the ground of three main categories: work context (research question 2), motivation, and work practice (research question 1) of each role. Then we indicate the strategies that employees used to overcome the obstacles in their daily work (research question 3). In the end we analyse the impact of the different factors on user-centred design."]}
{"intro": [], "relatedWork": ["In healthcare, a multitude of neuropsychological tests have been developed and used by clinicians for assessing cognition. Mini Mental State Examination (MMSE) [46] , Montreal Cognitive Assessment (MoCA) [29] and Addenbrooke's Cognitive Examination-III (ACE-III) [15] are widely used for cognitive impairment screening and monitoring in clinical settings. Currently, these assessment tools are typically paper-based and not designed for self-administration [15] . Thus, it is infeasible to run the tests frequently to monitor changes in cognitive functions over time due to learning effects [46] , costs and resource requirements around availability of qualified clinical staff to administer them. These can adversely affect the ability of clinicians to detect the early signs of decline in cognitive functions, potentially delaying diagnosis and treatment as well as undermining the effectiveness of medication or other interventions [37] . These limitations have led to a call for alternative approaches. Taking advantage of computerised assessments may provide more precise test results, better control of stimulus presentation and ease of administration to assess cognitive abilities. One of the most widely used computerised tools for cognitive measurements in clinical research is the Cambridge Neuropsychological Test Automated Battery (CANTAB). The CANTAB system includes various tests measuring a range of cognitive functions, e.g. executive function, attention, memory and decision making [55] . It has been extensively used to assess cognitive functions in older people [32] , athletes with exposure to repeated brain injuries [7] , for paediatric neuropsychological assessment [25] , HIV dementia patients [34] and alcohol drinkers [14] . However, trained clinical personnel are required for protocol administration of CANTAB.", "\"Serious games\" have recently gained increasing research attention for their potential to improve sustained participation in continual assessment and therapy by incorporating elements of fun and user engagement in their design [10, 11, 26, 27, 47] . Serious games are those designed for some additional purpose beyond pure entertainment, such as: training, marketing, communicating, assessing and/or enhancing cognitive and physical health [33] . For instance, a tabletop-gaming platform in the Eldergames project was developed to improve cognitive functions in older adults. Their findings showed that their interactive tabletop games were wellaccepted with regard to usability and reported to create a positive experience [11] . However, this approach requires space for equipment setup and is thus not feasible for running in a large-scale experiment. In contrast, the ubiquitous computing power of modern mobile devices offers promising solutions for data collection and processing for cognitive assessment and monitoring outside clinical settings. Mobile versions of serious games have been developed to simulate common daily activities such as cooking [27] and supermarket shopping [54] , in order to assess and help improve cognitive functions among people with mild cognitive impairment (MCI). To complete tasks in the game scenarios, a multitude of cognitive processes were involved, e.g. object recognition, attention, visual search, memory and executive functions. By comparing in-game task performance and classic cognitive assessments, e.g. MMSE and TMT [45] , their findings demonstrated significant correlations between variables in the games and results from standard cognitive measures. Unlike the simulation-based designs that artificially represent real-world scenarios in such games, replicating a popular casual game Whack-a-Mole presents more game-like attributes and reduces the feelings of being tested [47] . A Go/No-Go discrimination task has also been incorporated into serious games to measure cognitive inhibition. The significant correlations between median response time and cognitive test scores suggested that this in-game feature could be used as a predictor for cognitive status. A recent systematic review found that the use of gamified tasks can help improve drop-out rates in longitudinal studies including a reduction in test anxiety [26] . Because of their entertaining nature, these game-based assessments were reportedly well received by the users even in older adults. In spite of common misperceptions, a systematic review reported that older adults enjoyed video games and benefited from game-based cognitive intervention [20] . This was supported by a recent report demonstrating that 23 per cent of the U.S. gamers were 50 years and older [41] . Hence, these studies have emphasised the potential of serious games as highly engaging cognitive assessments to monitor changes in cognition outside of a clinical environment for populations with cognitive disorder across age groups.", "It is important to note that all these studies have explored hand movement in non-time-dependent tasks, such as handwriting. However, gameplay hand movement is closely related to user reactions on game stimuli. The characteristics of touch gestures in games are highly dependent on the time the user perceives stimuli in the game and the limited time they have to perform a specific gesture. Therefore the shape, speed and length of a gesture can be different, depending on the time it takes to perceive a game trigger. For example, a slow response time in identifying a game object that a player needs to interact with (e.g. in \"Fruit Ninja\" spotting a fruit that is about to move out of the screen) could result in a faster and more erratic gesture in order to complete the gesture in the reduced time available. Previous studies have shown that mental fatigue [21] and age [8] adversely affect the speed of processing resulting in slower reaction time. This means that in certain games, faster and more erratic gestures could be an indicator of slower response time to visual stimuli, and therefore indicative of cognitive decline."], "rq": ["Addressing Research Questions7.1.1 RQ1: Are the swipe length and shape of touch gestures related to changes in cognitive performance? and RQ2: Is the speed of touch gestures related to changes in cognitive performance? We found that overall swipe speed features were positively correlated with TMTA and TMTB in Tetris and Candy Crush, while overall swipe speed features in Fruit Ninja and Candy Crush were positively correlated with RESIN. These results imply that increases in swipe speed were associated with decreases in performance on these cognitive functions (visual search, mental flexibility and response inhibition). This finding demonstrates a clear diversion from the studies on traditional handwriting movement [28, 36, 44] . Indeed, in handwriting studies, higher hand movement speed is correlated with increase in cognitive performance. However, we consider that the seemingly contradictory finding can be explained by the significant differences in user intention, between handwriting and gameplay. Based on gameplay observations, we noted that fast and erratic gestures in games like Fruit Ninja, tend to occur when players narrowly miss certain objects that they are expected to interact with, within a limited time frame. We therefore hypothesise that the temporal nature of game interaction can lead to more erratic and fast gestures, as the cognitive abilities of the players decline. The positive correlation between the directness index of swipes and response inhibition ability as well as the swipe patterns idiosyncratic to Fruit Ninja provide evidence to support this explanation. It is consistent with the negative correlation we identify between VISP and swipe speed in Fruit Ninja. The results seem to suggest that these fast swipes, demonstrate decreases in visuospatial abilities, and are indeed rushed movements."]}
{"intro": [], "relatedWork": ["In this section, we overview the current landscape of automated testing and input generation tools for Android, discussing limitations of these approaches while illustrating CRASHSCOPE'S novelty in context. Several approaches for detecting and reproducing crashes are available in literature [30] - [32] , [39] , [40] , [43] , [51] , [52] , [63] , [64] , [69] , [74] , [78] , [80] - [82] ; however, we forgo discussion of these approaches, as they are not presented in the context of mobile apps, and hence do not consider the unique associated challenges."], "rq": ["IV. EMPIRICAL STUDY 1: CRASH DETECTION CAPABILITYThe goal of our first study is to evaluate the effectiveness of CRASHSCOPE at discovering crashes in Android apps as compared to state-of-the-art approaches for testing mobile apps. The quality focus of this first study concerns the fault detection capabilities of CRASHSCOPE in terms of locating crashes. The context of this study consists of 61 open-source Android apps previously used to evaluate automated testing approaches in [29] , as well as five approaches for automated input generation (listed in Table II) . We investigated the following research questions (RQs): A. Methodology In order to compare CRASHSCOPE against other stateof-the-art automated input generation tools for Android, we utilized a subset of subject apps and tools available in the Androtest testing suite [8] , [29] . We chose to perform this study on a subset of the tools offered by the Androtest artifact due to runtime issues, namely, some tools would not run consistently on the set of provided subject apps (e.g., the tools would launch an emulator but not the app), causing inconsistent results we chose to exclude. However, when contacted, the authors of the tool were helpful in supporting us. We believe the tools tested against constitute a diverse representation of the publicly available Android testing tools. The Androtest suite contains 68 subject applications for testing; however, when recompiling the applications to run the tools and extract the apps from the VM to run with CRASHSCOPE, seven of the subject apps failed to compile with the instrumentation necessary to gather code-coverage results. Therefore, each tool in the suite was allowed to run for one hour for each of the remaining 61 subject apps, five times, whereas we ran all 12 combinations of the CRASHSCOPE strategies once on each of these apps. It is worth noting that the execution of tools in the Androtest suite (except for Android monkey) can not be controlled by a criteria such as maximum number of events."]}
{"intro": [], "relatedWork": ["There is long-standing research on emotion assessment from physiological signals [1] , [22] , [23] , [24] , [14] , [25] . Among these studies, few of them achieved notable results using video stimuli. Lisetti and Nasoz used physiological response to recognize emotion in response to movie scenes [14] . The movie scenes elicited six emotions, namely, sadness, amusement, fear, anger, frustration, and surprise. They achieved a high recognition rate of 84 percent for the recognition of these six emotions. However, the classification was based on the analysis of the signals in response to preselected segments in the shown video known to be related to highly emotional events.", "Takahashi [15] recorded EEG and peripheral physiological signals from 12 participants. He then classified the responses to emotional videos into five classes, namely, joy, sadness, disgust, fear, and relax. He achieved the accuracy of 41.7 percent using EEG signals. However, the feature level fusion (FLF) of EEG signals and peripheral physiological signals failed to improve the classification accuracy.", "Eye gaze and pupillary responses have been used extensively to measure attention. However, we are not aware of research on how emotions affect eye gaze while watching videos; therefore, the eye gaze itself has not been used for emotion recognition. The pupillary response is the measurement of pupil diameter over time. Pupils can dilate or constrict in response to light, cognitive, attentional, and emotional stimuli [27] , [28] . Gao et al. [29] showed the significance of using pupillary reflex for emotion assessment after reducing the light effect using a real-time feedback."], "rq": ["CONCLUSIONSThis paper showed the performance of an interparticipant emotion recognition tagging approach using participants' EEG signals, gaze distance and pupillary response as affective feedbacks. The feasibility of an approach to recognize emotion in response to videos is shown. Although the results were based on a fairly small video data set due to experimental limitations, the promising accuracy can be scalable to more samples from a larger population. The improved performance using multimodal fusion techniques leads to the conclusion that by adding other modalities, such as facial expressions, accuracy as well as robustness should further improve. Results from our previous studies [3] showed that there is a significant difference between peoples' emotional self-assessments in response to videos. However, there usually exists one most popular emotional tag for which there is significant agreement in a population. This \"most popular emotion\" has been shown to be detectable with monitoring users' bodily responses. Moreover, the population tags give the retrieval system a higher chance of success in a given population. We have shown that it is possible to design an accurate and user-independent classification protocol to recognize emotions from pupillary reflex, EEG signals in response to video content. Moreover, we have shown that for the video data set utilized, the nonverbal affective cues can replace affective self-report with comparable emotion recognition performance and no requisite of direct user inputs. We can thus answer positively to our two research questions. Thierry Pun received the electrical engineer diploma in 1979. He received the PhD degree in image processing for the development of a visual prosthesis for the blind in 1982 from the Swiss Federal Institute of Technology, Lausanne. He is head of the Computer Vision and Multimedia Laboratory, Computer Science Department, University of Geneva, Switzerland. He was a visiting fellow from 1982 to 1985 at the National Institutes of Health, Bethesda, Maryland. After being a CERN fellow from 1985 to 1986 in Geneva, Switzerland, he joined the University of Geneva in 1986, where he is currently a full professor in the Computer Science Department. He has authored or coauthored about 300 full papers as well as eight patents. His current research interests, related to affective computing and multimodal interaction, concern: physiological signals analysis for emotion assessment and braincomputer interaction, multimodal interfaces for blind users, data hiding, multimedia information retrieval systems. He is a member of the IEEE."]}
{"intro": ["Identification and categorization of registers and genres has a long history. Early studies on specialized languages centered on the role of registers following Firth's (1957) concept of lexical collocation. Firth's theory of text cohesiveness and register types is based on the idea that text register and text cohesiveness can be determined by the distribution of the words in a text and their combinations. Later work in register analysis followed Halliday (1978) in which linguists identified special registers on the basis of lexical aspects, which were considered sufficient in themselves in order to distinguish specific registers. While these early register studies generally focused on isolated words and their frequency within texts, they did not consider how registers compared to each other in their respective differences. Recently, however, many linguists have begun to focus on the study of registers from a comparative perspective known as register variation (Biber 1988; Conrad & Biber 2001) . While much of this current work is located under the paradigm of multi-dimensional variation analysis (Biber 1988 ) and considers the co-occurrence of syntactic constructions, only some of the research considers how lexical items can be used to analyze register variation (e.g.. Biber, Conrad & Cortes 2004) . Of specific importance to this study is the analysis of variation based on shared bigrams, or the co-occurrence of words across corpora, to categorize texts into different dimensions of register variation."], "relatedWork": ["Though this overview is far from complete, it does illustrate that n-gram analyses are a useful tool in corpus linguistic analyses. Thus, n-gram analysis was selected as an approach to register analysis for this study. However, in a similar fashion to Peng et al. (2003) , and following the computational linguistic standards of Jurafsky and Martin (2000) , the current study only considers bigrams. This is because unigrams do not capture enough of the syntactic and semantic context and larger n-grams, such as trigrams and quadgrams, create sparse data problems. Bigrams, on the other hand tap into both the paradigmatic and syntagmatic features of the text and, in addition to being extremely simple to compute, they have been found to be effective in many computational applications to include text categorization."], "rq": ["4.\uf6dc CorporaThe Map Task Corpus is a tasked-based corpus that is the linguistic product of a cooperative task involving two participants. The Instruction Givers have a marked route on their map and give directions to the Instruction Followers who have no route. The maps are not identical, which elicits unscripted problem solving dialog. Because of the domain, we predicted a strong spatial predisposition in the lexical and syntactic collocations of this dialog. However, to ensure that any Map Task Corpus findings were based purely on their spatiality, another task-based corpus was selected to include in the analysis: the TRAINS Corpus. This corpus is based on the routing and scheduling of freight trains. The corpus shares with Map Task its basis as a task based corpus, but it is more temporal and directional in nature than the spatial Map Task Corpus. A selection of non-task based spoken dialogs were also included in the analysis. Following the methodology of Biber (1988) , the spoken dialogs found in the London Lund Corpus were included in the analysis and broken up into six different speech situations: spontaneous speech, prepared speech, face to face conversations, telephone conversations, interviews, and broadcast speech. Our primary purpose in including the LLC was to use it as a means to compare natural dialogs and task-based dialogs. As such, we were also interested in the possibility that bigrams might be powerful enough to delimit natural dialogs from task-based dialogs in a factor analysis based on the idea that task-based dialogs were more instructional in nature and depended on a more controlled lexical domain. Because there has been ample attention given to dialectical differences between American and British spoken dialects (Biber 1987; Helt 2001) , we also included American spoken dialogs. These included the Santa Barbara Corpus and the Switchboard Corpus. The Santa Barbara Corpus is a collection of natural speech recordings taken from people across the United States. The Switchboard Corpus, on the other hand, is a collection of about 2,400 two-sided random topic telephone conversations taken from 543 speakers from all areas of the United States. Since one of Biber's (1988) primary research questions was the delineation of spoken and written dimensions, we also included the LOB and the Brown corpora. The Brown corpus is a collection of written American texts published in 1961. It comprises 500 text samples of about 2,000 words each and totals about one million words. Each text sample is categorized into one of fifteen registers including religion, science, fiction, humor, and press reports. The LOB Corpus is a direct replication of the Brown Corpus, but is based on 1961 text samples taken from British written sources. Based on the work of Biber (1988) and Louwerse et al. (2004) it was thought that the written corpora would be distinguished from the spoken corpora as a result of the written texts being more integrated and less fragmented and involved. A brief description of the corpus used in this investigation is found in Table 1 ."]}
{"intro": ["Native Americans comprise an exceptional class of citizenship within the U.S. While many Native Americans are voting members of tribal nations, they are also eligible to vote in local, state, and national elections. However, the historically agonistic relationship between the U.S. federal government and Native American nations, has discouraged Native American individuals from engaging with electoral politics in the U.S. [25, 49, 57] . Moreover, Indian Country 1 , which is associated with some of the largest Native American voting blocs, suffers from a lack of communications infrastructure 2 , limiting Natve American individuals' potential for political engagement through digital means. To demonstrate the critical need for Internet infrastructure in Indian Country, it is necessary to understand the discursive qualities and data characteristics of political content disseminated across Internet Protocol (IP) networks. Indeed, the U.S. Government Accountability Office has recently issued a statement outlining the need for data surrounding tribal Internet access [23] ."], "relatedWork": ["A large body of work has explored information and communication technologies (ICTs) and political engagement, and it is clear that the Internet enables new grassroots movements to quickly materialize and operate for a period of time [20, 21, 6, 7, 19] . The Mexican Zapatista movement of the 1990s provides a prime example of the success social movement organizations (SMOs) can achieve by networking over the Internet [20] . Prior studies have commented on the balkanization that occurs in political social networks on Twitter, where actors divide into affiliate networks, reducing exposure to opposing viewpoints [26] . However, for marginalized social groups, sharing political viewpoints within affiliate networks can become a source of in-group validation and motivation for political mobilization [12, 56, 31] . While social media platforms can empower marginalized groups, limited Internet access and connectivity continues to trouble Indian Country. According to the Federal Communications Commission (FCC), fewer than 15% of people living on tribal land have broadband access [18] . As is typical for infrastructurepoor, rural areas, many reservations depend on wireless networks to extend residential broadband access [2, 16] . In some communities, this is accomplished through a combination of wireless backhaul links connecting homes to the Internet over Wi-Fi [51, 48] or TV whitespaces [58] ; in others, residents rely on cellular network coverage to access the Internet from home [24, 34] ; in still others, people must travel what can be tens of miles in order to reach the nearest access point, typically located in private businesses bordering tribal land or in tribal libraries and media centers [34] . The dependence on wireless technology leads to connection opportunities that are either limited because of their financial expense (in the case of data subscriptions), attenuated performance over long distance operations (in the case of microwave and satellite), or excessive time requirements (in the case of opportunistic transactions made from a municipal cellular or Wi-Fi hotspot)."], "rq": ["Bandwidth CharacteristicsWe address RQ3 in light of Indian Country's infrastructural limitations described in the Introduction and Related Works sections. We investigate the impact media richness has on the propagation of individual tweets in the Native American advocates data set. We argue that all tweets are essentially bulletins that enable asynchronous interaction between the poster and audience. However, the richness of individual tweets can vary considerably depending on the presence, type, and size of media embedded in the tweet. Of the 5,172 unique tweets we observe in the Native American advocates data set, 1.7% contain embedded video content, 35.8% contain embedded photo content, and 62.5% do not contain any embedded content. Per Daft and Lengel's definition, we consider tweets with embedded media to be richer than those that lack embedded media [14, 35] . Moreover, we consider tweets with embedded videos or GIFs to be richer than tweets with embedded photos based on the fact that such media offers the \"simultaneous transmission of multiple information cues\" [35] . Similarly, we consider tweets with embedded videos to be richer than tweets with embedded GIFs, as the audio component lends the expression of a greater \"variety of languages\" [35] ."]}
{"intro": ["We investigate this research question on the example of discriminative training for patent translation, using the algorithm for multi-task learning with 1 / 2 regularization presented by Simianer et al. (2012) . We compare multi-task learning on \"natural\" tasks given by IPC sections to multitask learning on \"random\" tasks given by random shards and to baseline models trained on independent tasks and pooled tasks. We find that both versions of multi-task learning improve over independent or pooled training. However, differences between multi-task learning on IPC tasks and random tasks are small. This points to a more general regularization effect of multi-task learning and indicates a broad applicability of multi-task learning techniques. Another advantage of the 1 / 2 reg-ularization technique of Simianer et al. (2012) is a considerable efficiency gain due to parallelization and iterative feature selection that makes the algorithm suitable for big data applications and for large-scale training with millions of sparse features. Last but not least, our best result for multitask learning improves by nearly 2 BLEU points over the standard MERT baseline."], "relatedWork": ["In this paper we apply the multi-task learning technique of Simianer et al. (2012) to tasks defined as IPC sections and to random tasks. Their algorithm can be seen as a weight-based backward feature elimination variant of Obozinski et al. (2010) 's gradient-based forward feature selection algorithm for 1 / 2 regularization. The latter approach is related to the general methodology of using block norms to select entire groups of features jointly. For example, such groups can be defined as non-overlapping subsets of features (Yuan and Lin, 2006) , or as hierarchical groups of features (Zhao et al., 2009 ), or they can be grouped by the general structure of the prediction problem (Martins et al., 2011) . However, these approaches are concerned with grouping features within a single prediction problem whereas multitask learning adds an orthogonal layer of multiple task-specific prediction problems. By virtue of averaging selected weights after each epoch, the algorithm of Simianer et al. (2012) is related to McDonald et al. (2010) 's iterative mixing procedure. This algorithm is itself related to the bagging procedure of Breiman (1996) , if random shards are considered from the perspective of random samples. In both cases averaging helps to reduce the variance of the per-sample classifiers."], "rq": ["IntroductionWe investigate this research question on the example of discriminative training for patent translation, using the algorithm for multi-task learning with 1 / 2 regularization presented by Simianer et al. (2012) . We compare multi-task learning on \"natural\" tasks given by IPC sections to multitask learning on \"random\" tasks given by random shards and to baseline models trained on independent tasks and pooled tasks. We find that both versions of multi-task learning improve over independent or pooled training. However, differences between multi-task learning on IPC tasks and random tasks are small. This points to a more general regularization effect of multi-task learning and indicates a broad applicability of multi-task learning techniques. Another advantage of the 1 / 2 reg-ularization technique of Simianer et al. (2012) is a considerable efficiency gain due to parallelization and iterative feature selection that makes the algorithm suitable for big data applications and for large-scale training with millions of sparse features. Last but not least, our best result for multitask learning improves by nearly 2 BLEU points over the standard MERT baseline.", "ConclusionOur research question regarding the superiority of \"natural\" or \"random\" tasks was shown to be undetermined for the application of patent translation. The obvious question for future work is if and how a task division can be found that improves multi-task learning over our current results. Such an investigation will have to explore various similarity metrics and clustering techniques for IPC sub-classes (W\u00e4schle and Riezler, 2012a) , e.g., for the goal of optimizing clustering with respect to the ratio of between-cluster to within-cluster similarity for a given metric. However, the final criterion for the usefulness of a clustering is necessarily application specific (von Luxburg et al., 2012) , in our case specific to patent translation performance. Nevertheless, we hope that the presented and future work will prove useful and generalizable for related multi-task learning scenarios."]}
{"intro": ["In this paper, we focus on RPS pain synthesis, and clinician recognition. Clinicians need to both visually (and verbally) assess the amount of pain patients are experiencing in order to make treatment decisions. However, research suggests that clinicians are likely to both underestimate the intensity of patients' self-reported pain [47] , and they are also likely to overall interpret facial expressions with less accuracy than laypersons [21] . Some researchers have hypothesized this is due to the decline in empathy as clinicians progress through their training [27] . Unfortunately, ignoring patients' emotional needs can lead to incorrect diagnostic decisions, poorer health outcomes, and reduced patient satisfaction [70, 30] .", "Fortunately, training can be effective in improving clinicians' ability to detect patient facial expressions [23, 11] . Thus, RPSs may prove to be an excellent training tool to facilitate this learning process. Certainly this effect has been shown to be true in the virtual space (c.f. [20] ); however, it is difficult to use virtual simulations in situ at the bedside, where clinicians must visually assess patient faces while simultaneously conduct physical exams [29, 41] . Furthermore, augmented reality and projected displays are unfortunately ill-suited to most hospital simulation domains due to space and power issues [22] , and can cause physical barriers between the patient and clinician. Thus, perhaps physically-embodied, expressive RPS systems may be an effective educational intervention for patient facial expression decoding."], "relatedWork": ["Facial expressions of pain are important nonverbal communication signals, particularly in healthcare [25, 47] . Communicating pain via facial expressions is important because it signals to clinicians that a patient might need medical attention. While selfreporting is the main method of assessing pain, there are issues with this method. The most critical issue is that self-report cannot be used for children or patients with communication challenges such as patients with cognitive impairments or unconscious patients. In such cases, an observer must visually assess patients' pain. However, there are differences between how clinicians and how patients conceptualize pain (clinicians are substantially impaired at pain perception), which leads to problems when making diagnostic decisions for these patients [47, 66, 2, 39] ."], "rq": ["Pilot studyZhang et al. designed an activity for simulating different natural expressions including anger and disgust in their participants [68] . Therefore, the naturally stimulated anger videos had very low intensity compared to an acted dataset such as the one we used in our previous work [41] . Naturalistic anger source videos were hard to recognize due to their very low intensity. However, since our research questions were focused on pain, we decided to continue with the study and include anger and disgust in addition to pain to make sure we do not ask participants to only watch and label only one type of expression (pain).", "DISCUSSIONWe found support for our first research question, which supports earlier findings in the literature, that clinicians are less accurate than laypersons in decoding pain [21, 23, 43, 35, 27, 17] . Our work showed that this effect is found regardless of simulation embodiment (robot or virtual character), which suggests even the novelty of the embodiment is not sufficient to incur improved decoding skills. However, since training has been shown to help mitigate these clinical habituation effects, expressive, interactive RPSs may be useful in the medical education curriculum to be used alongside procedural skills training. For example, rather than having infrequent and contextless patient empathy training sessions [58] , clinical learners could be continually learning pain decoding skills as they practice other critical care skills on patient simulators (e.g., performing physical exams, assessing patient state, etc.)."]}
{"intro": ["However, despite their current prominence, it is not clear that commodity cluster technology will remain cost-effective when scaled to the PetaFLOPs range. New issues -such as power, cooling, and physical infrastructure -are becoming increasingly important. Additional issues, such as bandwidth to primary and secondary storage, are emerging as significant challenges. (This point is expanded upon in section 2; section 2 of [3] outlines a similar argument.)"], "relatedWork": ["Almost since the Field-Programmable Gate Array was introduced in 1985, researchers have contemplated ways of using FPGAs to build high performance CustomComputing Machines (CCMs). Several have been used in clusters or direct predecessors of clusters. Early researchers used large collections of FPGAs because individual FPGAs had relatively few resources; hence multiple FPGAs were required to implement a substantial design. Typical examples include the Splash-2 attached processor [2] and \"The Virtual Computer\" [5] . Although the goal of these systems was to provide a fast co-processor, a kernel of the idea of \"clusters of interacting systems\" is in these designs. The Splash-2 boards had a configurable interconnection network between the FPGAs and one model for programming these boards was to use a variant of data parallel C [11] . In this model, the processing elements are not independent systems; however, clearly this was approaching a cluster of communicating systems.", "Other related projects have been built. For example, in 2003 AFRL Rome built a 48-node cluster of PCs with an off-the-shelf FPGA board on the PCI bus [22] . However, this is different from the Adaptable Computing Clusterwhere the FPGA was in the network data path -and very different from the current project where the Platform FPGA is the node."], "rq": ["Commodity Cluster SolutionsMulti-core processors will allow the on-chip rateof-computation to continue to grow exponentially with Moore's Law. However, as just mentioned, this does not address the issue of primary memory speed. This so called \"Memory Wall\" was predicted many years ago [37] but microprocessors have been able to avoid the the growing disparity by using ever-larger on-chip caches. Thus it possible that some clever research will emerge that again postpones the bottleneck issue; however to date the only solution has been to create ever-larger data caches. There are other unanswered research questions as well, such as how hundreds cores on a single chip will communicate (on-chip and across the nodes of cluster). The point is not to say that multi-chip processors have insurmountable problems. Rather just to note that the technology is not without risk."]}
{"intro": ["The high-level research question in this work is whether cycling and serpentining -as two perspectives of reexamining top-N list -improve user experience. However, we are not trying to optimize a particular user experience. We recognize that different experiences may require different approaches. A situation where a site recommends a single item cannot benefit from serpentining. A user who treats the top-N list as a \"to-do\" list, taking the top item each time, would not be served well by cycling. Rather, we want to see how these manipulations relate to user experience in the hopes of guiding designers in adopting them, or offering them to users. Similarly to the finding from Ziegler's work [32] that users are willing to accept a certain loss of accuracy in order to have more diverse recommendations, we expect that the perceived accuracy of recommendations may get reduced because of the manipulation; however, we test whether the accuracy reduction may be preferred in exchange for the exposure to a broader and \"fresher\" set of items."], "relatedWork": ["However, there is a need for more systematic study of recommender models' and algorithms' effects on user perceptions and experience. Change in recommendations is a good thing when users perceive more freshness and less boredom, but also could be confusing when changes are highly unexpected or overly dramatic. In other words, several psychological factors (that may not be directly observable) may be involved in user's decision making and, therefore, a systematic user-centered approach is needed to evaluate their potential involvement. Users' exposure to recommendations can also be studied by analyzing user actions, following the approaches and ideas from the science of persuasion and marketing. As Trellis's [30] work showed, advertising exposure has a nonlinear effect, in other words, repetitive exposure is necessary but has diminishing gain. Their and others' results [18] suggested that two to three ad exposures might be optimum. As discussed by Petty and Cacioppo [21] and also suggested by their results, repeating a persuasive communication tends to first increase and then decrease agreement. They proposed a two-stage attitude modification process: repetition enhances a person's ability to process a message in the first stage, and tedium and reactance are elicited by excessive exposures in the second stage. Similarly, this two-stage process might also apply in recommendations. Although CARS [1] adapt recommendations based on users' contextual state, i.e., based on time, mood, or companion(s), there might be contexts that are hard to measure and very sparse data about them is available for each individual user. Therefore, repetitive recommendations may increase the chances that users process the recommendations in relevant contexts. In addition, we study user-perceived boredom and freshness associated with the dynamics through surveys. There is not much research on changing recommendations based on users' past exposure to recommended items. One thread of related research is CTR (Click-Through Rate) estimation in information retrieval [2] , where documents with many exposures but no positive feedback from users are downgraded because their estimated CTRs become lower. Recommender systems can also utilize indirect feedback, such as clicks, which would be treated as an implicit preference signal [9] . In other words, when focusing on implicit users' feedback in response to displayed recommendations, a recommender can be designed to achieve similar dynamics. We do not use CTR as the primary evaluation approach in our work, because the system studied is not targeted at generating click-throughs, but rather at helping users have better experience with in exploring and finding movies (as measured in a much more holistic, comprehensive manner). Moreover, in our system users can see and rate movies without clicking through to detail pages, so informativeness of clicks as a primary evaluation measure may be limited. However, we do keep track of clicks as one of several indicators of user activities and engagement with the system.", "Recommender systems can be evaluated with offline metrics and online field experiments. Offline metrics sometimes make assumptions about online environments. One such important assumption is that the recommendation value decays going from the top to the bottom of a recommended item list. The nDCG [10] and weighted recall (or Breese's score [4] ) evaluation metrics, for example, assume exponential decay. We propose to test this assumption, because it may not be optimal to display all best 1 https://movielens.org recommendations at the same time. List-wise optimization have been shown to improve recommendations [28] , which suggests that an optimal list may not be the same as a collection of individually optimal items. Also, it has been shown that, in addition to accuracy, many other properties of a recommender are important aspects of user satisfaction [22, 19, 20, 32, 11] , such as diversity, novelty, etc. Pu et al. [22] proposed a user-centric evaluation framework for recommender systems with state-of-art survey designs [23] . Knijnenburg et al. [12] proposed a comprehensive framework taking into account both objective system measurements and subjective user perceptions to explain user experience. We directly apply this framework in evaluating our manipulations. Particularly, they postulate six components and their causal relationships -objective system aspects (OSA), subjective system aspects (SSA), user experience (EXP), user interactions or activities (INT), situational characteristics (SC) and personal characteristics (PC) --according to Theories of Reasoned Action (TRA) [7] . We use and model the former four components through methods of recording and analyzing user activities and survey responses here. This framework relies strongly on asking users their subjective experience through survey questions. In many examples of this type of studies, users typically interact one time with a system and then evaluate its performance. However, in our current study users can interact with a system over time, i.e., over several sessions. Because of this, we vary the moment of presenting the survey questions, to see if querying the user experience might affect how users interact with the system."], "rq": ["INTRODUCTIONThe high-level research question in this work is whether cycling and serpentining -as two perspectives of reexamining top-N list -improve user experience. However, we are not trying to optimize a particular user experience. We recognize that different experiences may require different approaches. A situation where a site recommends a single item cannot benefit from serpentining. A user who treats the top-N list as a \"to-do\" list, taking the top item each time, would not be served well by cycling. Rather, we want to see how these manipulations relate to user experience in the hopes of guiding designers in adopting them, or offering them to users. Similarly to the finding from Ziegler's work [32] that users are willing to accept a certain loss of accuracy in order to have more diverse recommendations, we expect that the perceived accuracy of recommendations may get reduced because of the manipulation; however, we test whether the accuracy reduction may be preferred in exchange for the exposure to a broader and \"fresher\" set of items."]}
{"intro": ["These cognitive challenges have been addressed by current research. In the psychology research literature, the cognitive capabilities of individuals and the role of the physical environment thereupon are discussed extensively [cf. 27, 28, 31] . Research on memory aid systems highlights suitable technical support to recall information [cf. [11, 15, 16, 21] . However these current research discussions address mostly the individual level or single-user scenarios, and insights on the cognitive aspects in mobile collaborations and how the individuals' cognitive capabilities influence their collaborative behavior are scarce. To provide appropriate support, it is important to understand the role of the OOS-OOM phenomenon in mobile collaborations. This brings us to our first research question: RQ1: How does forgetting influence mobile counseling sessions?", "The cognitive aspects in collaborations are broadly discussed in research on computer supported collaborative work (CSCW). Researchers provide high-level insights on the concept of collaborative memory [2, 24] and extensively discuss how to support collaboration partners to create and use a collaborative memory [1, 2, 19] . However, current research focuses mostly on stationary scenarios, and insights on the novel challenges and their influence on group members' cognitive capabilities and the creation of a collabora-tive memory are lacking. Current research on mobile memory aid systems addresses the individual's cognitive capability, and presents diverse solutions to facilitate memory cue creation [15, 16, 21] . However, research insights on suitable support accounting for multiple users are scarce. Both the collaborative situation of the clientconsultant relationship and the mobile setting give rise to new challenges for developing suitable support systems. We thus asked ourselves how an appropriately designed \"memory aid\" could support actors to create and use a collaborative memory in their mobile collaboration. After reviewing related literature on psychology research, CSCWresearch and memory aid systems, as well as discussing different design options, it was \"working with pictures\" that turned out to be a surprisingly useful concept for responding to the characteristics of mobile collaborations and to bring information back into the minds of the actors. Thus, in this study we further pursue the second research question"], "relatedWork": ["The actors' cognitive processes not only comprise the individual's internal mental processes, but also their interactions with others as well as with the physical artifacts in the surrounding environment. In this context, the changing environmental context can influence individual's cognitive capabilities considerably. In psychology research literature, researchers discuss extensively the individual's cognitive processes and the role and effects of the environmental context on an individual's cognitive capabilities [cf. 3, 8, 10, 27, 28, 31] . Studies report on different effects (e.g., environmental reinstatement [28] , where changing the physical environment causes individuals to remember fewer memories) and propose measures to reduce the resulting context-dependent forgetting (e.g., multiple-learningcontext-technique [27] , where individuals learn information in different environmental contexts rather than one). Whereas these studies provide useful insights on how to enhance a human's cognitive capabilities, they mainly discuss them on the individual level, when reporting on several actors and how they influence each other's memories, discussions remain mostly conceptual. These interactions between actors can enhance individual's cognitive capability, e.g., by either cross-cueing [9] , where information from others trigger memories of an individual that s/he would not have remembered alone, or impair it, e.g., by the \"outshining\"-effect [28] , where an individual's memories are \"outshone\" by easier-to-access information. However, current research studies barely provide insights how corresponding effects influence actors' behaviors in collaborations.", "Current research on counseling support systems investigates consultants' and clients' collaborative work practices from different perspectives. Novak [17] describes the hampering effects of information overload in shared problem solving, where actors' ability to make decisions deteriorates due to the presence of too much information. Novak and Schwabe [18] highlight the impact of sticky information that is bound to a specific location (physically, mentally) aggravating the exchange of information. Nussbaumer et al. [20] discuss the information asymmetry between consultants (as experts) and clients (as laypersons), and report on the negative effects, thwarting collaborative interactions. Schmidt-Rauch and Nussbaumer [25] give insights into actors' collaborative task of co-creating the value of counseling and show how to design appropriate support to help them becoming more equal co-creators. In their solutions, these researchers give insights into collaborative work practices in counseling collaborations, showing how technical support systems should be designed to support users appropriately. However, they rarely consider the individuals' cognitive aspects in storing and recalling information, and do not discuss how they influence the individual's collaborative behavior. Furthermore, they focus mostly on stationary scenarios, disregarding the actors' physical environment and its role and effects within the consultant-client collaboration."], "rq": ["INTRODUCTIONThese cognitive challenges have been addressed by current research. In the psychology research literature, the cognitive capabilities of individuals and the role of the physical environment thereupon are discussed extensively [cf. 27, 28, 31] . Research on memory aid systems highlights suitable technical support to recall information [cf. [11, 15, 16, 21] . However these current research discussions address mostly the individual level or single-user scenarios, and insights on the cognitive aspects in mobile collaborations and how the individuals' cognitive capabilities influence their collaborative behavior are scarce. To provide appropriate support, it is important to understand the role of the OOS-OOM phenomenon in mobile collaborations. This brings us to our first research question: RQ1: How does forgetting influence mobile counseling sessions?", "INTRODUCTIONThe cognitive aspects in collaborations are broadly discussed in research on computer supported collaborative work (CSCW). Researchers provide high-level insights on the concept of collaborative memory [2, 24] and extensively discuss how to support collaboration partners to create and use a collaborative memory [1, 2, 19] . However, current research focuses mostly on stationary scenarios, and insights on the novel challenges and their influence on group members' cognitive capabilities and the creation of a collabora-tive memory are lacking. Current research on mobile memory aid systems addresses the individual's cognitive capability, and presents diverse solutions to facilitate memory cue creation [15, 16, 21] . However, research insights on suitable support accounting for multiple users are scarce. Both the collaborative situation of the clientconsultant relationship and the mobile setting give rise to new challenges for developing suitable support systems. We thus asked ourselves how an appropriately designed \"memory aid\" could support actors to create and use a collaborative memory in their mobile collaboration. After reviewing related literature on psychology research, CSCWresearch and memory aid systems, as well as discussing different design options, it was \"working with pictures\" that turned out to be a surprisingly useful concept for responding to the characteristics of mobile collaborations and to bring information back into the minds of the actors. Thus, in this study we further pursue the second research question"]}
{"intro": ["We identify that container-like understandings of urban tourism space [51] , as represented in the tourist-historic city model [12] [13] [14] , resemble the traditional framing of space as a \"natural fact\" [64] in the CSCW community. Both approaches, however, are lacking satisfying explanations of how tourism space can emerge and develop in residential neighborhoods. The tourist-historic city model solely takes into account tourism-related facilities and infrastructure as defining elements of tourism space. Such structures are often non-existing in new urban tourism areas like Kreuzk\u00f6lln, one of our case-study neighborhoods. Still, this neighborhood without any major sights is becoming a tourism hotspot [33, 55] . Against this background, we follow a constructionist understanding of urban tourism space [51, 68, 136] . We argue that tourism space, like tourist sights [84] , is socially constructed through representations [99, 102] and performances [15, [45] [46] [47] 74] . That means we no longer regard tourism facilities and infrastructure as the central elements defining tourism space. Instead, people are the major agents who transform places and landscapes into tourist destinations. They attach meanings and values to places and objects [37, 102] , produce written, oral, or pictorial representations of them, and thus contribute to the discourse of how places or objects are to be perceived. Finally, following the performative turn in tourism studies [74, 75] , we argue that places need to be enacted through \"bodily performances\" [15, 75] . Practices, such as picture taking or collectively \"gazing\" [122] upon a building, are necessary to enact places in a touristic manner [76] . Taking these theoretical considerations into account, we analyze how two different Berlin neighborhoods, Kreuzk\u00f6lln and City West, are socially constructed in Airbnb listings. The following three questions guided our research: RQ1: How are the two neighborhoods Kreuzk\u00f6lln and City West constructed as tourism spaces in Airbnb listings? RQ2: How does the space construction differ between these two neighborhoods? RQ3: How do the neighborhood descriptions differ between Airbnb hosts and the destination management and marketing organization (DMO)?"], "relatedWork": ["Understanding space and place on a conceptual level is a central goal of geography. Much empirical work, however, deals with natural or cultural phenomena happening in distinct places. Considering the nature of space just became popular again after the \"spatial turn\" [116] in social sciences from the late 1960s onwards [117] . This development induced debates on the nature of space and place in various disciplines, including the CSCW research community [41, 50, 64] . In 1996, Harrison and Dourish [64] and in 2006 Dourish [41] broadly discussed differences and similarities between the concepts of space and place and resulting implications for CSCW researchers. An important outcome of their considerations, to which we relate our research, is the assumption that digital technologies, such as online sharing platforms, influence the way people encounter and appropriate urban space."], "rq": ["INTRODUCTIONWe identify that container-like understandings of urban tourism space [51] , as represented in the tourist-historic city model [12] [13] [14] , resemble the traditional framing of space as a \"natural fact\" [64] in the CSCW community. Both approaches, however, are lacking satisfying explanations of how tourism space can emerge and develop in residential neighborhoods. The tourist-historic city model solely takes into account tourism-related facilities and infrastructure as defining elements of tourism space. Such structures are often non-existing in new urban tourism areas like Kreuzk\u00f6lln, one of our case-study neighborhoods. Still, this neighborhood without any major sights is becoming a tourism hotspot [33, 55] . Against this background, we follow a constructionist understanding of urban tourism space [51, 68, 136] . We argue that tourism space, like tourist sights [84] , is socially constructed through representations [99, 102] and performances [15, [45] [46] [47] 74] . That means we no longer regard tourism facilities and infrastructure as the central elements defining tourism space. Instead, people are the major agents who transform places and landscapes into tourist destinations. They attach meanings and values to places and objects [37, 102] , produce written, oral, or pictorial representations of them, and thus contribute to the discourse of how places or objects are to be perceived. Finally, following the performative turn in tourism studies [74, 75] , we argue that places need to be enacted through \"bodily performances\" [15, 75] . Practices, such as picture taking or collectively \"gazing\" [122] upon a building, are necessary to enact places in a touristic manner [76] . Taking these theoretical considerations into account, we analyze how two different Berlin neighborhoods, Kreuzk\u00f6lln and City West, are socially constructed in Airbnb listings. The following three questions guided our research: RQ1: How are the two neighborhoods Kreuzk\u00f6lln and City West constructed as tourism spaces in Airbnb listings? RQ2: How does the space construction differ between these two neighborhoods? RQ3: How do the neighborhood descriptions differ between Airbnb hosts and the destination management and marketing organization (DMO)?"]}
{"intro": ["There are two implicit assumptions in the above research question, which are intuitive but not always confirmed by prior studies. The first assumption is that profiles length positively affects user utility. Some works show that profile length of new users is positively correlated to the accuracy of recommendations in term of user utility [12] [13] [4] . However, this result cannot be easily generalized, as its supporting experiments are limited to item-based collaborative algorithms, and accuracy is measured only in terms of error metrics: RMSE [13] and MAE [4] . Moreover, [28] finds that the correlation between profile length and utility is not always present, but it depends on the elicitation strategy adopted. These studies instill some doubts on the general assumption that a longer profile corresponds to more accurate recommendations. We may wonder, for example, to what extent we can claim that the fallout of a content-based recommender algorithm improves with the profile length."], "relatedWork": ["Similar results are outlined in [29] , where experiments show that more elicited ratings do not necessarily imply more perceived effort. However, these findings have a different motivation with respect to [27] and [28] . Users in [29] perceive a low effort with poor quality recommender algorithms, even in the case of a very long elicitation process, as they feel the need to provide more ratings to the RS in order to improve quality."], "rq": ["INTRODUCTIONThere are two implicit assumptions in the above research question, which are intuitive but not always confirmed by prior studies. The first assumption is that profiles length positively affects user utility. Some works show that profile length of new users is positively correlated to the accuracy of recommendations in term of user utility [12] [13] [4] . However, this result cannot be easily generalized, as its supporting experiments are limited to item-based collaborative algorithms, and accuracy is measured only in terms of error metrics: RMSE [13] and MAE [4] . Moreover, [28] finds that the correlation between profile length and utility is not always present, but it depends on the elicitation strategy adopted. These studies instill some doubts on the general assumption that a longer profile corresponds to more accurate recommendations. We may wonder, for example, to what extent we can claim that the fallout of a content-based recommender algorithm improves with the profile length."]}
{"intro": [], "relatedWork": ["The nature of sensemaking activities and the cognitive processes involved have been the subject of established work [28, 41] , with recent studies focusing on how groups establish common ground [12, 13, 21, 56] , uncover hidden knowledge [14, 22] , and engage with large analyses [20, 27, 37, 38, 40] . In terms of general sensemaking, the data-frame model [28] describes several key macrocogintive processes relevant to our own investigation, including connecting data to a frame (an explanation reflecting person's compiled experience), reframing, elaborating, questioning and comparing frames. The more recent work detail additional behavioural and analytical processes observed in collaborative settings. Our work is orthogonal, focusing on the role of expertise. In terms of analysis methods, our work is similar to [23] who performed an insight-based user study to understand how analysts reach insight during visual exploration. Our focus, however, is on collaborative model exploration, in particular for trade-off analysis."], "rq": ["We looked at frequency and order of scenario types.When it comes to the setup, although we used a multitouch interactive surface throughout the study, predominantly a single domain expert led most of the interaction in each case study session. The rest of the participants discussed seated or standing, but refrained from interacting. This finding is supported by other studies on collaboration around interactive displays [47, 53] . We note that although most participants did not interact directly with the display, they were however actively involved in the exploration. For example, they proposed new research questions, requested to see particular views or to refine existing criteria. We also observed at least two instances in UC1 where domain experts explored the Pareto front in their own laptops.", "Subjective User FeedbackTo the best of our knowledge, there are no other studies that looked at collaborative model exploration in real-world settings. In terms of results, we found similar processes to those described in general sensemaking literature [28, 41] . Our contribution here, however, is in identifying why these processes tend to occur (e.g., storytelling to recap), and when they occur (e.g., storytelling periodically for large groups, or at the end of big chunks of exploration for smaller groups). Alignment is a particular process to model exploration, also described in [11] . However, our work considers more complex models, multiple computational stages and co-located expertise. We discuss next seven key findings from our study, relating them to our initial research questions, and comment on the applicability of our methods to other domains:", "Subjective User Feedback1. Exploration as Multiple Linked Analysis Scenarios [Q1] We observed that exploration is split into mini-exploration scenarios. Trade-off analysis starts with a preliminary exploration often leading to a focused research question. The remainder of the exploration is characterised by the nonlinear interleaving of new and refined hypotheses and research questions [41] , operating on a variety of exploration objects. Those scenarios denote a shift in the research questions and hypotheses set out by experts, which often result in change of focus in the model or data space. A parallel can be drawn between our approach and the data-frame model described in [28] . For instance, their \"reframing\" maps to our new scenario, and \"elaborating the frame\" to our refine scenario. In our case, however, re-framing revealed itself to happen specifically when participants shift their research questions and hypotheses. Furthermore, we provide a more fine grained analysis of the exploration, by crossing high level categories of interest (e.g., insight, expertise), with exploration objects (correlation, exploration method)."]}
{"intro": [], "relatedWork": ["In robotics, the delay inherent to control loops can have a detrimental impact on system performance. This is particularly true for sensor-based control used in autonomous robots. Visual servoing of a robot, for example, can be sensitive to the delays introduced through image acquisition and processing [9] . Similarly, delays in proprioception can produce instabilities during dynamic motion generation. In [2] , a dynamically smooth controller has been proposed that can deal with delay in proprioceptive readings. However, the approach assumes constant and known time-delay. A major milestone in robot control with time-delay was the ROTEX experiment [8] . Here, extended Kalman filters and graphical representation were used to estimate the state of objects in space, thereby enabling sensor-based long-range teleoperation. How to effectively deal with such communication delays has been a central research question in robotic tele-operation. Delays in robot control loops are not limited to sensor measurements only. A prominent approach for dealing with actuation delays is the Smith Predictor [17] . The Smith Predictor assumes a model of the plant, e.g. robot system, and can become unstable in the presence of model inaccuracies. A different approach has been proposed in [3] . A neural network was first trained to predict the state of mobile robots based on positions, orientations, and the previously issued action commands. The decision making process was, then, based on predicted states instead of perceived states, e.g. sensor readings. The approach presented in our paper follows a similar line of thought. However, instead of predicting specific states of the robot, we are interested in predicting the delay occurring at different parts of the control loop."], "rq": ["II. RELATED WORKIn robotics, the delay inherent to control loops can have a detrimental impact on system performance. This is particularly true for sensor-based control used in autonomous robots. Visual servoing of a robot, for example, can be sensitive to the delays introduced through image acquisition and processing [9] . Similarly, delays in proprioception can produce instabilities during dynamic motion generation. In [2] , a dynamically smooth controller has been proposed that can deal with delay in proprioceptive readings. However, the approach assumes constant and known time-delay. A major milestone in robot control with time-delay was the ROTEX experiment [8] . Here, extended Kalman filters and graphical representation were used to estimate the state of objects in space, thereby enabling sensor-based long-range teleoperation. How to effectively deal with such communication delays has been a central research question in robotic tele-operation. Delays in robot control loops are not limited to sensor measurements only. A prominent approach for dealing with actuation delays is the Smith Predictor [17] . The Smith Predictor assumes a model of the plant, e.g. robot system, and can become unstable in the presence of model inaccuracies. A different approach has been proposed in [3] . A neural network was first trained to predict the state of mobile robots based on positions, orientations, and the previously issued action commands. The decision making process was, then, based on predicted states instead of perceived states, e.g. sensor readings. The approach presented in our paper follows a similar line of thought. However, instead of predicting specific states of the robot, we are interested in predicting the delay occurring at different parts of the control loop."]}
