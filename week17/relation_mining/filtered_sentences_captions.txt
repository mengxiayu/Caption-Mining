sentence	source
,uh... perhaps you're going to write it in c, perhaps you're going to write it in some other language. it doesn't matter. it doesn't matter. the idea is all the same. ok so here's the goal. we're going to try to modify this code to be what's called 'thread safe' in other words i can actually use it with multiple threads so along the way we're going to fix some errors as well. ok so what do we got. we've got a pointer that corresponds to the start of my linked list. uhm, in more complicated examples this might be in a separate data structure but this is good enough for a little example here. ok, and then i've got two methods to	['a struct', 'code', 'thread', 'pointer']
a million dollars and oh hold on a moment what's this dinosaur business that should never appear remember my second my other thread didn't actually do anything with the result instead this dinosaur is claiming that it's so jurassic park have one close to a billion dollars right so we can see that these two threads are are interacting in a way that we don't want to happen right the string that we're using down here have been corrupted by the other thread now hopefully this is probably obvious as to why this is happening that the two calls to text message from other one another two both end up writing into the same piece of memory so let's just talk about how we might try to fix it so one possibility is you might say well what if i made this static ok that's not going to help all you've done is change the visibility of this variable is still only going to be one of it is just that now only the code inside this dot c file this compilation unit will actually be able to refer to this particular variable	['memory', 'code', 'string', 'thread']
about it when i'm doing internal memory pointers if i just say this is always how i'm going to treat my code or my pointers etc are going to be this type or my editions will be based on this ok so what do we lose well we lose a little bit of flexibility were potentially over allocating bites so in fact we might need to a small amount of wasted space	['memory', 'type', 'code', 'pointer']
acquire in the same order i can never generate the case where i've got a process to which has now acquired this but then also goes backwards and create awaiting condition on an earlier resource all of my lines which correspond to it waiting for resources must be to the right i cannot generate that cycle in the wakeful graph which pictorially always kind of looks like a bow tie where i've ended up with weights on resources which are both before and after in my resource order so all of my weights i'm going to be to the right and therefore is always possible for the earlier resources to be complete my process is complete so therefore i cannot set up a chain or between my process is where i end up say with process three waiting for process one and process one waiting for process doing ok so that is the secret source it's always make sure that we get resources in the same order so i want you to think about how you would implement that suppose for example you had a set of integers say they might be under a one of a link list and each one of those integers has a mutex lock so m one m two m three m four m five etc how can i make sure that if i need to lock let's say two or three mutex locks in order to modify those integers how can i ensure that all of my code always locks the necessary integers in the same order case how would you do that and answers that will be in a future lecture video bye for now	['code', 'a mutex', 'a process', 'resources', 'code', 'a mutex', 'a process', 'resources']
across multiple processes using shared memory but more about that in the future also notice that my counting semaphores here number spaces and numb items i'm afraid works on linux but does not work on os x so if you in turn apple maybe think about this as a summer project ok so great we've got something which works providing only one thread at a time is calling nq if i have multiple threads then they could both get past this line but my changing of the buffer here is actually critical section i don't want two threads to see the same value of in here so first of all declare these right and so i better have a mutex lock inside here so pthread mutex look	['memory', 'a mutex', 'section', 'thread']
actually if we look back in time r block size on old systems was actually limited to just five hundred twelve twelve bytes so so if you want to know about the actual space used on their disk you can read this kind of blocksize here but realize that that if you	['block', 'system', 'block', 'system']
all automatic variables are little stack variables here and that includes parameters as well ok so what does t what is t one and what's it doing well t one what is its type is a pointer to a character and otherwise it's going to hold a memory address and add that memory address we expect to find characters right but we're giving it this string so actually a t one is going to hold the memory address of that h it's going to point directly into the text segment it's going to hold that memory address which between you and me is going to be a low value the text document is is it near the beginning of the processes memory ok now this is a price however with t two t two is not a pointer is actually an array we didn't bother to specify the size because the compiler can work that out itself and the surprise here is actually the compiler is going to write some extra code for us here because rather than just looking at that that string literal in memory when we call this function it's actually going to copy those bites it's going to copy the one two three four five six seven eight nine bites including that zero bye to the end into the stack memory forwards so if i was to stop my process an actually use a debugger to have a look around i would find the original abcdefg h and then i'd find a copy of that inside the stack and the difference between the two of course is that the stack version we can modify as minutes mutable because it's just stack memory	['memory', 'type', 'parameter', 'code', 'string', 'address', 'pointer']
all right and again we could reason about this we could say if there's if there's any locks if there's any threads sleeping on this waiting to push the only time that that can occur is if the reached the maximum number so if any is equal to now nine then i know that	['thread', 'thread', 'thread', 'thread']
all we have to remember is that we are very careful to only use that piece of memory be careful so if we asked one hundred bytes only use a hundred bytes don't start using the hundred one hundred two hundred three bites step probably important and being used for something else also if we know the start of our allocation don't use the bytes before again those bytes are probably going to be used for something else and if we override them then our program will probably have undefined behavior who knows what it's going to do so let's take a look at this little puzzle here i've got two calls to malloc i'm requesting ten bites and then later eight bytes and the puzzle is how can i make these two calls actually returned the same address now you might notice in this example here that i've got these void things so avoid pointer means i want to store an address and i'm not going to tell you what there just simply treat it as a number as an address as a memory location and we won't talk about what kind of objects or what kind of primitives or anything about with storing there so we can't we can't we shouldn't do pointer arithmetic on void pointers or at least that's the official line more about that later ok so we've got our two memory allocation requests how could these possibly would be returned the same thing so the answer to our little puzzle here is what do we do the following after calling malloc we immediately say hey thanks so those bites but you know what i changed my mind i don't need them anymore so let me call free and pass in	['the following', 'memory', 'memory allocation', 'address', 'pointer']
alright let's get back to the next part right so also on the compilation step we have this wonderful thing called size of now size of it is evaluated at compile time let me say that again at compile time so if i say size of int the compiler says look on this platform i know that an inch is four bytes or eight bytes so that actually becomes a number eight four oh eight if i give it a variable like counter then it will depend upon the type that variable so if a counter isn't it again this would evaluate to save four on a particular platform possibly even two on a small embedded cpu ok so it tells us the number of bytes required to store that value if i have a pointer so let me make it a point to type so here is a pointer to an int ok so on a thirty two bit system there were thirty two wires which represents the address all my addressable memory ok so if i want to talk about a particular address being able to read or write a particular bite i need thirty two bits also known as four bytes so on that particular machine i would need for bytes to hold a pointer to a particular integer on a modern processor probably you're looking at me right now using a sixty four bit processor sixty four bits is going to require a sixty four bits to hold an address in other words it's going to take eight bytes to hold that address so so size of can be very useful now when i care about how big something is	['memory', 'type', 'address', 'system', 'pointer']
also notice that we've had to do a mem copy here so that's the performance cost of of buffering which is now we're copying bytes into memory so if you're so we've traded one performance hick up for another so yes we can improve performance a little bit because we're not making lots and lots of lots of calls to the system for every little character in every little string that we're trying to send out but the expense but the way we paid for it is to now copy things into a single buffer so this is has some performance improvement but i hope you can see that for really specialized cases this distill has some performance penalty and so we could still do even better than that if we wanted to take control over own destiny and not use things like f board s to write truly performant code so yes we've reduced the number of system calls but we've paid for it by copying things into memory so there's an additional cost there alright so that's kind of quick sketch of the things we need to think about when implementing the c library are see you in the next video bye	['memory', 'code', 'string', 'system']
an actual string like this or i can specify it as a host name so for example like illinois dot edu ok if i do this then there's probably going to be a packet leaving my machine in the next moment to say hey we need to figure out the ip address of this host name can you help me please	['string', 'address', 'string', 'address']
and also if we pop from things we will just decrement size k and pre decrement size and then read that as our result so in this implementation the value the thing that we're putting on and the thing that we would later return at the same thing it's not like we're actually going to duplicate this string being passed it was simply going to say oh thanks for that memory pointer later on i will give you back exactly the same memory pointer so it's up to the calling code to make sure that the	['memory', 'code', 'string', 'pointer']
and and and be very careful about about typos when you copy paste code alright so we've made our first program that can run two things at the same time in fact is doing three things at the same time we've got our original thread that's going to get stuck at these two places these two gatekeepers the only way you can get through both is after both threads have finished and we had two threads running hello we could have made it more complicated example where we started another thread starting on yeah or different function altogether ok the big news however is to all of these threads live inside the same address space they can all see the same physical ram if you had one thread that was like agent smith that wanted to go haywire it could actually overwrite the other pieces of memory of the other threads in an effort to take over the world ok right so i'll see you in the next video bye	['memory', 'code', 'thread', 'address']
and as usual we've assumed that the format of are integers is compatible with a type here and even that the format of our our string incompatible say that it's going to be using ascii it might be using a different kind of character set for example might be using unicode or utf eight etc etc etc so life is never as quite as easy as it appears and as you can see we're doing a lot of work and in fact it's going to be quite slow to call not only making a remote procedure call will also the heat memory as well ok so but that's kind of a feel for why are writing this stuff code is is annoying boilerplate stuff to write ideally we'd have a tool to generate it for us and you've seen one example of that already in the lab with rpc jenn right so this socially now think about how we can kind of marshall all the data that we want to kind of send over the while and how we can une marshall it as well and that's going to be our next video bye	['memory', 'type', 'code', 'string']
and as you can see initially i don't have any cake ok but soon we're going to be creating cake and we're going to use this because i want to talk about creating resources and then consuming those resources ok it's kind of very standard problem that we're going to have when we start writing larger pieces of code that now i've got bits of code processes and threads which are putting things into my data structure or or finishing images or finishing processing of videos etc and then i've got other threads say great as soon as you have these things i wanted now consume these and act upon them right so what do i have in order to implement this well you can see just like i could have p thread threads i can have a mutex thing here it is and here is a condition variable and just like a p thread mutex initializer lips will fix that actually must be an underscore	['a struct', 'code', 'a mutex', 'thread', 'resources']
and as you know they are necessary and sufficient we need all fall to be true and exactly or for them to be true and then we know that we've met the conditions for deadlock so what are they let's actually look at some definitions here so here's the first wanna process is currently holding at least one resource and requesting additional resources which are being held by other processes ok so it is holding and waiting so that's a hold and wait condition	['a process', 'resources', 'a process', 'resources', 'a process', 'resources', 'a process', 'resources']
and at the steps were going to kind of concentrate on here is actually this very first step is to somehow we need a way to wait to enter the griddle section if another thread or process is inside the critical section and then we'll do something so there's a critical section code and then will lead to critical section so we need to do something after that and then most of the time off threads and processes doing other things so that's the problem we're going to solve this problem we're going to address is how do we how do we correctly deal with critical sections and we're going to look from this from a historical perspective and look at some examples which don't work alright that's it for today that's it for days lecture video and i'll see you in the future bye	['code', 'section', 'thread', 'address']
and finally we need to return something to the user should we return chosen now that would be a mistake that would be the wrong memory address return we actually want to return the piece of memory that we allocated for them which is inside our data structure under the word pointer or under the field pointer ok right so what do you think about that does it work yes it does but there's a couple of bugs here so i'll talk about one and then we'll talk about some of the others in a little bit so one quick problem is it is actually pretty slow look at all of these system calls or calling s break here ass break their esport here ass break their perhaps surely you can do better than that well yes actually here's one quick way there if you actually read the description of how s brake works it returns the old	['memory', 'a struct', 'address', 'system', 'pointer']
and for that we really don't need to understand how to work with errors and how to print out errors and how to discover when things don't work so networking is tricky because with things don't work where you actually want to understand what your problem with the client or the server was there a problem in setting up the connection and so dealing with errors becomes quite important areas can be because of code areas we've made but it also can be say because the client has finished the connection before the server had finished saying everything he wanted to say unvoice versa ok so let's start talking about errors that right so	['code', 'code', 'code', 'code']
and i need to declare it i don't need to write that i can just i know that it's inside you <unistd.h> right so now we have a little main method high maine and you take the number of arguments and a pointer pointer rv fight ok so let's just read from standard input right now i need a place for that i need some bites well i could call malloc to get some bites on the heap i could have a global variable such as an array or i could have a stack variable read does not care or re cares about is hey give me an address and tell me how many bytes i can right there ok so let me have a little buffer space here pick a random number like four thousand ninety six ok so now you know that if i just use the variable buffer without pushing the square brackets then that is going to evaluate the very first bite of that away or the stack is not a pointer it's an away and arrays can't be changed to look at somewhere else so i can't say ok variable start looking at this other memory location you cannot do that but we can use it in a pointer context so let's do that let's call size t and will say result and say ok read now at this point i need that file descriptor	['memory', 'the heap', 'address', 'pointer']
and i want to reserve some space for might my file so i'd like to know how big it is now one way you may have seen already is simply to use stat stat tells me all sorts of great things about a file its size which file system is on the number of hard links we haven't talked about yet modification times and all that good stuff but let's just stay within the c library today for the most portable code and figure out how big the file	['code', 'system', 'code', 'system']
and if it changes it will send her a warning message out ok so it's going to be busy keep going around inside this loop checking the date as fast as it possibly can right so that's the code we know and also we set the name of the thread to hal nine thousand hope you know the movie reference and then let's start that running through it ok so i want to run this i'm going to say write java please run my app and i went in the background now if i was running on lenox this would actually print out the process id why because here i'm opening a special file called slash proc slash self and that is normally a symbolic link in lenox to the process numbers so then i could get the real path and get its name however i'm running on a mac so that did not tell me the proces name right so what are we going to do about that well fortunately i could do several things i can for example use ps and that would be a huge list of all processes there's even a version with java however there's just prints out to java processes so there we go we found out they process id of the currently running program so now great i can send a signal let's do sig quit to eighteen seventy	['code', 'a process', 'thread', 'background']
and if you want to use it from code then there's the equivalent system call here again we use a path but this time you actually to specify the mode numbers as well there are symbolic numbers in here or you can write your own octal number in here ok so but there is not this kind of second form you can't do this from	['code', 'system', 'code', 'system']
and inside our main method we're going to do we're going to create a whole load of pizza it's ok and make a note of their thread i ds pass in the firework function ok and then after we've done that we will set fireworks equal to one and then will call preconditions signals so we know that is going to wake up one thread	['thread', 'thread', 'thread', 'thread', 'thread', 'thread']
and it's important to bear in mind that anything else any other threads that are running will continue to exit it's just that one thread that happens to be running this hello code ok right so we could now start to kind of create create our threads here so let's do p thread create and at this point i need to give it a pointer to a thread id so i need the address of my little variable here will make that in a moment the next thing is the attributes and i don't need any of those	['code', 'a thread', 'thread', 'address', 'pointer']
and my calls here wouldn't be able to continue until say these two have completed and then i can start doing the merge simile this merge can happen once these two have finished so it's kind of fun to sketch out how you might actually implement this so how would you use condition way to how to use p threaded barrier to make your code run nice and fast	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
and my little loop will know when i call pizza create i have to pass in a void pointer but what if that void pointer actually was just the y value in other words somehow will take the value that we want to give to a thread and convert it into just the void pointer type so we're literally just casting it pretending that the values zero is a memory location pretending that value one is a memory location etc so we're not actually passing in the address of a real piece of memory we're just converting the integer into a void pointer into a memory pointer we have to do the same hack when we receive this information so we've asked thread create to start a thread and to get a new cpu for us to run this calc one so what is calc one here it is ok and the value that we pass into hack here so here's hack which is going to appear here that's going to be passed into this variable here avoid pointed here and rather than try to dereference that no we're treating that memory location that address as the actual integer that we want ok so we're passing it casting it back into it so this is an exciting hack honestly we have no true way to know whether enters officially going to be as large or smaller than what can be represented by a void pointer i certainly wouldn't recommend this in production code but i hope you can see how it works and certainly you will come across these kind	['memory', 'type', 'code', 'a thread', 'thread', 'address', 'pointer']
and now i want to represent that so with my ascii graphics i'm going to have a character i wanted to display in each one of those positions of my little terminal window so i've got height times width and i just want to initially to set all of those two a dot k so rather than might be in for loop let's use their more performant memset i want every bite to be this doc character so whatever ascii value that happens to be happens to be thirty three but no one needs to know that and will do that for the say half million characters or however many there are in my display probably eighty times twenty four for example right so time to get started right so here's here's the plan then right i need the thread runner that's going to sign my thread that's going to run the display and that's going to run the function called display and as an argument will pass that heap memory and then i've got all of my runners which actually cause the rain on my display so they're going to run a little function called run and again i pass a pointer to my heat then we so you might be concerned that my variable here image is actually a stack variable will remember we're not actually going to that particular variable we actually passing its value what is this value is a pointer is looking at the heap memory that we we allocated here ok so yes we are using a heap stack variable here but that's fine because actually what gets passed is the address of of heap memory of the mileage memory ok so anyway back to this we're going to create all of those threads we remember the thread i ds then we're going to call p fed exit on our main thread in other words we will never get to this line here so	['heap memory', 'memory', 'the heap', 'thread', 'address', 'pointer']
"and now i've got, great, the actual information i wanted to do with system call that i can make called open. or i want to know about the stat, and great, i've got all the versions of stat that i can now use on my apple system here. so section two is reserved for kind of system calls. what about strlen? so if i ask for strlen, there is no manual entry for strlen inside section two. why not? strlen not a system call. we do not need to go back to the kernel ""and say, """"hey excuse me, kernel, please look at my memory"" ""to figure out how long my c string is."""" i don't need"" to invoke the whole operating system for that. i can do that directly inside my process's memory. so for things which are part of the c library, i just need to go to section three. and so that's where we'll find strlen and other things like strcmp to compare two strings, or say strcat. so [indistinct word] up to specify the system area, sorry, the"	['memory', 'string', 'section', 'a system call', 'system']
and program to run and maybe you want to specify some optional arguments to pass that program ok let's have a new line at the end ok watch that percent sp it should be the string at that very first entry of that little table we drew ok after that do not continue do not collect two hundred dollars etc do not play monopoly instead exit with an error code right so down here now we want to call exec so i'm going to call exec and i want to use your version i want to use a path please so you don't have to specify the exact location on the file system ok so in here i need to program dayton let's have a variable that does that and then what about my array well i don't want to start at the beginning i don't want to give it the address of that little table the beginning i want to move forward by one i want to give my process name i wanted to pass in whatever i want to pass in where my table starts and the first thing is give me the program we want to run ok so we do argv plus one we want to move advance to that second pointer in that away and let's hope it fails i'm sorry succeeds if it fails then we're going to get to line eleven time to print something out so we can say exact failed and maybe going to find out a little bit more about why and then again let's exit with an error value k	['code', 'string', 'address', 'system', 'pointer']
and secondly what value do you think might be in there were malik for performance makes no guarantees about the contents of the memory that it gives you it could be all zeros because you put your nice new fresh process and for security the kernel is giving you piece of ramp that it is personally zeroed out just for you or it could be that you been calling malloc and free a lot and so now you're malloc your heat memory looks like an old dirty sock drawer where bits of memory a cold hole arbitrary values from previous malloc calls and so we are just treating it as a struct but actually all the memory is just a whole lot of zeros and ones so the value that you're going to see for this next pointer it's completely arbitrary even if we hadn't freed it so that's several mistakes here if we actually want to use things then don't freedom first only freedom after you've finished using them and better code would then set this next pointer to zero after after freeing it but so so this is a good good example of how not to write link this code with that let's finish this lecture have a great time thank you and goodbye	['memory', 'a struct', 'code', 'pointer']
and so what do we do we take something out of the data structure and then will print this thread managed to eat this and in fact this code is going to be run by multiple threats ok we're going to have two threads trying to eat cookies at the same time ok but will protect our data structure by the use of this peter mutex lock ok we need to weigh to add things to a data structure and so here is my little add cookie notice that i've got i protected my change the data structure using using the lock and after modifying the data structure i'm also going to broadcast so anybody any thread that happens to be sleeping inside the condition available will be working up	['the data structure', 'a struct', 'code', 'thread']
and that will release the lock whilst it's blocking ok so here's our condition variable that were going to sleep in and watched was sleeping unlock that mutex and then before returning lock it again so the big idea here is that in all the code that we write let's do i make a highlighter well let's do it like like a yellow ok it all this code every single piece of this	['block', 'code', 'block', 'code', 'block', 'code', 'block', 'code']
and then here's an expression to read that value how does this work ok so we know when finally were assigned a new cpu to start this function that we're given address what do i want to do with that address well i know something is stored there and i know that that's something isn't is just so in fact i want to treat that address as an integer pointer great so now i have that integer pointer i actually want to read whatsapp their contents so let me dereference it with little ass tricks there ok so we've got the value now we've been seeing how we can create p thread i ds	['thread', 'address', 'pointer', 'thread', 'address', 'pointer', 'thread', 'address', 'pointer']
and then i don't want to pass in the address if i instead i want to pass in my pointer to one of these you introduce i've just created so starting values and i could say take the ice warren i want the address of that but you know that we can also write that is just ok here's the start of the array i want the offset of ips and will use integer arithmetic ok so we've initialized array let's give this ago and off we go so will compile it ok	['address', 'pointer', 'address', 'pointer']
and then i've got also my stack another variable core pointer and what type is it it's a pointer never mind what it points to simply by the fact that it has to point to any memory address means that it's going to need to be the right number of bytes queso say on a thirty two bit machine that will be four bites on a sixty four bit machine will be a preds ok so will pretend that i've made a one two three four five six seven ok have one more byte there we go by eight bytes there and what do we put inside this these eight bytes the memory address of a literally it's looking at a it's holding that address and then we have another variable called child when we put that in here these will stack variables and we call fork right ok and what do we do inside the child rights so if with a child we do reference or pointer and we change the value to twenty in other words in the child we are writing the value or twenty inside the area here so we're going to put stupid little arrow have a blue blue arrow key	['memory', 'type', 'address', 'pointer']
and then they call same way on s one but we've already incremented it's once they get to continue and then post on some post which will never block and now they overwrite their buffers so it's pretty big unhappy space here yes we've seen a problem here of overflow buffer overflow we overrode a value that we actually need we actually managed to put too much stuff into the buffer now the chances of that happening are pretty small is this very small number of microseconds between us calling sam post and then asking for the mutex lock but that is a non zero value also notice it's actually only really going to be a problem when my buffer is actually completely full so perhaps under light testing or if your website doesn't have many customers then you're not going to see this problem it's only when your buffer actually hit capacity do you have exposure to this problem ok so that's kind of fun stuff to think about reasoning about code like this is tricky my advice is to think about kind of the extreme conditions like underflow and the overflow and what happens if you have say two threads appearing at the same time and what would happen if just before you acquire the mutex lock another thread was able to acquire it instead	['block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread']
and then we say well while fireworks is zero corporate recognition weight in other words if my firework thread starts up here and it starts up early then we're just going to block it for but we're going to ask it to release the mutex lock and lock inside here so go back to the kind of first code remember we created all of the threads initially back when are fireworks variable with zero it's only after we've created all five	['block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread']
and then when you first create a thread it will inherit the signal mask of of the creating threat basically if you like his parent thread that created the feather called preferred create so it's pretty common to see multithreaded code first of all set the signal mask to say hey just block all signals i don't want to know about them right now then create all the threads that needs and then inside say one thread start changing the signal mass to say ok this is the thread that i want to be interrupted in order to process in order to run the signal handlers	['block', 'code', 'a thread', 'thread']
and then will print out that message alright so we expect to see some message involving an grove and illinois meanwhile i have another thread that doesn't print anything all it does it just calls two text message at the same time so let's see if we run into any problems here because it looks like this is a completely useless thread right it doesn't actually do anything with the result it just keeps on calling text message so my question to this is problem are we going to run into any kind of critical sections here can we find any race conditions to answer that we actually need to understand more about two text message now i'm already a little concerned about it because it clearly returns a pointer here which we never free so i that is appointed to some global memory or like a static variable or this is generating	['memory', 'section', 'thread', 'pointer']
and they call lock on the same mutex lock ok can they carry on and execute their next piece of code no there blocked there stuck in effect that cpu goes to sleep in practice the kernel can say oh i can see you you're stuck right now you're short order cook can't device because there is no voice yet so i'm actually going to sign the physical cpu to do something else i've got another thread that would love to get started love to get do some work right now so let me tell us you're going to do something else but from this thread perspective nothing was going to happen it does not pass go does not execute the next line of code until the day that our thread one has finished doing what it's doing inside those critical section	['block', 'code', 'section', 'thread']
and to make it tricky we're not going to use any counters we're just going to use pointer arithmetic ok so here's the challenge denton right so i'm going to take a memory address which will be the value of where this array starts in memory it's actual memory location and i want to keep walking through that reading each integer until i find negative one so his head will do this then so i'll have another variable my little pointer here and that's what we're going to keep changing and will keep incrementing it until we get to that negative one so it's so i want to see the value of the current address so let's use that point to remember pointers are meant to be used most of the time let's actually dereference him let's actually go and read the stuff at that memory right so once that is not equal to negative one what i want to do is change my pointer what do i want to move it to the next values so i could write pointer equals point oh plus one but i could shorten that two plus plus and with pointer arithmetic if we add one the compilers going today or this pointer points to integers so i need to move it not just one bite forward but enough bytes forward so that it can actually access the next integer so the type is always used with the pointer arithmetic right so we're going to go round and we're going to keep moving forward reading integers hopefully we're going to find that negative one at some point which point how can we discover the integer well so i discovered the number of items we need to read so items into the interval before validated was found so here's kind of the big surprise if i now take that address and subtract off the other address of where we started then that subtraction again is pointer arithmetic which means that the size of the pointers matches so this won't tell me the number of bytes between where we ended up and where we started will actually tell me the number of integers that we needed to advance in order to find that negative one so that's kind of a fun little pointer arithmetic problem and in the next video what are we going to do yes i'm going to challenge for you how could we possibly be that p one and p two actually refer to the same memory location as it did that in the next video bye	['memory', 'type', 'address', 'pointer']
and typically with these design languages you have to declare whether a parameter is read in or right out or both so for example we might say that this parameter is something which is the value is passed into the function rather than being sent out of the function and the joy of using an idl is that we can specify these high level descriptions of each function and then just crank the handle hit go and our our rpc tools will automatically generate all the marshaling code force you've seen this already with rpc jen which has its one his own version of an idl an idl can get more complicated than this when we start talking about structures and composite types we're going to mention a couple of other examples of this where we are in terms of google protocol buffers but that's it for this video in their next video i'm gonna talk about complexity and the latency of yor pc calls so expensive ok bye for now	['type', 'parameter', 'code', 'protocol buffers']
and we want to find ways to ensure the only one thread enter the critical section at a time so this is actually a classic operating system problem because critical sections occur all over the place inside the kernel because there's so much concurrency going on and can we kind of find a way to write code to ensure that	['code', 'section', 'thread', 'system']
and what about the actual protections for each page of memory ok so we want to be able to read and we want to be able to write to these pages of memory but i don't need to be able to execute them i don't care where inside my virtual address space this memory ends up and i want four thousand and ninety six bytes please ok so if this succeeds great i get it back a pointer which i can actually start to use it will be the contents of alice dot text but we of course were able to change it so let's do that right so here's a little demo where i'm actually going to now do some communication between a parent and a child so strong copy and i can copy contents directly into that memory location so here's the child writing something into there and what about the parent the parent can read from the same address now back at the beginning of two forty one and we talked about forking we said hey these are completely different address spaces and actually there are no longer connected after you called fork ok well guess what that was a little lie why because you couldn't handle the truth but now let's actually have a look at the truth with mmap we can share things and this is the really cool part of mapping memory here that both the child and the parents will see this piece of memory and it will be the same piece of memory the same physical piece of ram for both the parent and the child for this particular mapping to alice dot text so the moment that the child starts writing into those piece that pieces of ramp the parent can read it as well so isn't that cool let's actually kind of a look at this let's actually do some rp cs sorry some interprocess communication some ipc between the parent and a child so off we go right	['memory', 'mmap', 'address', 'pointer']
and what can i do with them ok so a lot doesn't support that many operations we can lock it and unlock it so let's have a look at that code and big important idea is before we're out allowed to lock and unlock the mutex i have to initialize it so there's a couple of ways you can do that guess what you can say pthread mutex iniciat and pass in a lock and one of the great things about pizza it's implementation of mutex locks is that we can actually pass in a few attributes like we can set it up to debug we can actually create recursive locks but i'm going to anyway we're going to stick with this vanilla logs today again this is kind of one of the example where where the posix implementation the positive definition of mutex logs goes a little bit further than what the new c standards do ok so i want to initialize my lock and i'm not going to pass in any special attributes today right so that's one way of doing it	['code', 'thread', 'code', 'thread']
"and when we want to ensure good performance as well. because the c library, when we actually say, """"""hey, print out the following numbers for me or send me to"" """"""send the following strings,"""" isn't necessarily"" going to immediately call write. it's not immediately going to call the system. instead, for performance, it may choose to buffer all of that content inside the memory until the day that we decide to flush it out until the day we decide to send it. so let's turn our attention then to the kind of c library version of the world where,"	['the following', 'memory', 'string', 'system']
are we done no well ok you just typed a character but how is that character represented we're so used to thinking about the fact that we're writing in say ascii or utf eight that doesn't actually have to be the only way that we can represent our data so for example perhaps you want to store and send pictures using a jpeg format or perhaps you want to send a text using this ebcdic format which is a different way to represent characters or perhaps you want to use png so perhaps you want to do movies etc ok are we done no at the top most level is the idea of the application so at the application level, we get to define our own apis we get to define how we want to access remote files and resources and describe things like directory services as well so this top most level this is where we start talking about ok i want to be able to access web resources using http which itself is a protocol that grew out of a simple file transfer protocol and another well known protocol here is smtp which is a way for us to send emails simple mail transfer protocol so smtp allows you to send very simple messages or to send emails with attachments for example ok so these different levels of abstraction allow us to work independently so for example tomorrow i might decide that as you want to access a web page not over tcp but over udp of course if i do that then my web client better be able to actually handle udp connections and also my web server needs to be able to handle udp connections does it happen today yes surprising it does so if you happen to be a rather large company called google for example you might actually decide that you want to implement your own connections using udp and you can do this because you own both parts of the network you own both the client and the server also tomorrow you might decide that you want to support not only ip four but ip six as well and you might do this because you actually want to start creating new servers and yeah you're unable to get an existing ip four address ok so that's a little bit about the open systems interconnection model or the osi model	['a protocol', 'type', 'resources', 'address', 'system']
be actually performing writing currently i've got the number of readers currently accessing the data structure so whilst that is non zero my writers are going to have to wait and also the number of readers they would like or want to be reading so this may be larger than the number of readers actually reading ok so with that in mind it's actually kind of see how we've sketched this out ok obviously we have some mutex locks to ensure that we update these variables atomically but the very first thing we're going to do then for each of these sections is to is to either call preferred mutex lock or unlock so for a few microseconds we hold onto a log but that's only for us to do some accounting either we will immediately a scape can have through this code or we will end up calling peter condition way in which case we release the mutex anyway	['the data structure', 'a struct', 'code', 'section']
because two threads of enter the critical section at the same time right so if we test our code once twice three times ten times as are very strong chance that we won't notice this effect we've only going to see this one time out of five hundred approximately like i said we didn't do the exact integral but this means that actually make race conditions to occur can be quite hard now we went for figures that said	['code', 'section', 'thread', 'code', 'section', 'thread', 'code', 'section', 'thread']
between us deciding the value of fireworks is zero and then calling peter condition wait so if it happened right inside there if that just that moment in time then what's going to happen we've actually called preconditions signal but no thread was yet sleeping no thread was yet blocked inside condition wait ok so was to fix for that and the answer is to actually log on the same mutex here so if i call pete said mutex lock here	['block', 'thread', 'block', 'thread', 'block', 'thread', 'block', 'thread', 'block', 'thread', 'block', 'thread']
busy checking this right so while while n is equal to the maximum number go round the loop now we know we could put a sleeping here if we wanted to we know that right now this is a terrible test because we're holding the lock if all of our code uses a lot no one else will be able to do this fortunately for us we're going to be using p thread condition wait	['the loop', 'code', 'thread', 'the loop', 'code', 'thread', 'the loop', 'code', 'thread', 'the loop', 'code', 'thread']
but at some point they need to come together and say send messages over data bus or some other kind of event structure so when they manipulate that structure only one of them should be changing at a time ok so that we've identified a critical section and now we need to make sure that if one thread is currently doing that then other threads get temporarily blocked put on pause if you like whilst we are in that critical piece of code and the key to doing that then is this	['block', 'code', 'section', 'thread', 'block', 'code', 'section', 'thread', 'block', 'code', 'section', 'thread']
but i can be sure that if all of my code follows this pattern so after this i call p thread mutex unlock right and then here's the address of my mutex i can be clear that that that only one thread at a time can be accessed in the data structure so that sounds like a big overhead and in theory it might be if that's the only thing you're doing but remember in practice in real programs ninety nine percent of the time your thread is working on something else it's only when it's actually got a result or once more data that would actually go to this shared data structure	['the data structure', 'a struct', 'code', 'thread', 'address', 'the data structure', 'a struct', 'code', 'thread', 'address']
but it gets worse than that because formally the value of this variable is not defined outside of this loop and in fact when we call pizza at exit we don't even need the stack anymore for maine so the memory that we might be reading at that point is no longer really hours to be looking at so we've got a pretty badly formed program here right so how can we fix it we need to address this race condition right will do it in two different ways first of all how about we turn this into a task that we give each one and my task right now is just know the little integer so let's have some memory for each thread so i'll call it say starting values and you can see i'm using a global here right and it will be let's see i'll have ten am ok and i can initialize these which i could do as part of this loop or i could do it earlier ok so you can be let's say hundred plus are you today just so we can prove that we're running this program ok and then i don't want to pass in the address if i instead i want to pass in my pointer to one of these integers i've just created so starting values and i could say take the ice warren i want the address of that but you know that we can also write that is just ok here's the start of the array i want the offset of i please and will use integer arithmetic ok so we've initialized array let's give this ago and off we go so will compile it ok	['memory', 'thread', 'address', 'pointer']
but my point is can be much larger they have a much larger space of numbers now address space now sixty four bits so in practice what's going to happen here we're going to truncate the value only going to take the lowest thirty two bits the bits that actually can be represented by the end oh dear so are we going to be lucky is it going to be the upper thirty two bits are all zero well maybe maybe in this specific example because we're testing it with a string literal and we know that's likely to be in a low part of memory but in general if this is say appointed to malloc it's unlikely to work once we start having values greater than what see about four gigabytes or so so so yes don't do this if you're going to avoid it it's not safe so that was fun but don't be surprised to see this kind of ugly code in old c code and hopefully now understand why it might work in some systems and might fail miserably in others by	['memory', 'code', 'string', 'address', 'system']
but we care about which is the p thread mutex lock here we go and you'll see it doesn't take that many parameters this was really easy we just take the address or mutex object ok so the definition here is if the mutex is already locked the calling third will block until the mutex becomes available ok so let's write this out as an example so i've got my pthread mutex lock here and i pass in the address of my little object here called lock right	['block', 'parameter', 'thread', 'address', 'block', 'parameter', 'thread', 'address']
but we never let it go so when the second thread starts and calls preferred mutex locked it's going to be waiting for a very long time an infinite amount of time it never gets that duck that duck has been stolen by the first red and never returned so as a result the second thread will never finish so as a result rp so join in maine will never complete so as a result will never put the counter ok i think we better fix that let's put in their pthread mutex unlock there you go after i finished in my surgery on the data structure i'm going to give the duck back at which point is this anybody else waiting for the duck they too can grab the duck and then carry on	['the data structure', 'a struct', 'thread', 'the data structure', 'a struct', 'thread', 'the data structure', 'a struct', 'thread']
but you won't actually find any characters there instead it's a pointer itself so it also is going to be four bytes or eight bytes holding a memory address and if we follow that that is where we will find the beginning of some string ok so this function is meant to append things but it has several errors so to fix it i'm actually going to take their code and will will edit it in place in a text editor ok so little bit larger alright so it's	['memory', 'code', 'string', 'address', 'pointer']
but you're saying hold on a moment this pointer you're starting with this user pointer it's avoid type that means that we're not declaring anything about what's actually at that memory location and if you read the c standard you're not allowed to do pointer arithmetic on that type because we don't know what's there would be absolutely correct however or modern compilers gcc clang and others do support this is the following extension which is you can add and subtract avoid pointers and if you do that then they behave like character pointers and in particular you are adding subtracting bytes off this memory location so we're walking back exactly the right number of bytes in this case because of this type ok so now i've got that now i can immediately say things like alright point p i know you're looking at my meta data entry so now let me declare that this entry is now free and then i would write my code to the block coalesce sing by checking my neighbors left and right to see if either of those are free and if so then i would assume they exist and if so i would collect them into one alright so that's one way of doing it but you and i also know about pointer arithmetic so here's a different way of doing it so	['the following', 'memory', 'block', 'type', 'code', 'pointer']
calling functions printf and all that kind of stuff independently because it has its own stack its own thread of execution so that thread has his own variable called message and there's another thread with a different stack with ok so different part of memory that takes a different argument an runs to a different sort of execution is going to end up in p thread exit so just kind of prove that these variables are living in different places let's actually print out the address of my local variable here so my message is at let's actually look at the address of	['memory', 'printf', 'thread', 'address']
compute string literal could be appointed to some string memory and it will call malloc get some heat can we add and create a string with the same character sequence but it is a different part of memory so that's a neat way of duplicating strings and then later when you finish with it of course it's on the heap so you can call three here right so let's back go back to our code here so i've got capacity excites the number of items are comedy in it and my data right so it's a pointer to a pointer to a character does that make sense well we know that it should be a pointer and yes each one of those entries of my way i expect to be able to store character pointers so that type is correct but hold on a moment what about this capacity ok so we've just ask for sixty four bytes the rest of the code assumes that capacity is related to the number of items which are actually stored there that's why we're doing this comparison here and why we use use the data as an array so this is not correct this should have said capacity times size of and then the thing that we're storing inside each entry so we're storing inside eat entry you might be tempted to write character but don't 'cause that's not correct and we know the thing we're actually storing is character pointers ok so right now we've got a better idea about size what do we do here right so i mentioned great we're going to double the capacity when we went out of space and then we call realloc is this a good use of real ac no this is a classic error here too we made two classic errors here first of all the real ac might be able to bust through a wall and just give us more space where the data is currently stored but maybe not	['memory', 'the heap', 'type', 'code', 'string', 'pointer']
critical section because i'm holding the lock lock so so we'll keep those pieces of code to a minimum and so this idea that you lock you did a tiny bit of work on a data structure and then you unlock it that is very common to see inside multithreaded code	['a struct', 'code', 'section', 'thread']
definitely working up ok so i implement increment the value of fireworks i print out oh and that value and then i decrement it ok so what's going to be the largest value this code will print one two three four five six what do you think so just as a reminder i've got five threads running this and the only way they can escape out of this code is after fireworks is no longer zero so what's the maximum possible value that we might see from this first to run this hundred or thousand to a million times what's the largest integer that would expect here ok so think about that pause this video and make your choice and then we'll see if you're correct ok so we think about this for five seconds and then we'll review the answers	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
doesn't have doesn't take just a simple integer for the integer or no instead you also pass in a pointer to your memory that you would like it to use so here's some memory and typically as well you impasse in how much many as well so we could pull up a terminal window to see the exact order of these things but what i want you to learn yeah there's quite a few of these kind of underscore are variations or variants of existing course and they were added later to posix	['memory', 'a terminal', 'pointer', 'memory', 'a terminal', 'pointer', 'memory', 'a terminal', 'pointer', 'memory', 'a terminal', 'pointer', 'memory', 'a terminal', 'pointer']
each disk block is four kb let's just work out how bigger disk we can actually use before we run out of addressable space here so what is two to the thirty two minutes at home ok so i can think of that as two to the ten times two to the ten times two to the ten times two to the two	['block', 'address', 'block', 'address']
element but i can simplify that to just the pointer arithmetic on the array name and that gives me the address ten of the element inside that worked so great and then for each thread i'm going to ask you to run little function called shout and he's going to pass to shout when it starts when it finally gets a cpu core to run we're going to pass in the following memory address so what is that well it's a global variable i just want to reinforce the idea that all these threads are running inside one process and they can see memory outside of their own stack space ok so here's that shout function we're going to pass in as something on the stack of the thread this pointer and we do something with that so for example i could print it out as a pointer so arg is now holding a memory address so let's print out that memory address or flush it and what exit	['the following', 'memory', 'thread', 'address', 'pointer']
entry so sometimes it takes a bit of getting used to the idea that i can just talk about a memory address and then immediately say ok now put these filters filters over eyes and don't think of it as just bits and bytes actually think of it as a piece of a data structure or actually think of it as an int or a double or something else see doesn't care the compiler doesn't care the cpu doesn't care up to a point more about that in a bid you can say at this particular address i want you to treat it as if this particular object or primitive value so great we're going to use those bytes as a metadata entry right so there's a few things we need to do here we need to set up those fields we've got a pointer and a size and a free so let's make sure that we do the easy ones first here right so we've going to make a note of how many bytes this entry represents remember that's the actual number of bytes the user can use and it's important for us as well to set the fact that this entry in our linked list is going to be unavailable it represents some memory there's actually been taken	['memory', 'a struct', 'address', 'pointer']
esperat returns negative one when cast it as a void pointer if it fails if it refused to give us any more memory case so in that case we should return null because that's part of the malloc specification wait just a reminder what does void pointer mean it means i'm a pointer but i'm not going to declare or i don't care i want to keep secret exactly what i'm going to store at that location and void pointers can be cast to other kinds of pointers implicitly so you don't need to explicitly say cast that to another type ok so yeah we don't care about what this pointer is just simply or what was going to be stored there just simply that if i want to compare it to get negative one i should cast out first void pointer ok right so now i'm before i'm returning i'm doing some logging here printf say hey great now you have some memory at that location so let's print out this variable as a pointer i'm not using percent s i'm not attempting to read any memory at that location i'm simply saying take this value and display it as a hexadecimal value	['memory', 'type', 'printf', 'pointer']
every time we call pisode create but what if you wanted to know your own idea what if you said what's my id how would how would i determine that so there should be a way to do this and there is so we say my id is p thread itself so that's the other way of getting a thread id if you want to know who you are something which represents a particular thread then you call peter itself right less for fun printed out which is not normal behaviour normally don't print out these i ds one way to do this we will just treat it as a pointer to some memory so let's say that this id represents some integer type thing which is some address type things or just print it out and now i've got a void pointer i can use percent p to say right treat this doesn't address ok so will pick that up and if we wanted we could play the same trick down here we put this out but	['memory', 'type', 'a thread', 'thread', 'address', 'pointer', 'memory', 'type', 'a thread', 'thread', 'address', 'pointer', 'memory', 'type', 'a thread', 'thread', 'address', 'pointer']
everything that we are sending is a subdirectory of the following in other words the canonical path should always start with the following characters that i've highlighted if there was a malicious user requesting resources for example they might request dot dot slash dot dot slash dot dot slash dot dot slash	['the following', 'resources', 'the following', 'resources']
finish before we exit made right so great let's get myself a philosopher will get the i th one will initialize its name will initialize it left hand and right hand fork to be one of my five mutex locks look i'm using modulo arithmetic so that the fifth philosopher wraps around and gets to zero for kids game right after setting that all up let's start off threats will call preferred create will make a note of the thread id and will ask it to actually run some multithreaded code which will look at in a moment i learned the rest of my main thread doesn't do much it sleeps with forty seconds then changes running and now just wait for those five threats to finish	['code', 'thread', 'code', 'thread', 'code', 'thread']
first of all my cake eater is called decrement but it's blocked but it's got blocked on p three condition wait and then after a few seconds we think we call implement a few times so you could see that we've called broadcast now we're going to wake up the document method so peter conditioned weight returns and is able to eat cake right so in fact we can follow this pattern for a few few times the producer makes more cake each time we increment we change the data structure but calling beats condition broadcast and then the decrement method is able to continue and you can see it's it's consuming cakes so this is great we've got basically like a cue based structural or the idea of a producer can 's beginnings of a producer in a consumer and the consumer can block until resources are available and we've implemented this with just a single test like is the value of cake 0 or not but now you could realize that you can write any application condition	['block', 'the data structure', 'a struct', 'resources']
first of all that's not how we're going to calculate the size of a string. a size of source here is going to look at the type. and what is the type of src for source? it's a pointer to something and so pointers to things are going to be four bytes or eight bytes, so however many bits are required to actually talk about our addressable memory. so on a 64 bit machine, i need 64 bits, i.e. eight bytes. so that's not going to be helpful it might work in very simple testing of trying to create small strings, but that's not how we get the size. and we also need to get some memory that is going to outlive the lifetime of my function. and of that, of course we're going to need some heap memory. ok, so let's have a go at that. the last thing i notice is that this looks a bit suspicious to me. are these the right way around? turns out they're not. how can we confirm that? answer: use the man pages. so, if i use the man pages of strcpy, i would discover that the destination goes on the left. ok, so with that in mind let's write our own version of strdup. ok so we'll skip that and go to [indistinct]. right, so we'll write mystrdup	['heap memory', 'memory', 'type', 'string', 'address', 'pointer']
for the fork on the right in other words they all get blocked so yes there is a chance that all my possibles will will deadlock because all waiting for resource it is never going to be released so oh dear this apparent code on the internet is not smart enough to solve this problem so yes ladies and gentlemen as a series two forty one	['block', 'code', 'block', 'code', 'block', 'code']
fortunately get line will then free up the old memory allocate some new memory force and it does this all automatically the only thing it needs from us is to remember from one call to the next where its buffer is so that's the purpose of these two variables this line pointer and this size pointer the first one is going to be useful to remember where it's storing the current line inside the heap the second one is how big is that buffer so so if potentially exceed that size we can get a new one right but why is it the case that both of these are pointers here's the trick get lines actually going to change our variables from one call to the next so we actually again to give it the address of our variables so let's do this actually write some code here so it'll get line demo here	['memory', 'the heap', 'code', 'address', 'pointer']
gets to modify this data structure anybody else that wants to insert something into my data structure or iterate over the linked list or get a value that just going to have to wait until i finished operating on my data structure ok so only one surgeon at a time is the mantra here and how we're going to do that well i'm going to introduce you to our first synchronization primitive in a moment and that is going to be called a mutex alright so i'll see you in the next video when we start talking about new taxes in particular p three music clocks rp thread mutex	['a struct', 'a mutex', 'thread', 'a struct', 'a mutex', 'thread']
give them this value as their parameter so eventually when our start routine actually start so we don't know when that might be it might be the milliseconds time or it might be practically instantaneous but at some point in the future they we know that the function takes a void pointer and so this is the value would like to pass in ok and the return value that is going to be the exit value from the function so if the thread never calls p thread exit its return value will be the threads exit value ok so let's go and actually kind of demos demonstrate this now right so i need a little bit of a program ok so here we go right here's my very first program this time we actually use the exit success rather than saying return zero you don't need to wait for me to type that ok so how can i now do things with with threats so i need of course the preferred library so let me include that hash include	['type', 'parameter', 'thread', 'pointer']
help for help in the background ok great so we know we're going to push in the values zero up to nine hundred and ninety nine nine have enough ninth ok right and so if we're just going to some these so we have the sum of values from zero up to that number there ok but in fact we're having two threads actually push all those values in so	['thread', 'background', 'thread', 'background', 'thread', 'background', 'thread', 'background']
here is the idea that we don't just say oh i've got a piece that mutex lock that actually is the very problem i'm trying to solve is that i've got a critical section and i want to make sure that if i have say two threads or two processes that only one of them at a time can actually be inside the critical section if two of them are inside the critical section same time then we've probably destroyed the integrity of the data structure that we've got we're trying to modify so the critical section problem became really important in the nineteen sixties when we were trying to figure out how to write good operating systems because with operating systems there's lots of things going on concurrently i've got lots of processes to an update things i've got bits of hardware interrupting me trying to get their data structures fixed so i need to work out very carefully how to implement a good critical section so today we're not going to ask people to going to arrive this	['the data structure', 'a struct', 'section', 'thread', 'system']
here we go right i've got different resources down here here's my resource of type a b and c ok so you might imagine for example these are pieces of hardware maybe it's exclusive access to the screen i want to go and put my computer into a kind of full screen mode so only i can actually kind of right to the screen or maybe it's a piece of hardware maybe i want exclusive access to the firmware or to storage device or maybe it's a database table and i now need to make sure that only i can access it	['type', 'resources', 'type', 'resources']
here's my little file here wouldn't it be cool if the contents of this file so here it is let's kind of sketch it out as some holodisc blocks if we could actually map those directly into some memory ok so let's kind of copy them in and then those pieces of memory can be directly part of the address space of a process and that's what nmap is going to allow us to do this idea that we can kind of make as one the address space of our process and things on the disk it allows us to do a bit more than that but let's kind of just start there ok alright so let's see what we can do with this so here's a map here is here is your high poly reference you know the most powerful ones that we're going to play with today that we say i want to map some memory and i want to map it to a file now we don't give a file name instead we just give a file descriptor so for example we have	['memory', 'block', 'a process', 'address']
hey i care about some specific signals if they're outside if they are pending then i'm going to eat them one at a time ok just tell me about one of them so in this case as you can see we are going to we're going to sell tell sick wait two kinds of signals that we care about sigint or sigterm for example and guess what that actually happens to be exactly how we set up the mask earlier so great let's use the same mask and then when this will block until the day that a signal is is delivered to sgwait just write regular code and now we can put things like printf and file code and other normal code inside here we don't have to worry about whether it's signal safe anymore so let's actually have a look at that code and you'll notice by the way that yet we we have this inside a little loop because after we've consumed one signal we want to go around again and seeing the next one ok so where is that here's my sig weight demo	['block', 'the mask', 'code', 'printf']
hi ok so a couple quick questions for you so i can thread access heap memory i think the answer right now you should know is yes they can so we're actually passing in some heap memory in our our previous code right so we said ok let's start or run method and you can see it's got the right signature to be given to p thread create<br> create and we passed in pointer there it is initialized a stack variable which is going to be individual to each thread unique to each thread but what are we passing in here remember we're passing in that memory that we malloc'd on the main thread so if we went back to	['heap memory', 'memory', 'code', 'thread', 'pointer']
hi ok so i got a little bit of a challenge for you here let's go back in time and say well how would you actually implement a valid mutex lock remember these things are critical to implement our critical sections where we can only have one thread manipulating data structure or some resources at the time ok so what do you think about the following attempt right so this suppose we were	['the following', 'a struct', 'section', 'thread', 'resources']
hi ok so initially we've just let's switch to that ok we have assumed that my whole process has been loaded into memory but there still may not be all possible addresses that map to physical ram we've seen this already when say you accidentally tried to read or write an invalid memory allocation for example page zero or maybe your programs malloc implementation there's a little bit crazy instead of trying to re divide into addresses which don't probably exist yet ok so when that happens what's happening is that we are going through our multi level page table system here and we get to an entry that says no i'm sorry i do not map to any one of my actual physical pieces of ram	['memory', 'memory allocation', 'address', 'system']
hi ok so let's have a look at how we can write some code which is non deterministic and then fix it up in different ways so here we go let's get started right i've got a little main method down here and i'm going to create ten threads and each time i go to store the address inside my little ray here of thread i ds and then i call pizza at exit so we know that at that point the main thread is done ok but the rest of the process lives on our ten little fence live on ok what do they do case so here's our game plan let's	['code', 'thread', 'address', 'code', 'thread', 'address', 'code', 'thread', 'address']
hi ok so let's jump to a different level let's jump back into the c library perhaps you wanna write some very portable code it doesn't require on requires to think about these low level posix interface is we just want to write code that works say in windows as well maybe you kind of other operating systems that support the c library and which is kind of everything so let's have a look at how we can kind of jump around	['code', 'system', 'code', 'system']
hi ok so let's make it a little bit more complicated now let's have a whole load of data structures ok so in this case i'm actually going to have eight different data structures here we go right and so for each one of these i'm going to use a condition variable to block when things are not ready and i'm going to need eight different locks now i probably could implement this code with just a single lock but then i might have unnecessary lock contention so lock contention is when one thread would like to continue but it can't because another thread is currently holding the lock and so of course that effects performance sometimes we actually need that behavior when another field is kind of into the same critical section but we could probably in this problem get by with a fewer number of locks sorry a few more locks in order to reduce lock contention so so in this case we have we've got eight condition variables and eight locks plus here's my data structure is actually is going to be of eight integers but i want you to imagine that this actually could be a lot more complicated ok right so i've got some initialization to initialize all my condition variables and locks as you can see all i'm doing is using the array name	['block', 'a struct', 'code', 'section', 'thread']
hi ok so let's talk about critical sections of functions which are not necessarily thread safe in terms of their implementation so here's a little example based on some real code where we want to be able to internally log errors so we don't want to display them to the console now we actually want to store them on some file so let's have a quick look to see how it works so when you call my log error function it takes an error number some integer and an optional message which eventually we're going to save to a file so you'll see down here we call f printf we're going to store it in this file handle when we've just got a string of the message and some error string as well and then finally let's flush that as well so it is actually definitely written out of the file ok now let's look at some of the other details first of all notice that	['code', 'printf', 'string', 'section', 'thread', 'code', 'printf', 'string', 'section', 'thread']
hi ok so we both through five different examples of where we sought deadlock or not no deadlock and fundamentally it was the request sequence that determines whether we actually ran into deadlock or not so what can we do to prevent deadlock and one algorithm that our system could use is something called the bankers algorithm so if the operating system knew in advance what resources particular process wanted so if we knew an example example for example the process one is going to need let's say eight aa whatever azar and say three bees whatever bees are but no season dies	['resources', 'system', 'resources', 'system']
hi so it's quite common to put aside a little bit of heat memory in order to define exactly what we want our thread to do so i want to give you an example of that and then talk about how would set it up right so here's the idea suppose i had an away and i want to be able to kind of process all the elements in my way and fortunately my task is embarrassingly parallel some part of it is meaning that i can easily just spit up my data and say ok thread you do this half and another thread ok you do that half so right now what if i got so i've got method then that i want or function that i want to speed up i want to make multithreaded here it is is my little calc method here and it's given a pointer to an integer ie the very first element of my array and the number of items we'd like to process ok so if we're going to speed things up let's just split this down the middle it doesn't make sense for one thread to say work on all the even indexed items and another fair to work and the odd indexed items that wouldn't be very great for cash there is much better to split it down the middle ok so will calculate the half of it and then game plan then is to create a thread or two to do this so for example we might do the following this call p thread create we're going to make a note of the thread id we don't pass we don't need pass any attributes today and then here's the actual image calculation method that we're going to use that we're going to use to actually do the calculation i just need to when i call that actually kind of passing some hints about what it should be doing so let's make a little task and put that on the heap so we'll have a little pointer here called say task one key which will represent what would like that thread to do ok so let's set this up right so what kind of information do i want to send to my image calculation well i probably would want to send the actual data so in this case this is just a pointer to the data so that can be data and then i need to decide or define how i want to specify the range that i wanted to work in there so i for example i could could specify the data always points to the beginning of the array and then provide a start and an end just like we did with the tiles before alternatively i could say that because it's just a simple contiguous array i could say that point going to pass into here is always the beginning of where i want my calculation to start i just need to say the number of items so let me put another squeeze in here another item in here so i've got the	['the following', 'memory', 'the heap', 'a thread', 'thread', 'pointer']
hi so it's quite common to put aside a little bit of heat memory in order to define exactly what we want our thread to do so i want to give you an example of that and then talk about how would set it up right so here's the idea suppose i had an away and i want to be able to kind of process all the elements in my way and fortunately my task is embarrassingly parallel some part of it is meaning that i can easily just spit up my data and say ok thread you do this half and another thread ok you do that half so right now what if i got so i've got method then that i want or function that i want to speed up i want to make multithreaded here it is is my little calc method here and it's given a pointer to an integer ie the very first element of my array and the number of items we'd like to process ok so if we're going to speed things up let's just split this down the middle it doesn't make sense for one thread to say work on all the even indexed items and another thread to work in the audience next items that wouldn't be very great for cash there is a much better to split it down the middle ok so will calculate the half of it and then game plan then is to create a thread or two to do this so for example we might do the following	['the following', 'memory', 'a thread', 'thread', 'pointer']
hi so let's look at complete solution of my implementation of get line first a couple things to point out is you know we can actually check to see if the point is we're being given a valid we expect all of these pointers to actually point to be non null so let's use assert to check that each of these values is a non zero ok so our next piece of code was to check to see if we don't actually have a valid piece of heap memory to use so i'm going to follow the pointers were given because remember our point is actually pointing back	['heap memory', 'memory', 'code', 'pointer']
hi so let's review some ideas from c code first of all what do you think the size of char is？ at this point you say oh now i know this ones easy the size of chart is defined to be one yes the character in c is actually a fundamental way of how we talk about addressable memory and so that's kind of the fundamental unit of one item that we can read or write so that is defined to be one in c code and have a look at their supposing one someone said the following i've got x what is x it's a pointer to in it and we've initialized it to hold the following value now we chose today to write that as a hexadecimal value but we could have also just used integer just a regular decimal integer as well and then someone says ok so what do you think the value of x plus one is at this point you need to say oh ok hold on a moment i know about pointer arithmetic	['the following', 'memory', 'code', 'address', 'pointer']
hi take a look at the following code we got quite a few things going on first of all we're actually using fork and remember what fork does focuses hey take this current process and duplicated for kits and now that you've got the original parent process and a child process and these two processes look very similar to one another they have the same variable setup they have they have some stack memory they have heap memory they have all of the program code but there is one little difference one easy way to tell whether you are in the parent on the child and the answer to that is what is your value of fork return	['the following', 'heap memory', 'memory', 'code']
hi welcome to lecture 38, so let's get started right today we're going to do some review ideas and also go into some operating system ideas as well. so let's start with going all the way back to threads and ask why is the following code threadsafe ok so let's have a look at it what's it doing. right so i've got a function. it takes a pointer to some memory, sleeps for second and then it assumes that there's a string of that memory. so will cast that	['the following', 'memory', 'code', 'string', 'thread', 'system', 'pointer']
hi welcome to lecture eight we're going to spend it mostly fletcher talking about memory allocation but before we do that let's have a look at little puzzle ok so first question for you why is it that we put the heaps so far away from this stack why is it that we organize our memory this way so to try to answer this and let's think about how these structures can grow in time both the heap and the stack can dynamic dynamic in the sense that they can get significantly larger so heat gets larger when we call malloc for example and stack gets larger when we recurse so every time we make another function call i'm going to need to extend my my stack space so for for architectures that only have a limited address space so particularly true on say sixteen bit and thirty two bit architectures let's put these two structures as far away as possible so that the likelihood of them colliding is small	['memory', 'memory allocation', 'the heap', 'address']
hi welcome to lecture fourteen so let's dive in and have a look at some threads unlocked are you ready ok so let's get started right so take a look at this crazy code here and this work out what's going to happen on a sixty four bit machine and thirty two bit machine so your first comment is how could this possibly compile hello is not an int ok so what do we have here well of course we have a string literal so this is going to behave as an array but can also decay into just a pointer point being the memory address of this first entry the age ok so that memory address could be treated as an int right which we then store into this variable and then later we say ok take that in value and pass it so and change its type backed into a character pointer	['memory', 'type', 'code', 'string', 'thread', 'address', 'pointer']
hi welcome to lecture seven so we're going to look at how to build a shell how to play with signals and how to review some system code so let's start with that here's our first little problem here's some c code and we wanted to see if we can spot any errors in this so let's go through this and see what we see if we can understand how it works what is trying to do and how we might improve it so what do we see ok i get my little pen going right so right i have a our method here main method and i'm checking to see if oxy is not equal to two in other words this little program that expects its own name and some command file to run ok let's find out what that means in a moment and so the usage here is not correct what we wanted was the first string arguments so i could have written argv of zero there	['a shell', 'code', 'string', 'system']
hi welcome to lecture twenty one so let's get started with a bit of a code review suppose you were given the following code asked to review it, ok what do we think of the following so how can we improve it and what's its purpose so it's called acquire and for gravity to fit onto this slide i've said pmt for p thread mutex if this truly was in the code i might say why we doing why do we have this typedef let's just stick with the regular types but anyway so we get two pointers too	['the following', 'type', 'code', 'thread', 'pointer']
hi welcome to lecture twenty so let's have a code review where we're going to talk about a little bit of code that uses condition variables are you ready ok so my little application is very simple it's just got two threads one thread some point is going to modify this value of x and then call signal another thread is waiting for x d b positive so we can think of this basically like a latch and only after it's become positive do we continue right so what do we think about this code	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
hi welcome to let your nine so we're going to start looking at how to build a memory allocator in other words we want to implement malloc and calloc and realloc so let's get started and think how we're going to do that right so here's the game plan we're going to need a data structure to keep track of the pieces of memory that we've currently allocated plus later when they are freed we want to keep track of those for items so that we can provide them for future allocations so the bedrock of our implementation is going to be this little memory structure in here so let's take a look at this right so what are we got well today we're talking about a struct which is a way for us to put a whole lot of information together in this case we're going to have a pointer for the users area of this particular application how large it is and whether this particular entry represents some memory that is currently in use another words malloc has been called in the users using it or is available for future allocations in other words free has been called on this block of memory and we should consider it for future allocations right now a couple of quick point about this is that i don't have to keep writing struct metadata entry each time every time i want to talk about this piece of this piece of this structure i have to when i'm talking about a link list so here is my linked list so that i can chain these together but for other times i don't want to have to keep writing the word stripe let's be lazy and for that we're going to use the c word called typedef typedef you can think of is just an	['memory', 'block', 'type', 'a struct', 'pointer']
hi. so, ok, we've talked about a scanf() which would read from default from the standard input but guess what we can do a lot more using the same ideas so we call it the scanf family just like printf has a family we can say instead you know what i don't want to just read from standard in i want to specify which file to read from which filestream so this f scanner for that or you might say actually guess what i've got some bytes in memory that i did as a c string and i want to pass the output from that so in which case i can use snf and all i need to do is pass in the address of my c string right so	['memory', 'printf', 'string', 'address']
how can we analyze this right so i've got a pizza it create an i'm storing somewhere the fed id 's and i'm going to say ok i want to thread that is going to start functioning and let's start function be and we're going to pass a void pointer the address of the string literals so the address of the capital a and address of the cadillacs to each one right so what will function be do function be then get this pointer and so we're giving it the address of xyz so when this runs and we're not quite sure when it will run it will print out xyz	['string', 'thread', 'address', 'pointer', 'string', 'thread', 'address', 'pointer', 'string', 'thread', 'address', 'pointer']
how can we analyze this right so i've got a pizza it create an i'm storing somewhere the fed id 's and i'm going to say ok i want to thread that is going to start functioning and let's start function be and we're going to pass a void pointer the address of the string literals so the address of the capital a and address of the capital x to each one right so what will function be do function be then get this pointer and so we're giving it the address of xyz so when this runs and we're not quite sure when it will run it will print out xyz	['string', 'thread', 'address', 'pointer']
how can we analyze this right so i've got a pizza it create and i'm storing somewhere the thread ids and i'm going to say ok i want a thread that is going to start function a and let's start function be and we're going to pass a void pointer the address of the string literals so the address of the capital a and address of the capital x to each one right so what will function b do function b then get this pointer and so we're giving it the address of xyz so when this runs and we're not quite sure when it will run it will print out xyz	['a thread', 'string', 'thread', 'address', 'pointer']
how large can of rb before triple indirect blocks are required ok so to answer this one it means we're going to use the ten direct blocks so that's going to be forty kilobytes then we have the indirect block so my indirect block itself is four kb but we're using thirty two bit addressing so that means each one of those entries here is going to be a number which takes four bytes for my thirty two bits ok so for my four kb block here that means i can have	['block', 'address', 'block', 'address']
how much memory on the heap do i need the size of my my little type here and a reminder that yes these are variables and they represent some memory sure but the actual objects themselves you can think of them like file handles that they actually exist as part of the part of the kernel so that's why i need to call p thread mutex initiate please create an object for me based on store a reference to that inside this memory structure so i've got my two locks now let's see what happens right so as part of the read i'm going to call read lock ok so i'm just going to call p thread mutex lock and then afterwards petered mutex unlock key and then the right i first of all i'm going to get the right lock then i'm going to get the read lock and i'm going to do some writing so what do we think about this is mutex locks sufficient to implement this right so take a moment to think about that and then i'll tell you in my point of view	['memory', 'the heap', 'type', 'thread']
hundred seconds but you get the idea right so that's all stepping stone to using a condition variable we do need a loop i'll tell you one big reason why in a moment and what do we need to do we replaced the sleep where their pee thread condition weights and here's a condition variable we're going to ask a threat to sleep in and we also going to release a mutex so it's we discovered it is always necessary to use a mutex because we're going to write code in here where we want to test some condition and then later use that the assumption that condition is now true so we need a mutex lock to ensure that we are the only person get there can be modified data structure so we end up biting p thread mutex lock cave right so there's the log and then later we unlock it	['a struct', 'code', 'a mutex', 'thread']
i just want to print print out everything and for that i'm going to use right today remember how it works is you simply say here's a memory address start sending the following bytes and as we're sending this to a terminal we're going to see that as ascii values so i've just got a very simple a piece of code here that goes through this prints out a width number of bytes and a little bit of calculation here to workout where in that heap i should start from at the end of that do a new lines have gone to the next one and then i need some control characters so this oh thirty three is actually the value twenty seven	['the following', 'memory', 'a terminal', 'code', 'address']
i might have a thread that say forgets to call sam post or for some other forget or some bug causes some event not to occur and then you get all of this fall out where other threads and other processes are unable to continue because they are also waiting for that for that thread or the other process so you'll see this occasionally on your phone or on your laptop where one little issue say with their gui process or gui thread now starts to have cascading problems and your deadlock starts to affect other systems as well because everything else grinds to a halt and there's multiple dependencies between all of our threads and processes ok so that's deadlock what what we'd like to be able to do is ensure	['a thread', 'thread', 'system', 'a thread', 'thread', 'system', 'a thread', 'thread', 'system', 'a thread', 'thread', 'system', 'a thread', 'thread', 'system', 'a thread', 'thread', 'system']
i wanted to first of all create a a process where i've got a global variable little m here and we're going to initialize it by asking it to hold the memory address of this string literal in other words it's going to hold the address of where to find that that w there ok what do we do inside a little program here we have a little bit available could a we called fork and the return type of focus this process process id type	['memory', 'type', 'a process', 'string', 'address']
i'm going to sum up the integers and if you know i'm sure you've seen this inside once every three right or you can do it recursively you can do this inductively or you can do it with lego as well you know that the sum is equal to n times n plus one over two right so in other words we expect a total of that right by the way i said you could do it with lego blocks here's the reasoning with lego blocks if you still some lego blocks from your younger sibling	['block', 'block', 'block', 'block']
if anything else we need to do yeah well we're writing a method which both to push and pop can can block so if i just put something onto this onto my way it could be that there's another thread waiting to pop things from the data structure so after i've modified it i'm going to call p threat condition broadcast	['block', 'the data structure', 'a struct', 'thread', 'block', 'the data structure', 'a struct', 'thread', 'block', 'the data structure', 'a struct', 'thread', 'block', 'the data structure', 'a struct', 'thread']
if that ever had occured what would what would you expect it to see where maybe that piece of memory that we were overwriting is being used for a different variable and so we might have seen a subtle error later on in our code because we change different variable or worse perhaps we changed a pointer in memory of the return address for something so now our code crashes or does something unexpected and exciting	['memory', 'code', 'address', 'pointer']
if the threads have gone to sleep inside p thread condition wait there only allowed to escape out of that after they reacquired the mutex log so that's the key idea that only one third of the time can be running this piece of code and it allows us to actually reason about this so we know that when we escape out of here the very first thread will see of fireworks value of one because we changed it upstairs in the main method so we implement so we increment it to two case of wig the first escapes out of here will	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
if we also had onto the mutex lock earlier if our musics lock had been one of the first things we've done then yes we would have encountered deadlock because the d q could not have continued it would have waited for that that mutex lock that would have never been never been released definition of deadlock waiting for an event that never happens so we didn't find deadlock just there there we came awfully close right what else can we find out about this code then ok so let's see the same post happens early ok that we're actually increasing increasing the count of the number of items in our buffer before we even changed the buffer values ok so we're basically going to add one discounted here so if somebody was waiting to extract value in other words if a thread had already called d cube but was waiting here because the count of s two was zero we're going to release them from that early oh yeah so this land sounds like a recipe for	['code', 'a thread', 'thread', 'code', 'a thread', 'thread']
in order to make it more thread safe now the last thing you might have been thinking about when i was talking about this is hold on a moment what about earner what is this other thing and wins it set ok so oh no is set by most system calls that can fail so for example read or write set errno to tell you what went wrong so if you call right and it doesn't work	['thread', 'system', 'thread', 'system', 'thread', 'system', 'thread', 'system']
in practice of course bulletproof code robust production code would actually check the return values of all of your system calls and that is kind of really good system programming practice to kind of detect when errors go wrong and actually becomes critical when you start writing network code c in the next video bye	['code', 'system', 'code', 'system', 'code', 'system', 'code', 'system']
inefficient and quite timely it takes a long period of time if i want to scan through all of my files to see which ones have changed which ones have been created it would be great if my file system could actually tell me which files have been created or modified since the last backup so we need some features to support that how are we going to do that right i kind of want to mention that one fun thing about all these features is that they are not required of course with all applications but they also are difficult to implement together for example compression may or may not hurt performance deduplication requires ability to scan files and may take additional cpu time additional memory and so may actually actually affect negatively the performance of your whole system	['memory', 'system', 'memory', 'system']
inside here so we won't let anybody go until we've actually created or five threads and also kind of starting up so but this line of actually changing the fireworks to one here could still actually technically occur before this five threads of actually started all we've just simply say is to say ok create them and at some point in the future please run alright so lots of interesting interleavings details there and as you can see this stuff is tricky	['thread', 'thread', 'thread', 'thread', 'thread', 'thread']
is actually ok it was compiled with optical useful what we wanted is a variable here let's just call it line which is going to hold the address of the heap memory and rather than just passing into it that whatever value happened to be inside that variable we actually wanted to know the address of that variable so that's one mistake second mistake is that both these variables should be set to zero so we fix that so will store that	['heap memory', 'memory', 'the heap', 'address']
is doing something else so this thing runs for one second and then it's some random type there's one second ok some random sign inside that just for one day second it goes and visits a critical section may be updates or reads a particular data structure ok so now that's fine but now we have two threads so here's another fit that also is going to run for the same second	['type', 'a struct', 'section', 'thread', 'type', 'a struct', 'section', 'thread', 'type', 'a struct', 'section', 'thread']
is first some io event to complete right so some input output for example perhaps you've called open perhaps you've called read perhaps you've called write and we need to talk to an external device for in order to get the data or put the data sometimes these these calls can complete to immediately if we already have the data inside ram but at other times we have to wait for the data to physically arrive ok so once that data is ready there in that system call can return an example of this might be you have written a ui program complete with windows and menu drop downs and all that good stuff processing those window events is just another piece of kind of io now we're waiting for events to occur from user input and so fundamentally there is some kind of read call going on to find out what the user wants us to do and most of the time it cost the user isn't giving his events but occasionally the user going to type a key press the screen that kind of thing and then our culture we can return it and our code can continue ok what else might we finish waiting for think about something that we've seen and you used inside this course well ok how about our synchronization primitives so some synchronization event has happened that we allows us to continue so what do we got we've got things like mutex locks you are able to acquire the lock we've got counting semaphores somebody's returned that piece of pizza into the counting semaphore so now we get to pull it out and continue and of course we've seen condition variables so now say broadcasters occured and now my thread is made continue we've also got other things like barriers so for example finally all the feds have turned up so now i'm going to wait this thread and let it continue	['type', 'code', 'thread', 'system']
is one solution to the critical section but like i said it's not a generally useful solution to the critical section we need to find a way to be able to kind of implement these correctly and will talk about some algorithmic concerns about that in the future instead now is what i've got a real challenge for you which is i want to implement a barrier in fact i'm going to give you all the code that you need here it is i just want to implement a barrier that will wait until five threads call this method called this function and i've got to keep track of how many there we go and all i'm going to give you is the following code which uses a counting semaphore so you get to choose how what you would like to implement what you'd like to to initialize is counting semaphore with and all you have to do is rearrange these lines enter the correct order so that's my challenge to you pause this video and see if you can work it out i'll give you the solution next video but before you do that make some brain new brain cell connections and actually think about how you're going to rearrange this code so it actually works by	['the following', 'code', 'section', 'thread']
is one solution to the critical section but like i said it's not a generally useful solution to the critical section we need to find a way to be able to kind of implement these correctly and will talk about some algorithmic concerns about that in the future instead now is what i've got a real challenge for you which is i want to implement a barrier in fact i'm going to give you all the code that you need here it is i just want to implement a barrier that will wait until five threads call this method called this function and i've got to keep track of how many there we go and all i'm going to give you is the following code which uses a counting semaphore so you get to choose how what you would like to implement what you'd like to to initialize is counting semaphore with and all you have to do is rearrange these lines enter the correct order so that's my challenge to you pause this video and see if you can work it out i'll give you the solution next video but before you do that make some brain new brain cell connections and actually think about how you're going to rearrange this code to the actually works by	['the following', 'code', 'section', 'thread', 'the following', 'code', 'section', 'thread', 'the following', 'code', 'section', 'thread', 'the following', 'code', 'section', 'thread', 'the following', 'code', 'section', 'thread']
it just returns an error numbers returns a non zero value so the very first time that we running this code with twice left equal to two if we caught acquire that second log we just say we failed so what do we do if we failed we immediately unlock the left hand thread	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
it looks like no ones needed for the longest possible time or less choose a page of ram that actually we know we already have a copy of that on the disk for example perhaps it corresponds to some of the code of a program and we already have that program stored on the disk somewhere right so that's kind of demand paging and in the next video let's address the following little brain teaser let's suppose you actually did a benchmark on catalog versus malloc ann you were surprised to discover that these two calls take the same amount of time how could that possibly be because kellogg is defined to return memory that has been	['the following', 'a page', 'memory', 'code', 'address']
it would be an error just to return the actual pointer to our metadata 'cause then the code that is called us would overwrite our struct instead inside our struct we've got a pointer so let's use that let's return the value of pointers that will tell the caller exactly which piece of heap memory they can use so that's all of accounting that we're going to need for first part of malloc alright so let's go back to this line of code here and let's talk about what it's doing so we're saying let's look at the current size each time around this loop of this entry and see if it's less than	['heap memory', 'memory', 'code', 'pointer']
it's got a reference count of three but if i was to remove it so let's remove what i call it like another dot c o k that my reference count has gone down to two so we still need it so that's why we need reference counting just keep track of the number of entries that it appears so you might see how when we do forensic analysis on disks we can look for i knowed entries which have been deleted but which still don't appear inside anyways like my file system but we still might contain all of the meta information so for example it might be i did deleted i knowed entry can still point to the disk blocks that	['block', 'system', 'block', 'system']
it's not yet available another thread is currently quite that musics lock ok so when will we escape out of this and the answer is never ok we can read the code and see that eventually we're going to release these locks but we're never going to get to that that piece of code that thread one is waiting for thread two and thread two is waiting for thread one so it's kind of stuck for stuck forever	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
it's outside our castle but unable to cross the moat because we have blocked it on all of our process or all of the threads so if you wish you can check for a signal to see if it's pending like literally calling sick pending and that will fill in one of these signal sets for you so now great you can actually see if there's a say a sigint that is hasn't been processed someone press control c awhile ago and maybe you want to print out a useful message so that's what this little program does here let's check the actual see which bits are set inside my signal set here so once i grab that i can say ok is the following signal a member of this so will take the address of my pending result an see if cig and has been set inside there and if it is we will print a friendly message back to the user to say hey thanks for pressing ctrl c but is no cookies for you today right so let's	['the following', 'block', 'thread', 'address']
join an i want to join on not the address of thread id but the actual value itself and i don't care about the exit value so don't write that anywhere ok alright so what's going to happen now first of all let me run it and then you can tell me why ok so let's clear this clear that's compiled let's run ok and this time i'm extremely confident we're going to see the same same output for the integers and they will be in order why am i so confident	['thread', 'address', 'thread', 'address', 'thread', 'address']
k so we turned my v where does become from i'm going to have something like double v equals so i go to my way now i want to pre decrement my value of n there we go alright so what about the blocking all right so we need something like look if my value of n is zero then go to sleep ok right so i'm going to have my p thread conditioned wait ok did you do today and here is my condition variable i'd like to sleep in and don't forget that mutex lock ok what is the mutex lock code look like are right so we've seen this before that's just	['block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread']
lego block proved there right so let's let's actually have a go at running this ok so do we have code right so we called it block and let's let's run this thing ok you'll notice that we only exit after we managed to join all three threats so will compile it stop the cake monster stop consuming cake	['block', 'code', 'block', 'code', 'block', 'code', 'block', 'code']
let's make sure that our all of our threads or processes always require resources in the same order so will have a meeting with all of our programmers and say look here's the things which you are saying a quiet calling peter mutex lock on abc and d we just need you to always acquire them in agreed apon order so for	['thread', 'resources', 'thread', 'resources']
let's open this in something which little bit more viewable ok make it larger ok let's let's instead right will use arc preprocessor trick so if hash of zero don't compile this ok and instead let's use pointer arithmetic our case so while let's go and see what argv is looking at and if it's gone zero or pointed out so printf there's printed out as a string and we want that value and just at the end of the loop let's take argv and we need to move it forward once they stop looking at the old memory location move to the next one ok right so let's looks good i want a new line ok compile this again	['the loop', 'memory', 'printf', 'string', 'pointer']
let's see all chill at the moment ok so we're going to get out of there were going to take this check this after you run through this code once i know notice it is frayed i apologize the logic as given incorrect let's have a look see what it does first of all philosopher waist to pick up the fork on the left ok so that's only going to proceed once you get exclusive access to that particular fork alright and then it's going to change this local variable failed to based on on what happens when it tries to pick up the the fork on the right so notice that initial value of tries left is too so actually it's going to call this function called trilok which we haven't seen before trilok never blocks instead rather than blocking if it's unable to acquire this mutex	['block', 'code', 'block', 'code', 'block', 'code', 'block', 'code']
let's see do malloc and then in the case of mark use store copy but instead let me show you another alternative which is let's let's deliberately set the very first bite of that heat memory to zero so in other words right how do i do that i need to dereference twice my variable to finally get to that very first character of my heap so let me set that to zero and i can do that by typing the integer zero or i can type the ascii nul byte right so this is the ascii nul byte which is not the same is writing know with two l's anytime you see 2 l tells you know you're actually talking about a pointer value ok so now we do that when we get down to strcat, strcat is immediately going to find that nul byte and say ah-ha that's where i should start from the last thing i notice is that returns a type of void pointer avoid pointer isn't is not scary it just means i want to point to some memory but i'm not going to tell you what is there i just actually really only care about the address the actual piece of memory that i want to read or write to later right now i'm not going to declare a type ok so let's return something there and will return say this is the piece of heap memory that may be allocated or the memory that you gave us that is there so the code is written assumes that if we are given	['heap memory', 'memory', 'type', 'code', 'address', 'pointer']
life would be fine if they did this carefully synchronized but instead you could imagine that are two threads go over and read the same value and then they add one at about the same time and then they write back their new values so instead of increasing the value by two we've only increased it by one you can imagine more extreme variations where one thread is running a bit slow perhaps my cpu keeps on being interrupted because it's being asked to transcode some videos as as i as i'm talking to you and so now the other thread is able to run forward a bit so imagine the following one thread reaches in grabs the number	['the following', 'code', 'thread', 'the following', 'code', 'thread']
like that is no longer a legal program because now we're returning a pointer to some array that's on the stack and that is not valid memory to use after we return so it might appear to work but there's no guarantee that that memory is going to remain good after we returned from two text motor two text message so next time i try to say ok let's try static here well ok so now what you've done you've just made a global variable again but this time it's yes it exists for the lifetime of the process but now the scope of it the ability to refer to this particular variable is now just limited to any code that you write inside this particular function right sort of static is said ok this is not going to live on the stack so if we do that it's still going to break we're still going to see dinosaurs winning money so i'll just prove that so after two seconds oh we see that we are corrupting our message so yes both threads now using the same piece of memory ok so none of those work	['memory', 'code', 'thread', 'pointer']
loop excuse me will be when there's no one left actually using the data structure for either reading all writing ok otherwise my new thread goes into this p threat condition wait ok so knew writers yes they're going to get priority as students we have arrived on the scene the reed has to wait but only only one of them is going to be able to continue to see why remember that each time a thread is working up outside condition wait remember is holding the mutex locks only one thread is running and so the very first writer that that has evaluation of false here gets to continue so what do they do they update writing from zero to one so now when they unlock and then proceed to change the data structure if another writer evaluates this condition so imagine we work them up in three p three condition wait or they've just arrived they will see an expression here that is true and so they will go into p three condition wait so that we can be sure that this condition must be false in order for us to continue ok so eventually that right oh will finish changing the data structure and then we get down here again so we wait to acquire the mutex lock hopefully as a very just a few nanoseconds maybe a microsecond and then we can say great we're out of here right so let's decrement the number of threads writing let's talk about the number of writers and then exit but before we exit maybe it's time to wake some people up ok so the most loud code would be to call peter condition broadcast on both the both condition variables so notice i've got a condition variable here for writers so we're going to send all the writers to some coffee shop and	['the data structure', 'a struct', 'code', 'a thread', 'thread']
make this thread exit it's never going to happen ok so our poor poor little fair door process is waiting some for an event maybe we're going to signal that event using a variable or some other method and it's just never going to happen so it doesn't get to complete it doesn't get to kind of run its activity or run the code and of course debugging deadlock is tricky it's often there as pairs that i could a thread maybe it's stuck inside p threat condition wait and we don't know why why that event doesn't hasn't hasn't fired hasn't occured	['code', 'a thread', 'thread', 'code', 'a thread', 'thread', 'code', 'a thread', 'thread', 'code', 'a thread', 'thread', 'code', 'a thread', 'thread', 'code', 'a thread', 'thread']
maybe we want to turn the backup simply remember things like assert as well is a kind of good chance to check that beliefs about the code and how it operates are correct ok the other thing that we could do is improve the way that we just we just ignore any freed memory so perhaps we need some kind of data structure to keep track of memory that was allocated and then freed because now we've got blocks of memory which we could reuse in the future right so for that how should we store that well one approach is to have some kind of linked list of	['memory', 'block', 'a struct', 'code']
memory there's a string that says a equals b so key value pair and we could pass that and if we wanted to implement getenv except of course there's more than one environment variable there's another one so just like argv argc there's a whole load of them and the last point are here is null so that's the way to find out all the variables now big important point here is that if you declare this environment variable it's important to tell the compiler the following is important to the environment the compiler that this environment environment variable is extern is it meanings external to the currency program that you're writing if you don't do this the compiler will say oh look at your list compiled you're declaring your own global variable i'll set aside a bit of space inside your process memory low down for your nice little variable that's not what we want we actually want to say or compiler i promise you that when you link on my program together when you pull in the selye be when you put in the other libraries when you pull in the code that i write in this c file and that other compilation unit is other c file then eventually when you put all that together there already is variable call&nbsp; environ so that's what extend us you're declaring this external to the compilation unit external to the current program	['the following', 'memory', 'code', 'string']
my i've got two threads two cpus actually trying to read a right to the same piece piece of memory what if that value was cached or the good news actually is depleted mutex lock takes care of that as well for us that if this cpu supports some caching mechanisms peter mutex lock will ensure that that values are flushed out to main memory if any other cpu wants to read these	['memory', 'thread', 'memory', 'thread', 'memory', 'thread']
my little threads going to do here so for forty seconds until that global variable is changed the first thing that my my philosophy does is sleep in other words thanks a bit so will print out his name then will sleep for and amount of time so in this case let's sleep for say some two one and eight seconds alright and then the philosopher goes to pick up the two folks	['thread', 'thread', 'thread', 'thread']
notice that in both these cases i careful to check the error values ok so this will be a non negative value if it is a valid file descriptor if it returns negative one then we know that my attempt to create a socket failed perhaps i don't have privileges perhaps i've created too many sockets at anyways so let's print out the string of every number and quit exit so network code has to check very carefully whether each system for work but once you've gotta suck it now you can call connect so again let's check to see if this failed if it returned negative one let's find out our value of erno and print out a useful message and quit	['code', 'string', 'system', 'code', 'string', 'system']
now here's a useful little command get cwd noticed that's right it tells us the process is current working directory which is going to be useful if we want to work with relative directories and in fact paths in your system of defined to have a maximum length so you can be confident that the string that you can request can never be larger than this constant here path max and we add one just to ensure that there's enough space for the c string zero bite at the end ok so if you want to know how where you currently on file system here is one way to do it right	['string', 'system', 'string', 'system']
now let's actually look look at the code that i want to be need to be thread safe i'm going to have two methods here i've got a very simple modify method this is going to allow me to externally add some resources to a particular data structure so you can see all i'm doing is just modify one of the entries inside that away ok and then i've got this other function which actually i'm going to run multiple times with multiple threads so i'm going to have in fact seven threads running	['a struct', 'code', 'thread', 'resources']
now what about function a so functionally when it runs let's see is given the address of abc ok but it doesn't do anything instead it just simply exits this thread and it returns an address so it takes the pointer that we gave it which was a pointer to the string in memory abc and a zero bite if it is	['memory', 'string', 'thread', 'address', 'pointer', 'memory', 'string', 'thread', 'address', 'pointer', 'memory', 'string', 'thread', 'address', 'pointer', 'memory', 'string', 'thread', 'address', 'pointer', 'memory', 'string', 'thread', 'address', 'pointer']
number of bytes tiny i should be copying is going to be yes to new size and of the old size ok at this point we run into a snag i don't have the old size how are we going to get that right so somehow i need a way to get my linked list entry for that given so somehow i need to go from the old tube the linked list now i've shown you one way to do this before with three where we just walk through the linked list looking for their entry until we found one with until the pointer of the linked list the point of entry of that linked list data actually was equal to the user area but maybe we've actually made a decision to have a better performing malloc and free so that the metadata entry can be found in order one way maybe we've said that the metadata is directly before the user area ok so how would we write this code so for that here's what we'll do is let's play with pointer arithmetic let's have a look at that old pointer but first we're going to cast it to an entry type k so if we've got that there were not looking at the right spot yet but we know just before that we stored our metadata entries so great we found now the real data entry now are we sure about that well let's put in a few asserts ok so let's double check for example the pointer really is looking at what we expect let's check for example that the windows correspond to some memory that is has been taken its current year allocated right so now we've got that entry i can look at the old size so let's pull it out the old sizes entry	['memory', 'type', 'code', 'pointer']
of exact which will use the path because we're going to look for this command called curl somewhere on that set of directories ok so assuming we find it we're going to start this new process and pass in this as these as its argument ok so we can now talk about how cold works so the first we want to say is ok we're going to call exact so we're going to load in the bites of cult into memory remember we have a head transplant at this moment goodbye the shell whatever was going on side that side that process because now we're going to be calling the main function for curl and we're going to pass in the arguments ok so when it starts up kerbal purse passwords given to it and it's v r x y and you will see the string so now we can start talking about finally about some of the network stuff how we have to first of all identify a domain name so it's illinois dot edu so we're going to try to connect to that how does that work ok great now you have an opportunity to talk about dns we're going to turn that into some ip addresses by doing dns what is dns development done name name system how does that work ok so now you can talk about the fact that maybe you've got an entry locally inside your e t c hosts file	['memory', 'string', 'address', 'system']
oh dear it will return negative one but you want to find out more about what went wrong so that information is encoded inside this global variable but wait a moment if i've got a multithreaded program surely it's going to be really hard to figure out which particular thread on which system call caused evernote change	['code', 'thread', 'system', 'code', 'thread', 'system', 'code', 'thread', 'system', 'code', 'thread', 'system']
oh i forgot to say one little thing about erino down here which is when is it set ok so here's a big idea is that it set to zero when your first program first starts up its value is changed whenever there's an error with a system called and we read the man pages to learn more about that but it's never reset back to zero so if i had a whole lot of calls let's say that i try to read from warm particular file descriptor and then try to write those bites somewhere else to another file descriptor fd two over here if i then check if evan oh zero or not then i can't actually tell you whether where the error curd maybe it happened early on inside my read maybe it happened inside my right or maybe it happened even earlier so just think of is a global variable that if an error occurs we change it	['a system call', 'system', 'a system call', 'system', 'a system call', 'system', 'a system call', 'system']
oh i must have right to thirty seven bytes but that's not enough so let's keep account of the true number of bites that we've actually sent so far and then go round the loop to try to send the remainder obviously we don't start from the beginning we want to start from whatever offset that we've counted up so far or maybe we've now got to the point where total bytes sent is everything which case we can finish and return say yeah we sent all the bytes ok we're done we're done with this return so we've actually got to write code that copes correctly with all four of these situations	['the loop', 'code', 'the loop', 'code']
oh idea so we've been oversimplifying things at this point we haven't been writing high quality code instead what we need to do is we need to check the return value of some weight and read and write and even sleep if we actually want to write production worthy code because some weight might be say oh i failed and it might fail simply because it got into up to do to a signal so we can check this and then we can just re run it again so typically you'll see the following kind of code that	['the following', 'code', 'the following', 'code']
ok alright so it looks like it's kind of working but not as well as we hoped we certainly got different thread ideas appearing and they do look like addresses i'll give you that but look at this we've got very strange values over here and even the last value is ten and if i run it again i get different values again if i run it again i get different values again ok so i get in all sorts of values here what is going on clearly we've got a program which is not deterministic we don't know what it's going to print out ok so why did that happen well hopefully you can see that we passed in the address of i and so actually what we have here is called a race condition it depends upon the exact interleaving in time of the instructions that are going to be executed i've got one thread that immediately after calling pizza it could create is going to increment the value by and then test to see if i is less than ten i have not go around again so we've got one threat doing that as fast as fast as i can and i got another thread that as soon as it starts will gas that pointer to an end pointer and then try to read it so it's a value that it sees depends upon the relative timing of these operations and that can change from one run to the next you might be surprised we even saw the value of ten even though our loop says is i less than ten yes so that's why our threads can start at some point in the future maybe few microseconds but maybe a millisecond maybe much longer ok and some point we're going to escape out of this for loop so at that point the value of i will be equal to ten because that was our exit condition but it gets worse than that because formally the value of this variable is not defined outside of this loop and in fact when we call pizza at exit we don't even need the stack anymore for maine so the memory that we might be reading at that point is no longer really hours to be looking at so we've got a pretty badly formed program here	['memory', 'thread', 'address', 'pointer']
ok alright so it looks like it's kind of working but not as well as we hoped we certainly got different thread ideas appearing and they do look like addresses i'll give you that but look at this we've got very strange values over here and even the last value is ten and if i run it again i get different values again if i run it again i get different values again ok so i get in all sorts of values here what is going on clearly we've got a program which is not deterministic we don't know what it's going to print out ok so why did that happen well hopefully you can see that we passed in the address of i and so actually what we have here is called a race condition it depends upon the exact interleaving in time of the instructions that are going to be executed i've got one thread that immediately after calling pizza it could create is going to increment the value by and then test to see if i is less than ten i have not go around again so we've got one threat doing that as fast as fast as i can and i got another thread that as soon as it starts will gas that pointer to an end pointer and then try to read it so it's a value that it sees depends upon the relative timing of these operations and that can change from one run to the next you might be surprised we even saw the value of ten even though our loop says is i lesson ten yes so that's why our threads can start at some point in the future maybe few microseconds but maybe a millisecond maybe much longer ok and some point we're going to escape out of this for loop so at that point the value of i will be equal to ten because that was our exit condition but it gets worse than that because formally the value of this variable is not defined outside of this loop and in fact when we call pizza at exit we don't even need the stack anymore for maine so the memory that we might be reading at that point is no longer really hours to be looking at so we've got a pretty badly formed program here	['memory', 'thread', 'address', 'pointer']
ok and approve it let's print it out right so i'm going to use put s today so i'm just say ok like here you go here's a pointer to character but don't treat it as a single character keep printing out those characters until you get to that zero what is put s this is actually equivalent to just print f to say ok printer print out the following string and a new line so it actually prints out a new line for us as well ok wait what are we missing we are missing some includes we need standard io for the printf we need something from alakan store copy how can we find that out use demand pages right so let me pull up a man pages right so tell me about ballack and you'll see that this inside standard lib so i need that ok and what about square copy again use the manpages right so man store copy and will see that's inside stringle h and if i have to scroll down i could find out more information about how they work king so copies from string the source to the destination ok right so let's put that in there and will have to get compiling this right so get out of that gcc reverse off and we're missing a semicolon so will fix that	['the following', 'printf', 'string', 'pointer']
ok and ha who've are yes guess gratulation 's we've managed to make another finished lee complicated program to add up to two million by using now kind of three for threads the main thread which doesn't do much it just delegates like a manager doesn't actually do any work and then two threads which are independently adding up a million but you did notice that actually we don't actually do any of the work in parallel first a thread probably the probably thread one but who knows actual add a million and then when it's finished it releases the duck and so the other thread gets to continue it requires a duck carries on adds a million to it and then unlock the duck ok so	['a thread', 'thread', 'a thread', 'thread']
ok and we take that caster character add one in other words we just calculated a pointer that now points to the b ok an we return that so if and when these two threads run we know that the first first one returns a pointer to bc string and the second one prints are xyz right what is the rest of the code to write so equals p thread join on thread a and grab the result and so in stores that in there area code result ok so what what is going to be put inside this result so this line is going to wait is going to wait until it's able to join p thread so that means we wait until functionary has finished at which point we set this result variable to be a pointer and it's pointing to here we go do that be right there which we print out ok so this will print bc add a new line	['code', 'string', 'thread', 'pointer', 'code', 'string', 'thread', 'pointer', 'code', 'string', 'thread', 'pointer', 'code', 'string', 'thread', 'pointer']
ok and we take that caster character add one in other words we just calculated a pointer that now points to the b ok and we return that so if and when these two threads run we know that the first first one returns a pointer to bc string and the second one prints out xyz right what is the rest of the code to write so equals p thread join on thread a and grab the result and so in stores that in there area code result ok so what what is going to be put inside this result so this line is going to wait is going to wait until it's able to join p thread so that means we wait until functionary has finished at which point we set this result variable to be a pointer and it's pointing to here we go do that be right there which we print out ok so this will print bc add a new line	['code', 'string', 'thread', 'pointer']
ok by the way this twisted we create can cause create their own threads right i gotta question for you let's go look at this code at the top here suppose someone said you will hold on a moment i'm kind of confused because isn't there a race condition as well with this this malloc and the fact that i've got i've got a stack variable here i mean isn't it possible that both threads might end up using the same piece of heap memory	['heap memory', 'memory', 'code', 'thread']
ok cool that as our argument here ok now how this memory be freed in fact we can delegate that to our image calculation so once that actually has completed it can call free on this argument so it's perfectly fine to create memory inside one thread will create heat memory inside one thread and release it inside another just be careful that when you free it you're completely sure that no thread is going to be accessing that data in the future	['memory', 'thread', 'memory', 'thread']
ok finally great let's ok off they go oh alright look at this we've run into deadlock where all five were hungry at exactly the same time so in practice causing this is actually actually difficult let me just run it one more time will see if we can generate it so you can see no expense spared on the graphics we've got five philosophers going through the states of either hungry eating or sleeping and yes we run into deadlock again this actually kind of take a look at this code because i want to show you that i actually had to work a little bit hard to make deadlock occur here so i want to reset my group right and let's	['code', 'code', 'code', 'code']
ok hi right so let's think about lock contention and also how this also relates to discovering race conditions ok so here's the scenario that we're going to think about that i've got a thread that most of the time is not inside the critical section and in fact if we sketch this out you'll see that initially i just got one single thread and only for a short period of time just one millisecond it's actually doing something inside a critical section that we haven't yet protected with any mutex locks but for the other nine hundred and ninety nine milliseconds	['a thread', 'section', 'thread', 'a thread', 'section', 'thread', 'a thread', 'section', 'thread']
ok hi so let's see what happens if we have a hundred threads right so how can we implement this well this is how i've how i've attacked this right i needed an array to capture all of those thread i ds i'm going to hundred of them today and so when i call pthread_create() i need to pass in a pointer to that memory so i could write something like i need the address of my array and i take the i th	['memory', 'thread', 'address', 'pointer']
ok i am not occured because we constructed this with the locks being acquired in a different order if they were in the same order it would have been fine let's just kind of quickly sketch that out to see that let's imagine that i had my first thread doing mutex worn and then mute x two and then mutex wanna mutex two down here for thread two then if they both try to acquire mutex in at the same time then we can imagine that thread one would acquire the mutex lock here which would mean thread two will be forced to block	['block', 'a mutex', 'thread', 'block', 'a mutex', 'thread', 'block', 'a mutex', 'thread', 'block', 'a mutex', 'thread', 'block', 'a mutex', 'thread', 'block', 'a mutex', 'thread']
ok if it's larger than unsigned long i don't care because i'm just printing out the number anyway so let me just cast it i wouldn't claim that this is kind of completely portable were bused bulletproof code because maybe on some systems and i know it might be a have a larger representation further than a simple long ok right so let me compile this directory list	['code', 'system', 'code', 'system']
ok is zero right the next issue is whoops i'm updating size here no this code suffers from the idea that get lines just returning the capacity the buffer it's not is returning the number of bytes read from the stream which is different from the capacity the capacity should be larger right so i actually need a new type here and double s for signed size and let's give it a better name like bites red ok and will change that to the address of my variable came looking good and now we want to just call exec well that's not how use exec exec see we're using the lp version which means that it's going to look up on the path and it also means i have to terminate my arguments with a character pointer with value zero in other words another point right so what do you think about that is that any good what will it do ok let's try it ok	['type', 'code', 'address', 'pointer']
ok of time where is ashley inside the the critical section so as we know everything will find our programs deterministic our program or function as expected provided these two don't meet another words providing they don't actually overlap right so could we estimate this will sure we could set up a full integral and think about how we think about these two random times as a whole bunch of times where they don't overlap and then there's times when they start overlap fully overlap and then only overlap a little bit again and then other times when we don't so we could set it up to set this up as a as a two dimensional integral but we just want to estimate this today so we're not going to worry about things like edge effects where where the very first thread goes into the critical section at the very end so it's not possible to overlap full or very visits critical section at the very end where it's not possible to overlap afterwards so let's not worry about that let's just concentrate on the idea that ninety nine point nine percent of the time my first date is not inside the critical section so we're going to look at the majority case an ignore the edge cases so right i thought and playing battleships with you now so i've thought of one moment in time where it is inside the critical section now you get to think of a number where you get to say ok right i'm going to choose my second thread to be inside this critical section what's the chances that we sunk the battleship what's the chances that they've overlapped	['section', 'thread', 'section', 'thread', 'section', 'thread']
ok right so let's kind of run through this remember that my disk is when i format it i've formatted it into a super block and i may have copies of that to the rest of the rest of the disk for backup purposes have a space set aside for i nodes and the rest of the space is going to be used for the actual files and any indirect blocks that we need to store okie sue this will look at our quick first question for x two with four kilobyte blocks at thirty two bit addressing watson maximum size are disk that we can support well the idea for this question is not about the indirect and double in triple indirect it's more the fact that if i want to say to the disk hey disc actually would load a particular disk block please then i can pass in a number which is bounded by thirty two bit addressing scheme so i've got two to thirty two possible dis blocks i could request and each one is four kb so if we do the math here and i think i did it in a previous lecture here that's remember the two to the thirty two how can i think about that well two to the ten is anybody knows is about a thousand thousand and twenty four ok so two of the thirty two is actually two to the ten times two to the ten times two to ten times ten times two to the two ok so now we can see that i'm going to change my units from kilobytes to megabytes to gigabytes to terabytes queso terabytes and then i've just got this two of the two times the original four so in other words i can support up to sixteen terabyte disks alright i hope that quick back of the envelope calculation makes sense	['block', 'address', 'block', 'address']
ok right so now we hopefully you can conclude what this code is going to print right so if you said it's going to print bc or the new line then you'd be correct if you said it's going to print bc in a new line and xyz you'd be correct if you said is going to print xyz with a new line and bc you'd be correct yes so what code is actually indeterminate fethard create makes no promises about when these threads now going to stop maybe in a microsecond maybe in a millisecond time there's a very real chance that	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
ok sir how could it be the celcom malik take the same amount of time well the answer is it depends it depends upon actually which operating system we're talking about and also actually just now talking about implementation choices based on implementation toys choices you'll find inside bsd and linux so let me give you kind of two two explanations how this could possibly be true and first of all let's do the the bsd one here's what bsd says bsd says you know we want to be very security conscious and that in fact is going to be our guiding principle that we want to make it secure operating system as possible so if a process has finished with a page of memory here then there could be important secrets inside that memory for example maybe there's a public private key information inside there maybe there's a password that you typed in maybe some sense of information that you just loaded from a file but whatever it is it's currently inside the ram so it would be unfortunate if that data got copied or access at some point in the future by a malicious process or malicious actor so what vsd does is to say we will have a background process to scrub all old pieces of memory so we're basically going to zero it all out so everyone is happy so that now i've got we put that as a little zero here a piece of memory that has been cleaned prewashed ready to go so if you called the kernel and say hey i need you to map please map some some pages of memory for me how many were let's say	['a page', 'memory', 'type', 'a process', 'background', 'system']
ok so and then after that unlock it wait and similarly with the other thread runner we want to lock it and then only allow other threads to modify that memory after we finished using it so after printf has returned ok so let's give that a whirl if we gotta type sweat	['memory', 'type', 'printf', 'thread']
ok so between you and me as big is not actually used anymore instead we're going to use some virtual memory tricks of all the slide this did modern c library uses some virtual memory tricks that we haven't learned yet so s breakers are simply mechanism but we will use it for cs two forty one to implement a simple memory allocator ok so remember how i said that the bottom of the memory i've got the text segment which is the program code and string literals and any other constants we've put in here and	['memory', 'code', 'string', 'memory', 'code', 'string', 'memory', 'code', 'string', 'memory', 'code', 'string']
ok so each philosopher is going to be given a pointer to its little struct there ok so each plus is going to get its own unique name etc right so we also have some local stack variables which mirror what we find inside the the struct you'll see why in a moment so let's see what	['pointer', 'pointer', 'pointer', 'pointer']
ok so hopefully your system programming a alarm bells go off because the problem with this code is that there's a path of execution where we forget to close the current directory so if we do find the name that we're looking for we returned one we never actually execute this closed so that's a problem	['code', 'system', 'code', 'system']
ok so if i control the one and only cpu and i cannot be interrupted then i get to do everything inside the critical section until i give up the cpu ok so providing i don't make any system calls providing i'm just updating my data structure no one can stop me because i disabled into apps	['a struct', 'section', 'system', 'a struct', 'section', 'system', 'a struct', 'section', 'system', 'a struct', 'section', 'system', 'a struct', 'section', 'system', 'a struct', 'section', 'system']
ok so if we have a pointer to this type and this structure type which got a lot of information how do i pull out the individual parts of what's there in the memory remember we've got things like whether how big it is in other words the number of bytes that the user could actually store there well that's inside our size variable and whether this particular entry represents something which is available which is free or not ok so you'll notice i'm now using this little operator this kind of arrow thing which means hey go to some memory and don't treat it as just float or an integer instead i want you to use its type and inside that type there's an offset and so many bytes in order to be able to read this variable so when the compiler first saw this struct it needs to allocate offsets to each of these variables so for example it might be that the pointer start store at the very beginning of this struct area size might be saved four bytes eight bytes later free might be another say four bytes eight bytes later the compilers free to put some padding between variables so the alignment of each of these variables makes sense and realized that these entries just like member variables inside a c plus plus class or fields of a java object were going to coeur each time all we need to know is the base address of where that struct is going to start ok so right let's go have a look at this in so we need a little loop that says well so i'm looking at a valid entry in my linked list so keep going until i get to the end i need to consider the current apartment that i'm looking at is a good one so our first criteria and this is important of course is that it's currently free ok what else well we need to make sure that it's sufficiently large right so how can i write that ok let's get a little pen here right so we need to see if the	['memory', 'type', 'address', 'pointer']
ok so in one corner i have the child here that every two seconds is going to print out forty bytes out and then directly reads forty bytes from that address ok so organized and say is hey take this memory and send forty bytes of it directly to stand it out meanwhile my parent process is modifying the memory so let's use s printf to directly write to this memory address that we got back from a map and we will write the following formatted string will say hello from the other side and followed by a little number account here ok	['the following', 'memory', 'printf', 'string', 'address']
ok so let's get down here ok right so what do we do after this point ok when we escape out of here where a scaping out of here because fireworks is no longer no longer zero and the very first thing we do is call p three condition broadcast in other words ring that fire bell wake everybody up in this might be sleeping inside this condition variable ok so now all five of my threads	['thread', 'thread', 'thread', 'thread', 'thread', 'thread']
ok so let's play with race conditions and then fixing with blocks right so what do you think the following code is going to print here we have a counter variable which is global as you can see anybody can reach into it and read it or write it and in fact like a little function here that is going to loop looks like a million times and each time around the loop we're going to implement that counter now the value of eyes a stack variable which means i can create a whole load of threads and each one is going to get his own value of i but they are all picking at this global variable this countered so they're going to share access to that that variable right and then i've got some code on here peter create peter create and then two p thread joins so out of the two p thread joins we print out the value of counter right so what do you think about this code what's it going to print let's give it ago so i need to compile it ok i've compiled it off we go right it did not print out of course two million it we run it it just happy prints out different values each and every time so why do you think that is a key so actually there's two reasons the first one is because it the value that we get depends upon the actual interleaving of my two threads to how they do this increment so even though we plus plus hear	['the following', 'the loop', 'block', 'code', 'thread', 'the following', 'the loop', 'block', 'code', 'thread']
ok so let's play with race conditions and then fixing with locks right so what do you think the following code is going to print here we have a counter variable which is global as you can see anybody can reach into it and read it or write it and in fact like a little function here that is going to loop looks like a million times and each time around the loop we're going to implement that counter now the value of eyes a stack variable which means i can create a whole load of threads and each one is going to get his own value of i but they are all picking at this global variable this countered so they're going to share access to that that variable right and then i've got some code on here peter create peter create and then two p thread joins so out of the two p thread joins we print out the value of counter right so what do you think about this code what's it going to print let's give it ago so i need to compile it ok i've compiled it off we go right it did not print out of course two million it we run it it just happy prints out different values each and every time so why do you think that is a key so actually there's two reasons the first one is because it the value that we get depends upon the actual interleaving of my two threads to how they do this increment so even though we plus plus hear	['the following', 'the loop', 'code', 'thread']
ok so let's see what it does right it initializes the gui will check out in a little bit we call kelak and we seem to be getting enough memory to hold air these thirty two bit integers and we also going to have another way on the heap for all of our threats that we're going to have a height number of threads and each one is size of p thread t ok so again not a point it looks good so far right now i gotta comment could offer alright this is giving me a suspicion that we might have have a steak inside here somewhere that's how look so we call patty at create we've pass in the address of my thread away	['memory', 'the heap', 'thread', 'address']
ok so let's start talking about how we can improve a free so first of all just a reminder that now you can see that with realloc if we could actually access that link list when real work is called we can start writing a real lock which is faster but what can we do about free how can we make free faster right now we had an implication of free that walk through the linked list looking for that user pointer but had to be unallocated can we do better yes so here's how we can do it using an order one approach what we need to realize is that if we put in the metadata directly inside the heap as well then the following is always true that if this is the heap memory that the user is going to see then geass before to the different colour there we go	['the following', 'heap memory', 'memory', 'the heap', 'pointer']
ok so let's talk about why the nation part of the operating system here that is ass break now if we were to look at the manpage of s break you'd read something like the following s break increases the process is data segment by end bites so when you call s break you can give it a number and you can say hey i'd like ten more bytes please alright so what does that actually mean	['the following', 'system', 'the following', 'system', 'the following', 'system', 'the following', 'system']
ok so let's think about kind of a minimum implementation of what are this code might look like from the outside hey it just looks like a regular call but from the inside we actually need to construct a message so how could we do that well here's one way there's a call called ass print f which will get some heat memory for you automatically so it's a bit like sprint f meaning that it will write the output to some memory but in this case it will actually get some heat them before you the right amount and then tell you where that is so we just need to give it the address of a pointer and it will update that pointer force ok so we are going to send a little message to say hey this new score here's a name here's the score right and let's send that off and we better hope that the name does not contain a calmer because we're using commas to separate the fields here right so will call right in practice of course this would actually have to have some error checking in here here's a message and we want to send the entire message ok what do you think about this message plus one well that would mean ok start sending the message from the e so this is incorrect we actually want to send message but why why does this code say send everything plus one well if we're going to send messages we need a way to say hey at the message has finished and is typically two ways to do that either top of the message that started the message you say how long your messages or you have some kind of	['memory', 'code', 'address', 'pointer']
ok so maybe you know about threats so great you are able to chunk up the work into different jobs so that each thread is responsible for the output of the total result and so you need each thread to work independently great you say i remember those two forty one p right to the rescue that now i can tell my first thread to explicitly write its results into the first part of the file meanwhile the second thread over here is starting to generate results as well and so it can start writing bits of data over here and we can explicitly say where in the file we want that to go so yep there's pwrite and there's also pread which does a similar thing that you can read from a certain part of the file and directly specify an offset into the file so they are very useful when you want to to do random access and random reads into file but also later inside cs two forty one we're going to learn how to memory mapped files directly into memory where we no longer even need to call read and write but we can actually look at the file as if it is actually part of our address space so that's coming up later inside cs two forty one and it's the most one of the most far and most powerful features of posix and system programming that you'll see in this course so the will do what's a named pipe ok how do i make a named pipe for this you can actually make pipes on your file system you can just say make vivo because they behave as a little first in first out queue so let's call it say my queue kate and now if you look on the current directory you will see there's something called my queue so here it is looks a bit like a file right now but let's find out some more information about it ok and you'll see i've got a magic letter over here that actually it's a queue so i can put stuff into it let's say helico hello pipe that into my queue	['memory', 'thread', 'address', 'system']
ok so our code will fail at line ten the only way that we could start this code from failing at line ten would be if we swapped lines ten eleven because this is what we can do with pointers with pointers you can say hey pointer pointer something else and so if we swap those two lines around by calling malloc first we would have changed t one to now point to some brand new memory to some heap memory and we could have set that very first bite to an agent but we would not have created a string because of h of to be a c string would have to also have a zero bite after it and malik doesn't guarantee as anything about the memory that we actually get with that i'll see you next video for further next question by	['heap memory', 'memory', 'code', 'string', 'pointer']
ok so our code will fail at line ten the only way that we could stop this code from failing at line ten would be if we swapped lines ten eleven because this is what we can do with pointers with pointers you can say hey pointer point to something else and so if we swap those two lines around by calling malloc first we would have changed t one to now point to some brand new memory to some some heap memory and we could have set that very first bite to an h but we would not have created a string because the h of to be a c string would have to also have a zero bite after it and doesn't guarantee as anything about the memory that we actually get ok with that i'll see you next video for further next question by	['heap memory', 'memory', 'code', 'string', 'pointer']
ok so that was blocked splitting we can also do the opposite which is cur lessing blocks so let's go back in for a moment and have a look at our code here where we worked remember through are linked list finding a viable entry here and if we did we decided to mark that particular entry as unavailable and we return a pointer to that entry ok so i want you to imagine the following suppose	['the following', 'block', 'code', 'pointer']
ok so there's several things we want to be able to do we want to be able to create a new thread of execution and when we do that is very different from folk when we do this we want to be able to say ok start running from here so for example i might want to say right in the background i want to start running a thread that is going to mine bitcoin so please i'm going to have a function called mind for example i'm going to use your spare cpu and i don't care about the environment and i'm not paying for electricity that kind of thing obviously don't do this all the university machine but i want to be able to say ok peter head start on my function called mine right now i wouldn't actually write mine like this because this means coal mine instead i need the address of my function and surprisingly if you just give the name of a function then that is actually that actually says ok where is this function or another one perhaps i've got a function which is going to download something in the background so maybe i've got a function called to know download update or does something else useful for me in in the background ok so then i'm just need to somehow to say hey system i've got this function please assign a new cpu to this function and start running it and that's the purpose of pthread create so this creates a new thread and for this we're going to pass in a function where we wanted to start for so it be very strange to say please start from maine instead we're going to write our own function and that's where we'll start ok so how do you then wait for that function to finish for example suppose i had a function that rendered a manageable picture or found me a bitcoin now i want to wait for that to finish before continuing ok so here's how we can do this we can call p thread join	['a thread', 'thread', 'background', 'address', 'system']
ok so think about a typical kind of local call how much work do you have to do so for this we extend the stack ok we put on return address onto the stack so this is the old pc value the program counter this is where we want to go back to after we return we're going to put potentially some parameters on here though for efficiently see today because we can because silicon today is so cheap we may not put all all of the calling parameters onto the stack instead we can pass them directly through registers and that's obviously much faster than writing to to memory in order to store some parameters and we need to change the stack pointer to say hey old stack was just here this other stuff up here and now we've moved down so that if there's local variables we can	['memory', 'parameter', 'address', 'pointer']
ok so think of like to parcel cards so this number is smaller great i'll take this now we build the next number ok so now this number is not as small as the number might from my right hand pile so i'll take that and repeat and eventually we managed to merge these altogether and notice i relied on the recursion fairy to do most of the work so of course this happens at all levels so if i've started with nice big block of data say mb of data then first of all we call recursion ok and so on and so on and that has to be cursively run these ok so how can i now	['block', 'block', 'block', 'block']
ok so this little demo is actually going to finish pretty quickly but in real production code which doesn't finish quickly it's important to make sure that we released everything that we've asked for from the system so in this case we want to free up the memory that we called we used for getline that will either be the original malloc we called or some new memory get line is used an then don't forget our little file handle as well and if we want to be good citizens we could also change our little file pointer here to be null just so no one could use it after that ok like i said there's a kind of overengineered for this small amount of code but i hope you understand the intent behind it right so can we run this ok let's let's set up some test examples let's see what we have here let's have a look at some little problems little examples scripts i've got here i've got one which	['memory', 'code', 'system', 'pointer']
ok so up here to be the same we're going to look at the device id of a special file but don't worry about that instead this is how we can find out the true size of a file in bytes and rather than being just say an unsigned long or size today we want to be able to work with extremely large files so this special type here there's off underscored t is designed to be large enough that should be big enough for any files and we want to store inside this for today and in the future right so here is s t size so that's kind of useful but perhaps you actually care about how many how much space is currently being used on the disk so the disk itself i've talked about four kilobyte blocks but	['block', 'type', 'block', 'type']
ok so we call fork and now we're trying to wait a little bit more kind of robust code here because we actually checking for the error condition and if it fails do not pass go do not do not attempt to call fork again and instead immediately exit so for can be very dangerous if like agent smith in the matrix movies you allow every process to make more process is as fast as possible so be extremely careful that day that you start writing code we're fork is inside the loop and one day then that they will count when you create a shell where you are reading every line of input in order to run that as a process	['the loop', 'a shell', 'code', 'a process']
ok so we didn't need a definition for deadlock and this idea that our our threads are frozen up maybe one thread is waiting for a mutex lock that is never going to be unlocked maybe we're waiting for something from a data structure which is never going to be given to us so here's a general definition for dead log key	['a struct', 'a mutex', 'thread', 'a struct', 'a mutex', 'thread', 'a struct', 'a mutex', 'thread', 'a struct', 'a mutex', 'thread', 'a struct', 'a mutex', 'thread']
ok so we're going to call start and that's the last thing is the parameter value that is going to be passed in when we do finally get round to starting a new thread will go in here so that null is going to be the value of this pointer if i'd said something else like an address of a variable again that void pointer would have taken that address ok so great we're starting three threads and then after that loop we're going to call it p thread exit and as you know what does p thread exit do is the point of no return it's the one way ticket to oblivion for my poor little thread and in this case i'm doing it on the main thread which means that we will never return from this call that's the end of the line for this cpu here executing the main thread which means of course we won't actually return from maine which means that we won't exit the process at that point so instead my process is going to continue until all my other threads are completed	['parameter', 'thread', 'address', 'pointer']
ok so we've got our struct now let's think about how we can use it when we're running the program we need to keep track of our little linked list so for that let's have a variable here called head here i can sort it right so we're going to see a reference to that and what is it it's a pointer to little struck that we just defined above we've also declared this variable to be static and what static does is it hides the variables so that only the code i write inside this compilation unit in other words inside the dot c file that i'm currently writing will actually see this variable so that's the safety measures just in case you decide to have a global variable called head as well then there actually referring to do different variables and it also ensures that my implementation details aren't going to leak out into the rest of the code right so i've got my global variable and initially of course i don't have anything allocated now let's think about how we want to implement malloc here's our plan malloc is going to do two things first of all let's walk through our apartment complex and see if we have any available apartments which are large enough and available to satisfy the request for the so many bytes that we need if that fails then we'll go back to the system and say timetable be some some more heap memory please and for that will use sbrk so will only happen in our plan b we going to go there if we cannot find useful piece of space to be allocated earlier that is now free ok so let's have a look at that	['heap memory', 'memory', 'code', 'system', 'pointer']
ok so we've got this general definition of deadlock now actually let's see if we can kind of construct some examples where we actually cause it so let's use team mutex locks and two threads to create an example of deadlock ok bye i'm going to actually do this in a text editor ok	['thread', 'thread', 'thread', 'thread', 'thread']
ok so we've kind of talked a little bit about this idea before so it could i implement p thread mutex lock just by disabling interrupts on on the cpu so the idea here is that if my code is running on the cpu if i disable interrupts then i cannot be stopped become agent smith out of the matrix that now i own the cpu so no one else can can take it for me so one of the limitations of this first of all that yes we can ensure that we're the only ones going into the critical section if one there is only one cpu	['code', 'section', 'thread', 'code', 'section', 'thread', 'code', 'section', 'thread', 'code', 'section', 'thread', 'code', 'section', 'thread', 'code', 'section', 'thread']
ok so what's the fix and why did this occur what the answer that we actually have to understand how shar two fifty six works and in fact if we would read the man pages we would discover that we could have passed in a point to some memory and if we made that memory unique to each thread then we would have had threadsafe code so let's look at quick look at the solution here so the solution is to get some space on the stack and remember each thread is going to have its own stack and passed a pointer to that for short two fifty six core and if we do that now we have thread safe code so i guess also takeaway message here is you have to fully understand the syst[em] calls that you're using if you want to write threadsafe code and then that's it that's the other elected by	['memory', 'code', 'thread', 'pointer']
ok the second is that i require an here's a big problem here is that actually require sufficient privileges to disable the interrupts and because this is such a powerful operation by default that is disabled for normal user programs we need interrupts in order to make a cpu stop running one thread and start running another in order to handle hardware interrupt you too do to devices iot devices being ready to either take data from the system or give data from the system for example the network card might report that her new packages arrived and here's some data or a disk or solid state disk might report hey i've now finally got the data you can now read this into memory or gpu might ask for more memory more data so there's lots	['memory', 'thread', 'system', 'memory', 'thread', 'system', 'memory', 'thread', 'system', 'memory', 'thread', 'system', 'memory', 'thread', 'system', 'memory', 'thread', 'system']
ok this is the whole story now there's a few little lies inside this story ok so what are the lies first of all that when we load libraries like the c library or if we were doing open gl sound library we need to put those in memory as well so in practice they will actually live between these where we dynamically load libraries so we might put other stuff in the side there also the idea that the heap is actually just one contiguous block of memory later on will axe that model and if you say to malloc hey malloc i'd like four gigabytes of memory actually it's going on a modern machine going to find a different space for such a large allocation ok but more little other light is that in the future we'll talk about threats and each thread will need to own stack but less live in a cozy world right now where we just got a single stack a single heap area and as we make more complicated programs these are going to expand my heap expands as i keep calling malik and i never call free my stack expands downwards as eyes for example keep making lots of recursive calls right so you'll learn more about stack and how we represent things on the stack	['memory', 'the heap', 'block', 'thread']
ok we can put any data we like inside there and by default the total amount of memory allocated to this is g asked sufficient for what we need ok but what about the day you call malloc and say hey my malloc i need another four thousand and ninety six bytes please this point we need need to go back to the operating system to the kernel and beg for some more van back for some more real addresses we don't want to talk to the oblivion we don't want to avoid we actually need those memory addresses now to refer to some actual memory and that's the purpose of s break is to say yes i know i've got my heap possibly say zero bytes at the beginning but that's not enough now i need to extend it so i please i'd like to move this watermark upwards say by two hundred fifty six bytes so that now i've got some more addresses i can play with i can use to hold some data so that's one less pack gives you an ability to turn on like a tap some more some more dresses which are valid ok we just keep extending this space here and we can use that then to implement possibly the world 's worst but simplest allocator so let's have a look in a moment then how we could actually use this to implement malloc are you ready are slow you in the next video bye	['memory', 'address', 'system', 'memory', 'address', 'system', 'memory', 'address', 'system']
ok we're pointing at one character but you and i know that actually we're going to point one memory address for the character but then the remaining characters then remaining bytes can be used for more characters we have whole c string and rather than just passing where that pointer points to we very sneakily are going to say hey tell me the address of this variable because i'm going to change this address to actually	['memory', 'string', 'address', 'pointer']
ok, so let's have a look at the code that's currently being given. i have a feeling there might be a mistake or two. right, so while asterisks pointer, in other words, follow that variable. let's have a go and look at what's actually inside that memory. this is very common with pointers. what do we want to do? we actually want to go and see what they're pointing at. so this looks like it's trying to check to see if there's a zero byte there, because if we get to the zero byte, great! we know that we've reached the end of this c string. [indistinct words] the reasonable request. ok, what's going on here? inside this loop, destination equals source. wait a moment! that is just copying the value inside these variables. in other words, we're not reaching out to that memory. instead, we are just changing dest	['memory', 'code', 'string', 'pointer']
"ok, so maybe you know about threats so great you are able to chunk up the work into different jobs so that each thread is responsible for the output of the total result and so you need each thread to work independently. """"""great!"""" you say. """"i remember those from cs241"" ""to the rescue."""" that now i can tell my first thread to"" explicitly write its results into the first part of the file meanwhile the second thread over here is starting to generate results as well and so it can start writing bits of data over here, and we can explicitly say where in the file we want that to go. so yep, there's pee right and there's also period which does a similar thing that you can read from a certain part of the file and directly specify an offset into the file. ok, so they are very useful when you want to do random access and random reads into file but also later inside cs241 we're going to learn how to 'memory map' files directly into memory where we no longer even need to call read and write but we can actually look at the file as if it is actually part of our address space. so that's coming up later inside cs241 and it's the most one of the most far and most powerful features of posix and system programming that you'll see in this course. ok, so the will do what's ""a named pipe?"""" ok, how do i make a named pipe? for this you"" can actually make pipes on your file system. you can just say make vivo because they behave as a little 'first in first out' queue. so ""let's call it say ok, and now if you look on the current directory you will see there's something called 'myq.' so here it is. looks a bit like a file right now but let's find out some more information about it. ok and you'll see i've got a magic letter over here that actually it's ""a queue"""" so i can put stuff into it let's say helico hello"" pipe that into my queue."	['memory', 'thread', 'address', 'system']
okie right so we scared out some ideas here as you can see it's kind of tricky to keep everything in mind you have to keep very clear idea about what your data structures look going to look like in memory and don't make any mistakes with pointer arithmetic so get it working first with a simple idea and then proceed slowly as you try to kind of optimize your code when things are working make sure you commit your code so you've always got something to go back to and also as a way to be able to discover early on when you've made a breaking change rather than writing hundreds of lines of code and they're wondering where the error was so so test early and test often alright where that asks you in the next video bye	['memory', 'a struct', 'code', 'pointer']
on a different thread an oh dear both of them are now trying to use the same piece of static memory so one hour is going to override the other one right so this kind of common with some of the earlier calls inside posix that they weren't built with with threads in mind and so threat support the ability to work with multiple threads has kind of been reverse engineered back into some of these api calls so stroit error itself with this underscore r will discover actually	['memory', 'thread', 'memory', 'thread', 'memory', 'thread', 'memory', 'thread']
on the stack, so [the] data itself represents 8 bytes on the stack so right just here we are passing in an address on the stack of this calling function of the thread that originally ran this code case. so that sounds pretty dangerous right we're actually saying, right, inside this array you want to pass in the address of this five just here using pointer arithmetic	['code', 'thread', 'address', 'pointer']
once i've called free. so in c, we have to think carefully about when we allocate memory and when we free memory. this is of course challenging, but hey, challenges are good for you. plus if you actually do this carefully, you can make your programs run quite quickly if you are aware of when memory allocation occurs. memory is a very precious resource on systems, and also allocating memory is a slow slow process. so this is one reason why many interpreted languages are quite slow, simply because of the number of allocations and deallocations that we're doing on the heap all the time.	['memory', 'memory allocation', 'the heap', 'system']
or how much capacity is left s two is initialized to zero so that's counting the number of things we've actually got inside the buffer right now and then we've got lots of threads producing things and consuming things as well ok so here's some questions that we might want to ask in sort of code review first of all can we find a way that deadlock can occur in other words when good it actually get stuck and if so under what conditions could it be for example when it gets completely full or completely empty is underflow possible meaning that is it possible for d q to return something even though we don't actually have anything inside the buffer right now in other words it will just return some multivalue that happens to be stored inside the buffer	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
or maybe it's some data structure but whatever it is we have this idea that only one process or thread at a time can access it now i'm going to use the word process that's kind of historical reference in the sense that we thought about these things even with four threads exist but you could imagine how we could set up identical situations to multiple threads running inside just one process so it's the concept is the theory which is the most important idea here ok so what do i got in question one i've got my first process p one requests and obtains resource a and then resource be ok so let's set up process one here ok process one	['a struct', 'thread', 'a struct', 'thread']
or you will find examples where the chunks are slightly smaller and also we can talk about blocks or super block such a much larger today but let's let's concentrate on this main convention here so in other words i'm throwing around four thousand ninety six bytes anytime i want to load or read something from the disk so you've probably been talking about kind of cache lines and this idea that if you make a request in main memory	['memory', 'block', 'memory', 'block']
other servers my server might send an xml message in order to confirm that booking or in order to find out if an airplane has some some seats between two destinations that are at a certain price point for example ok so xml is very kind of popular as interchange format for kind of finance and booking applications now quick comment is that you don't need to write your own json parser your xml pauses today of course there's plenty of library code out there that will do this for you some of them will give you events based on each time they see a new tag others will read the whole thing into memory and creates what's called a dom document object model module which is great for a kind of small message is not so great if your dom is huge and then you can iterate through that by asking a dom to say find a particular child of a certain type one last thing is you'll notice that each element we have here we can actually have water cord attributes case so we've talked about elements which are the items we actually find insight memory each element may have kind of attributes the difference between an element and a tag is the tag is the actual piece of string that we've written here the actor going to bite sequence that we needed to actually describe the elements ok so the tag is the actual thing with the open and close	['memory', 'type', 'code', 'string']
over here here's my mutex lock it's now got one in but the value that q it now has is zero so it escapes out of this loop and can continue so that first they can go into his critical section meanwhile as second thread calls mutex lock ok what happens to it well its own value of q is one and then it calls exchange right but it's just going to exchange a value of one with one because that's what's already inside the mutex log so now it reads a value of what again so what's it doing it goes around the loop again continuously trying to get rid of this hot potato right so it's like i've got a one oh what do i do i'm going to keep calling exchange i'm going to keep trying to push it into the mutex lock	['the loop', 'section', 'thread', 'exchange']
p thread mutex lock k and we're going to say please lock on this first mutex and then after you've done that please lock on this other mutex right so it will do some work ok do something and then after that we want to at least ok so we will call p thread unlock on both of these mutex is ok	['thread', 'thread', 'thread', 'thread', 'thread', 'thread']
physical memory and divided it up into these chunks into these rammed into these disk sorry into these memory blocks here and we needed to do things like say well these bytes right now i don't care about no one seems to be using word to paginate tables so all that code inside here is just wasting ram so why don't i evict it out of my memory meanwhile i've got some other stuff that i would like to have inside my ram inside my memory so i want to page that into from disk into memory maybe it's some code that i now need maybe it's part of a data structure that i haven't needed for several minutes	['memory', 'block', 'a struct', 'code']
physical memory and divided it up into these chunks into these rammed into these disk sort into these memory blocks here and we needed to do things like say well these bites right now i don't care about no one seems to be using word to paginate tables so all that code inside here is just wasting ram so why don't i evicted out of my memory meanwhile i've got some other stuff that i would like to have inside my ram inside my memory so i want to page that into from disk into memory maybe it's some code that i now need maybe it's part of a data structure that i haven't needed for several minutes	['memory', 'block', 'a struct', 'code']
push and pop in a tight loop and we called it for ten thousand times so empirically we've shown that maybe if there's a likelihood of it failing we've at least tested it to the kind of point one percent level but is that is that is that does that give me confidence to put this into production no i'd actually want to kind of actually do a code review and think carefully about how my code works so so in multithreaded code it's a very important we have strong understanding about how our code works and rather than just simple going to lightweight testing and say oh yeah great pistol work if we actually want to use this code and trust it on our game or driving a car or an aircraft or website which is going to make our livelihood we actually want to be confident that we've got this multithreaded coding correct ok that's it for now bye	['code', 'thread', 'code', 'thread', 'code', 'thread']
push say ten thousand times but we're actually going to do that with two threads and then i've got a consumer method that is going to call pop twenty thousand times is just one of those today so let's check that we actually get all values of all the double values that we pushed in so we know that we know that we're going to push in the	['thread', 'thread', 'thread', 'thread']
remember that actually when we return from the function all we need to do is just change our stack pointer to go back to the previous area and change a return value so that's why stack variables are so much faster to allocate and deallocate compared to variables on the heap there's so little work to be done with just change change the pc register and everything 's gone so great we've got an idea of a thread of execution and we could trace this through our program so if i want to make a second thread if i want another cpu core to be running at the same time then i'm going to need space inside my memory for another thread and so each thread then it's going to get its own stack right and these are inside the same memory address space but they're going to be separated by say megabyte or so so they don't collide ok and then the last quite common is why do they call it the thread of execution is because literally you could draw a line you could thread through where my cpu is currently acting so if i had a function called x and inside x we called say f two and inside f two there was a moment that called f the function below we could trace this we could say i look this is the history of my cpu it's common to hear it's currently in this step so literally could paint a picture	['memory', 'the heap', 'a thread', 'thread', 'address', 'pointer']
reserve some memory on the heap and return a pointer that ok so we just have to put in asprintf keep going down here here it is you'll see that it takes a pointer to a pointer so now with asprintf we actually say ok here's the result my result variable and	['memory', 'the heap', 'printf', 'pointer']
right and i've got a public counter global variable you can see i'm incrementing it inside this function and each thread that i'm going to create down here inside my main is going to run this code for a million times right so with that in mind what do you think it's going to do it i will tell you the answer that in the next lecture but why don't you pause this right now and make your prediction by	['code', 'thread', 'code', 'thread', 'code', 'thread']
right but we're giving it this string so actually t one is going to hold the memory dress of that age is going to point directly into the text segment is going to hold that memory address which between you and me is going to be a low value the text segment is it near the beginning of the processes memory now there's a surprise however with t two t two is not a pointer is actually an away we didn't bother to specify the size because the compiler can work that out itself and the surprise here is actually the compiler is going to write some extra code for us here because rather than just looking at that string	['memory', 'code', 'string', 'address', 'pointer']
right great ok so unless some implement a stack and will implement stack but is bounded by two things first of all you'll see that i data store here my little array here can only handle ten items also we can't pull anything from the stack if my stack is empty so now push and pop methods need to block if they are unable to continue right so let's let's have a good figure out how we're going to implement this first of all let's just pretend that with i cs two twenty five or some other course right and right than on the single threaded version ok so what are we going to have we're going to have things like the push method will be take my data structure my ray and after i've used the value of n increment it and density equal to be ok right what else you want to do so for multithreaded code i need to make sure that i'm the only person using this value of end otherwise two threads might call this code at the same time and both right into the same slot the same entry inside the away so less using mutex lock for that so we're definitely going to need mutex lock	['block', 'a struct', 'code', 'thread', 'block', 'a struct', 'code', 'thread', 'block', 'a struct', 'code', 'thread', 'block', 'a struct', 'code', 'thread']
right so anything else you want to say about this yeah and realize that look i can have some heat memory in here i could call malloc from one thread i could have some global variables just beneath that and all of my threads can refer to these things that just memory addresses it's up to you how you store these memory addresses where you use them so all of my threads could see my constants like hello tomato so let me put tomorrow in here somewhere down here but near the code if i'd made some malloc memory i could have passed that address to my threads all they need adjust addresses and they could happily use them so one thread can even see the stack memory of another thread there that isn't always a safe thing to do and i'll let you work out why so	['memory', 'code', 'thread', 'address']
right so great we've implemented that now actually let's have to think about how we can implement the firework right so what does r firework do k right well we acquire the mutex lock i might impede here just for for sure had so we've got we've got the mutex lock and all threads that run this code again to acquire the same lock	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
right so how can we fix it we need to address this race condition but will do it in two different ways first of all how about we turn this into a task that we give each one and my task right now is just no little integer so let's have some memory for each thread so i'll call it say starting values and you can see i'm using a global here right and it will be let's see i'll have ten am and i can initialize these which i could do as part of this loop or i could do it earlier ok so you can be let's say hundred plus i today just so we can prove that we're running this program ok	['memory', 'thread', 'address', 'memory', 'thread', 'address']
right so i promise we start using p thread mutex locks so here we go let's figure out how we can fix this program alright so xm ideas we can try here first of all let's get our self lock will make it a global so all my programs can see it if i didn't use globals i'd have to pass it around or least pass a pointer around to it right so p three edit musics type i'm going to call it a duck i want to imagine little duck quack quack that's very important little lock and today i'll use the the magic value piece red mutex initializer	['type', 'thread', 'pointer', 'type', 'thread', 'pointer', 'type', 'thread', 'pointer']
right so i'm going to get back a limited number of bits of information and in fact this integer is packed full of good stuff it tells us the exit value that you may have defined in when exchange program by either calling exit or by returning from main or if your program crash for example it tried to read and write some invalid memory like memory location zero then it's going to segfault and we could discover that well or if your program was perfectly happily running along and somebody press control c and interrupted it then would crash your program then we can discover that too so all this information is encoded inside this little integer now i could tell you things like and on this particular system the exit value at least the eight bits the lowest 8 bits basically exact value are encoded somewhere somehow inside this integer perhaps in the lowest bits, perhaps in the highest bits,	['memory', 'code', 'exchange', 'system']
right so let's pass in less actually start to use this value here so rather than just saying hello here let me have a screen ok where should i get that string form remember this argument i've got here well that points to some memory and you and i know that at that memory is a secret message so let me have a pointer now a character pointed to do that for me to then using my code k right so i could now just start writing the normal code i have and ok let's run this	['memory', 'code', 'string', 'pointer']
right so that's the first part of our critical section the other is when we also want to overwrite it so that will be inside here we do not want these two pieces of code running at the same time ok so how can we do that and so a mutabal the music 's let's get our mutex to rescue this code all right and make sure that only angrave wins a million dollars and jurassic park never sees its money ok so here we go right so i need to make myself a mutex case so i can do that i can do that in my main here right so i'll say pthread mutex	['code', 'a mutex', 'section', 'thread']
right so the point then is to actually a threat can block and two places it might be blocked temporarily at the very beginning here just wait get the mutex lock and a good rule of good conceptual idea is that you only holds mutex lock for a few nanoseconds we're modifying something for example ok so reminder this code actually does three things first of all it unlocks the mutex and then it sleeps literally we ask the cpu to go and work on a different thread right so we're not going to execute anymore code but later when we work it up before returning it will re lock which mutex so it will reacquire the mutex so if there happens to be another thread that was temporarily holding that mutex say was also being also college document or those will see in a moment also calling equipment then this thread has to wait so there's lots of places where thread is blocked ports has to wait till it can continue ok right so what about our increment method we saw that before we change the data structure we want to lock the mutex so that we are the only surgeon operating on it and then afterwards we unlock the mutex ok right so what do we forget we forgot to wake up any sleeping threads in here so we've modified the value of cakes so we could wake up all threats so for example we could say p thread condition forecast if we wanted to wake up all threats that might be sleeping inside the thread condition wait or we could call p thread conditions signal if we wanted to just wake up one of them and which one gets working up this arbitrary ok right what else can i say about this well it could be that there's no thread waiting inside the condition variable so in which case our signal or broadcast called here is a no op is not worth calling so if i truly cared about maximum performance i could actually reason about when i actually need to do this i remember that because of the mutex lock only one third of the time can be operating so at this moment we could say look if i've just changed my value of cake from zero to one then that's the only time that there might be sleeping through its otherwise if there's pieces of kate lying about no one 's going to be sleeping when they call decrement so let me test that if cake is now on let me call peter conditions signal now some of you might ask is it best to call peter conditions signal or broadcast before or after you are not the mutex surely it's better to call it afterwards but the surprising thing is	['block', 'the data structure', 'a struct', 'code', 'thread']
right so this gives me shivers down my spine here will it work one of the question is do we feel lucky there is a chance that the memory address of hello because it's a little in a memory will be in a low address so there's a chance that we could actually represent that using a c type int let's think about this for a moment so we could be on a thirty two bit machine where the integers for example might be thirty two bits and the pointers are thirty two bits in which case great everything is fine so there's a very strong chance it work despite i was going oh that doesn't seem like compliant code yes so in practice we wouldn't want to write this but on a thirty two bit machine it stands a high chance of working and in fact plenty of code used to be written like this where there was a spare spare parameter or a struct like a user parameter it was just an in so people will just throw pointers in there ok that worked for many years until the day that we decided to try to compile this code onto a sixty four bit machine now let's see what happens about when you do this trick on a sixty four bit machine so now my integers are only going to be thirty two bit still	['memory', 'type', 'parameter', 'a struct', 'code', 'address', 'pointer']
right so what do we notice first of all that my code over here on the right really does need a mutex lock before we change value of x and we signal ok let's see why the problem occurs is when we call change at the same time that our second thread is actually called in this wait for positive x let's see where the problem could occur	['code', 'a mutex', 'thread', 'code', 'a mutex', 'thread', 'code', 'a mutex', 'thread', 'code', 'a mutex', 'thread']
right so with this in mind i think it's time to fill in some code here but there's one thing we haven't talked about up here so i said that our tcp server only needs actually two network calls which is true but in practice there's a third one that comes in very very useful and it's the following is this get address info this is a kind of swiss army knife of a call which can do all sorts of useful things for us and in particular is going to allow us to correctly set these kind of four parameters here for the socket and the network connection and also it allows us to not specify ip addresses directly instead we can specify domain names like illinois dot edu and get address info can convert that into an ip for address and even potentially an ip six address as well so we don't need to memorize a whole load of ip four and ip six addresses instead we can use these fully qualified host names and get a drink address info will convert those force	['the following', 'parameter', 'code', 'address', 'the following', 'parameter', 'code', 'address']
"right so with this in mind i think it's time to fill in some code here but there's one thing we haven't talked about up here so i said that our tcp server only needs actually two network calls which is true but in practice there's a third one that comes in very very useful and it's the following is this getaddressinfo this is a kind of swiss army knife of a call which can do all sorts of useful things for us and in particular is going to allow us to correctly set these kind of four parameters here for the socket and the network connection and also it allows us to not specify ip addresses directly instead we can ""specify domain names like illinois dot edu and getaddressinfo can convert that into an ip for address and even potentially an ipv6 address as well so we don't need to memorize a whole load of ipv4 and ipv6 addresses instead we can use these fully qualified host names and getaddressinfo will convert those for us"	['the following', 'parameter', 'code', 'address']
right the second thing that we'd like to change is this if inside here so in practice this can bite you in two different ways first of all maybe in other applications you have multiple threads calling this and we really just want to ensure their x really is positive before we continue and other things may change value x the second problem with this code is the actual deep condition wait is occasionally may suffer from what's called a spurious wake up it never truly went to sleep ok right so why does that occur well let's let's go back and talk about the implications for how conditioned weight is actually implemented right so we've just seen this problem of change in value of x and then signaling too early before they thread is actually blocking and waiting for that signal to arrive so in practice what does this mean it means that unlocking the mutex	['block', 'code', 'thread', 'block', 'code', 'thread', 'block', 'code', 'thread']
right which is what the child is doing here is happening inside a completely different process so it's not going to affect the parent process memory at all so even though the dress value of the pointer is the same even if you say looking at address ffff liberalizing resume what something that number actually correspond to a different piece of ram and that's the idea of virtual memory that the address space of a process is unique to each process this ensures that if one process has a security or so it has a bug in it then it just it can't just suddenly start reading or writing memory from another process	['memory', 'a process', 'address', 'pointer']
right, ok. welcome to the next lecture i want us to think about how we might actually write the c library. ok so maybe you don't like the license of glibc maybe you want to write a library that is a lot smaller or simpler so how can we actually wrap the low level posix interface that the kernel gives us an actually implement the c-level objects like the file so let's i would go at this right now you know about fopen where i can pass in a filename k blah blah blah but there's also function called fdopen where i can just pass in an existing file descriptor so if we write f d open it would be pretty easy to then also implement f open which just calls open and then we can delegate the rest of the work to this ft open call right so here's what we need to do then we're going to be given a file descriptor and we want to create one of these file objects now normally these are opaque structures normally as programmers we don't need to peek inside to see how they're working but that's not true today because we are actually trying to write the c library so let's have a go at writing the kind of simplest version that we might want and that's what i've done up here ok so this is what i want to put inside my file struct i need to store several things first of all yeah i definitely need to know about the low level file descriptor that i'm going to need when actually call read and write secondly i want to have some kind of buffer and the purpose of my buffer is to actually reduce the number of times that i'm going to call read or write so if you give me some bytes to write out by default i'm not going to be the center i'm simply going to append them into some space into some memory and so that's the purposes of my buffer now i need to keep track of how large my buffer is so that's the purposes of of my capacity the size of my buffer and i need to keep keep track of how much i've used so far so that will be the size inside here and the last thing we can do today is to say what kind of buffering do we ask you want it might be that we want to use this forever stream in which case we want the option of saying we don't want any buffering at all so as soon as you give me some bytes i want to immediately call right or soon as you want to read i'm going to read exactly that number of bytes or maybe i want to use this to rap a terminal so i want to use line buffering so i'm going to flush my buffer every time you give me the new line or maybe i want the best performance possible and so i want the largest amount of buffering possible so this is full buffering and will only flush when the buffer is completely fallen other words we've reached the capacity ok so let's some sketch out some code then of how we can use this right then so you've given me a file descriptor the first time going to do then is just create enough space for this struct ok so you can see we're already using typedef so i don't need to keep on writing struct so instead i can say right the	['memory', 'a terminal', 'type', 'code']
see we do with this lot so peter create and we are going to give it the address of this good and no attributes and we're going to say when you start a thread please start it this function and the initial value to pass in will be null right to do that twice and then let's just check for no copy paste errors so good tid one tid too great so we're not going to get down to line nineteen we won't get to the print f until both threads have finished right so now let's have check out their code what do we do well each thread is going to call my folks each thread has his own stack and its own value of i so if you wish you could kind of paint a little picture to say here's one stack and here's another white changes colors exciting so	['code', 'a thread', 'thread', 'address']
so accept will return immediately if there's customers which have completed their handshake and waiting to talk to you or it will block if there's no new customers ready to talk so you might for example write code where we'll put this accept inside a loop and will process one customer at a time and there is exactly what we're doing here perhaps in the future will write a multithreaded version where as soon as we get a valid return from accept we know we can start say a thread just to process that particular customer	['block', 'code', 'a thread', 'thread']
so accept will return immediately if there's customers which have completed their handshake and waiting to talk to you or it will block if there's no new customers ready to talk so you might for example write code where we'll put this accept insider loop and will process one customer at a time and there is exactly what we're doing here perhaps in the future will write a multithreaded version where as soon as we get a valid return from except we know we can start say a threat just a process that particular customer	['block', 'code', 'a process', 'thread']
so anything that you can do normally through many trades you can do with the other threads a quick comment here however is that many applications with a user interface put all of their ui code into a single thread required if you kind of modify the data structure that represents the ui interface you do it inside one thread so android does this qt and other frameworks do this the reason is for performance that if we kept on having to lock that data structure last potentially other threads would modify it then are you i would actually have worse performance so if you want to update the ui from a different thread you end up creating a message which you then have to synchronize and send to the user interaction thread took to process	['the data structure', 'a struct', 'code', 'thread']
so by doing that great i'm now going to read all the bytes but also i can get some heap memory as well so if taylors told me how big my picture is and i can read all of those bytes in one go just by calling fread hey if read this is the number of bytes i want please read it from that file so great i've read that file into memory and now i can write that as many clients as possible so we now know how to set up our socket remember we want a socket passive socket we're going to listen ip four address today and here's the new bit of code though just talking about we need set socket opt to be able to say you know what if i restart my process i want to be able to immediately connect to the same port number so how do we do that we can use this particular circle option called reuse address	['heap memory', 'memory', 'code', 'address']
so for example maybe we want to take some data out of out of data store one stick it into data structure to ok it doesn't matter particular which order that we released them in just for symmetry i'm going to do it this way but let's let's think about what happens if we lock these in a different sequence inside another thread so i'm going to have now another thread that does the same sequence of operations accept ha we have swapped these around the case so we swap these two lights ok so is this a problem	['a struct', 'thread', 'a struct', 'thread', 'a struct', 'thread', 'a struct', 'thread', 'a struct', 'thread', 'a struct', 'thread']
so here's here's an important idea that there's possible code that is necessary that only one thread at a time should be executing because in that moment inside part of that code is where we are updating some resource for example updating some data structure or updating a file in a critical way and it's important that no are the process or thread updates at resource at the same time so it's critical that we prevent other threads or processes from also being inside a critical section at the same time so lots of kind of examples and in the real world where there's there's moments in time where we only want kind of one person to be working on something at a time or save as a database you might implement a database so it's critical that only one process updates particular row at a time ok so you can imagine that if we were doing code review you might say hold on a moment there i've got a race condition here between say my implement incrementing i and when we actually reading the value of i in our previous code when we were taking the value of this pointer	['a struct', 'code', 'section', 'thread', 'pointer', 'a struct', 'code', 'section', 'thread', 'pointer', 'a struct', 'code', 'section', 'thread', 'pointer']
so his default of the game that we're going to maintain our idea of heap just using a simple link list and each link each node in my linked list data structure just represents a segment of memory that is either currently in use meaning it's been allocated or is available is free so we'll keep our linked list in sorted order and everytime malloc is called we're going to actually walk through that link list looking for	['memory', 'a struct', 'memory', 'a struct']
so how can we identify what can we do to ensure this and one way to do that is to put locks around our critical section code for example suppose you had some code from cs two twenty five that is going to say insert a link right on a data structure and this price is going to work in the linked list price is going to work on a vector and inside that code you realize that there's a moment in time where you're going to say of mess with the pointers or you're going to copy the entire data structure from us one sized piece of resource to say a doubling of the resources some other piece of memory over there ok so that's a critical section what we need to do then is to block any other threads that want to do a similar operation we want to somehow say right i want to give you exclusive access to this right now so the only you this comment thread is executing in this code gets too	['memory', 'block', 'a struct', 'code', 'section', 'thread', 'resources', 'pointer', 'memory', 'block', 'a struct', 'code', 'section', 'thread', 'resources', 'pointer', 'memory', 'block', 'a struct', 'code', 'section', 'thread', 'resources', 'pointer']
so if list_prepend was told in two threads at the same time that would be ok. each thread has its own stack and inside each stack it would have its own link variables be pointing to different pieces of memory life gets exciting! not when you try to use a parameter value, but when you try to use the actual data structure. it's this moment here when you read 'head', that we might run into problems. so you could imagine for example	['memory', 'parameter', 'a struct', 'thread']
so in our example code above where we called it with test one actually what's going to happen is that when we started programming and create a process that string literal along with the code that we've written here will be loaded into memory and so we know the very first bite of this little particular string here and so that's somewhere in memory so that's why she going to get to this function is the very first bite of that string ok so we need a way to walk through the string looking for each character ok so let me think about how to write this right now i'm just going to keep going around forever looking at each character in terms so i will just put a wild one here and we'll come back to this ok and let's have a look at the current character so i don't care about the actual address that we my variable holds i care about what's at that address i needed the cpus are full of the money to follow that pointer so i can do reference that pointer with an asterix so notice the aspects actually means two different things if it's in a declaration it means this is appointed to something	['memory', 'code', 'a process', 'string', 'address', 'pointer']
so let's go actually have a look at some code that does that another kind of useful trick is if actually don't care about using a particular port number just that you actually want to listen on any port that happens to be free then you can always pass in a port number of zero here remember that it's a string not a zero pointer to memory address zero	['memory', 'code', 'string', 'address', 'pointer']
so let's have a look at the code we vote we created a thread and the main thread can return and carry on there's no requirement for it to wait for that thread to get started but what do we do we immediately say ok now i want to block i want to wait until i'm able to join on the other thread so that means before we get to go around the loop before we add two hundred dollars and go round the when opoly board again right before we get to say i plus plus in his eye lesson ten we have to run and complete the code inside my funk we have to read the value we print out we get the thread id self we print something out and return null and those steps have to occur in order for pizza joint to letters out of jail so we are extremely confident that i know for certain that my funk will finish this execution before we get to use another loop ok so we've made shell program completely terministic but at what cost yes ladies and gentlemen we've written the most complicated version of printing out the numbers from zero to nine by creating threads and each waiting for each thread in turn to finish so now we've lost the performance of having a multi threats because we've only actually ever got one thread doing anything useful at a time either the main thread is running or is created in new thread to do one simple action and then that finishes and back goes the main thread in it or something again and so on so we had this kind of a hand over which is a	['the loop', 'block', 'code', 'a thread', 'thread', 'the loop', 'block', 'code', 'a thread', 'thread', 'the loop', 'block', 'code', 'a thread', 'thread']
so let's reacquire the mutex lock so that we know for sure that we're currently only one thread running when we are changing our variables we're going to think about who we want to wake up here and then will unlock the mutex so yes there are parts of my code where only one thread can truly be running at a time but that'd be for a very very short period just for a few microseconds for example and most of the time in this is actually going to be when we actually reading the data structure so for example consider a linked list or map or maybe something on disk actual reading and writing is going to be a lot heavier than take more time than the actual code that we've written here for our locks	['the data structure', 'a struct', 'code', 'thread']
so now they were both able to do this but what happens next ok i think we should choose a new color for this let's go for yes it's kinda extreme pinky purple thing let's try that ok right so now what happens thread one says i'd like to lock this mutex but of course what	['thread', 'thread', 'thread', 'thread', 'thread', 'thread']
so now those exist so now when we run it it gives us a non null path it went into someone when it is up two and then i said ok now i need to find a parent now you find that so great is given me canonical paths let's start talking about how we can use this for something like a file server so which is part of a web server how can i make sure that i only serve content from my web directory i don't want to start this happily sending the contents of arbitrary files ok so for this i'm going to make use of two other things i'm going to use ass printf and also straw compare but not destroy compare but stewart end compare so we'll see how these are useful so remember that if you call sprint app and nothing is going to appear instead you give it some memory you say ok here's some memory on the heap that i've already met locked and please write the string into their so for example if i wanted to construct path like i might say ok look at percent air some centers and this might be say the the root of where i'm storing all my files and the request from the user of to what particular resource they want that's great but i better make sure that this string that construct is no bigger than the heap memory that i required perhaps i just want to be lazy and say hey predict can't you	['heap memory', 'memory', 'the heap', 'printf', 'string']
so now those exist so now when we run it it gives us a non null path it went into sub one went into sub two and then i said ok now i need to find a parent now you find that so great is given me canonical paths let's start talking about how we can use this for something like a file server so which is part of a web server how can i make sure that i only serve content from my web directory i don't want to start this happily sending the contents of arbitrary files ok so for this i'm going to make use of two other things i'm going to use asprintf and also strcmp but not only strcmp but strncmp so we'll see how these are useful so remember that if you call sprintf nothing is going to appear instead you give it some memory you say ok here's some memory on the heap that i've already malloced and please write the string into their so for example if i wanted to construct path like i might say ok look at percent s percent s and this might be say the the root of where i'm storing all my files and the request from the user of to what particular resource they want that's great but i better make sure that this string that i construct is no bigger than the heap memory that i required perhaps i just want to be lazy and say hey printf can't you	['heap memory', 'memory', 'the heap', 'printf', 'string']
so one one of the thousand basically so we don't expect the css significant performance impact because of two threads updating this however if our code was different if we had threads which say wanted to update the data structure ten milliseconds out of one hundred million seconds so now there's a one in ten chance that the lock that we asked for is is already in use	['the data structure', 'a struct', 'code', 'thread']
so one one of the thousand basically so we don't expect the css significant performance impact because of two threads updating this however if our code was different if we had threads which say wanted to update the data structure ten milliseconds out of one hundred milliseconds so now there's a one in ten chance that the lock that we asked for is is already in use	['the data structure', 'a struct', 'code', 'thread']
so one one of the thousand basically so we don't expect the see significant performance impact because of two threads updating this however if our code was different if we had threads which say wanted to update the data structure ten milliseconds out of one hundred million seconds so now there's a one in ten chance that the lock that we asked for is is already in use	['the data structure', 'a struct', 'code', 'thread']
so right now yes we have a small opportunity a chance that our second thread will deadlock how do we fix it by locking on the same mutex because then the only way that you can continue is after the threat has acquired the mutex so another thread will have to wait so now if we do that it becomes impossible to be executing these two lines of code at the same time that these two lines are being executed	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
so that is a limitation of function here so in fact if i type c w p w for present working directory that internally is using this gets cwd command so there it is actually part of the standard library and we can either pass in some space or we can pass in null and it will allocate it on on the heap	['the heap', 'type', 'the heap', 'type']
so the first thing that jumps out to me is a pattern stroll end of of malaquais hold a moment that is not going to be the night right number of bytes to hold a string i would at least expect this to be ok take the string message and add add one to it ok so what does this code attempting to do here it says hey i've got a pointer to someone elses pointer so let's look at that let's look at that point and if it's not initialized to anything in other words it's just looking at null then our plan will be to change their pointer to look at some knew heat memory	['memory', 'code', 'string', 'pointer']
so the same thing applies for our fault based systems and we are kind of at the lowest level saying hey i want to send a block of data tool for my device so why do we make these same size is my virtual memory is because think back to our virtual memory table where i needed to have a mapping from virtual addresses to physical addresses and the very first thing we did is we took our	['memory', 'block', 'address', 'system']
so the same thing applies for our file based systems and we are kind of at the lowest level saying hey i want to send a block of data to and from my device so why do we make these same size is my virtual memory is because think back to our virtual memory table where i needed to have a mapping from virtual addresses to physical addresses and the very first thing we did is we took our	['memory', 'block', 'address', 'system']
so we could actually think about the state that positions in this state space of possible states my two processes which actually correspond to when things get stuck in other words when do they correspond with circle cycles in my weight for graph and what we would discover is that they all interior points on this particular graph right so if example process one didn't do anything but process two acquired all of the resources and then release them and then process want acquired all of the resources it needed and then release them we've gone around the edges where says if i interleaved my two process process the two processor or thread operations then i'm trying to take a more dangerous path through the middle of this and some of these points i'm going to get stuck at i cannot continue ok so what does the lyrics do does it attempt to kind of look at what states in this state space	['thread', 'resources', 'thread', 'resources']
so we need to be able to get a process that line before we call get line again so we do this for for performance because we don't want to have each time go back to the heap and say hey heap i need some more memory for another line instead could be a lot more quicker to run if we can actually just overwrite the heap memory that we already requested	['heap memory', 'memory', 'the heap', 'a process']
so what we've got then is kind of long hold of the mutex lock inside my enqueue here so my concern is with this same wait what if i have a thread calling nq another those is produced an item wants to queue it up and we call some weight but i don't have any space left inside my data structure here in other words what if s one is zero we might have a problem here because now	['a struct', 'a thread', 'thread', 'a struct', 'a thread', 'thread', 'a struct', 'a thread', 'thread']
so will have some kind of tweaking there to decide some parameter in there to decide what point what's our threshold going to be that we want to create a new block ok right so let's go back and see if we have these questions alright so we talked about block splitting and false presentation and the last question for this little video is our is our implementation using an explicit or implicit link list so this implementation uses an explicit link list meaning that we are throwing pointers around were writing a lot of code that uses memory addresses explicitly we can talk about the memory address of p we cannot talk about members of chosen we could talk about the memory addressing turn to my lock so	['memory', 'block', 'parameter', 'code', 'address', 'pointer']
soapy said mutex lock and as luck would have it i've already got my variables up here ready to go right so let me call peter mutex lock on my mutex there we go so that might block for a short while if someone else is currently acquired the lock which is why a later on we are going to release it	['block', 'block', 'block', 'block']
some weight does not block at all for either thread and both threads were tried to insert at the same time so they both for example might see the same value of in or this plus plus is not atomic so we may not successfully increment the value correctly so we need to make sure that only one third of the time runs out and the perfect answer that it's a mutex ok and similar over here i can't have two threads trying to remove at the same time so if i cared about performance might actually use two different mutex locks here so this is my pthread mutex lock and simply over here i can use a different lock because these actually are going to occur different parts of my data structure so i've actually got two different kinds of concurrency things i'm worried about here one is the size of my buffer and i'm using the the counting semaphores for that and the other is a critical section and i'm using a mutex locks to protect that	['block', 'a struct', 'a mutex', 'section', 'thread']
store error and that gives us a string ok so we'll be seeing that in the actual code that we write also realize that if it returns a non zero value then it means it never actually found as a way to connect and so that result pointer probably hasn't been changed so just assume that it doesn't point to anything valid right ok some other things you need to know so i mentioned ip four or thirty two bit addressing scheme that today if you were to pick up a random packet would discover it's an ip for based packet but we're trying to transition over to a more flexible addressing scheme which is much larger so today we would like to use ip six but is not fully supported by all routers yet so	['code', 'string', 'address', 'pointer']
str error and that gives us a string ok so we'll be seeing that in the actual code that we write also realize that if it returns a non zero value then it means it never actually found us a way to connect and so that result pointer probably hasn't been changed so just assume that it doesn't point to anything valid right ok some other things you need to know so i mentioned ip four our thirty two bit addressing scheme that today if you were to pick up a random packet would discover it's an ipv4 based packet but we're trying to transition over to a more flexible addressing scheme which is much larger so today we would like to use ip six but is not fully supported by all routers yet so	['code', 'string', 'address', 'pointer']
student now smarter than the internet ok so we can prove we can show the circumstances in which deadlock is can occur this actually see if we can actually see that occur if we actually run this code in practice so here's here's the same code that i prepared earlier i wanted to get out of this and go to handouts but code	['code', 'code', 'code', 'code']
that we are in the matrix log so we could reason that we are the only thread that continue to run so great i've got all these other threads running at the same time but my head doesn't need to explode thinking about the possible interleavings of all of these expressions from this thread and another third because we own the mutex lock right and anybody else has to wait until we finished so it simplifies reasoning about this back down to just simple single threaded code again alright so great we've got our push method to work	['code', 'thread', 'code', 'thread', 'code', 'thread']
that we haven't closed resources so this actually security problem that it might work once or twice or ten times but we're leaving a file descriptor open and eventually will run out of spare far descriptors for process and then opening files or calling opened are won't work in the future we don't have any spare file descriptors left ok the other thing that we might comment on if we were doing a code review instead opened a could fail so if this returns null for example there is no current directory 's kind of a little bit bizarre but we could imagine that happens for example someone 's deleted the current direct current directory then this open durcal would return null so we're not actually checking for that ok and by the way in case you didn't notice look we're doing this trick to hear to say ok i know that i've finished reading the current directory when this is called to read returns null that's when i know where there's no more entries left to fight but the biggest idea here is that we didn't clean up ourselves we didn't always release resources so always check your code your system programming code to make sure that in all code paths particularly error code paths you've released resources as soon as you finished using them ok and this will correspond to file descriptors to memory to any other resources to tcp sockets etc etc etc right ok so	['memory', 'code', 'resources', 'system', 'memory', 'code', 'resources', 'system']
that's the purpose of this address of operate say tell me where something is because maybe i want to write something directly into that those memory locations right so that's going to pass in the address of my global and also the value of ten meanwhile there's going to look inside f one because our challenges to work out which one of these lines will actually which one or two or three of these lines will actually print out an address in the stack ok so our first contender is going to actually print out the address of v one what is v one is a parameter of this function ok our second will print out the address of v two and the third book has a typo is fixed that let's make that actually print out v two so we will fix that line ok so let's go in and look at our code here right	['memory', 'parameter', 'code', 'address']
that's where we're going to make our change so we know we just changed it we know that's actually going to be heap memory so into that heap memory we're going to ask a straight copy to copy the following following so in two three four five six seven do we have any characters that let's see one two three four five six seven eight nine ten oh we have a problem we actually going to copy eleven bytes because the zero bytes so if we wanted to make this code work with change this to eleven of course in real code we would actually not hard code this value of figure out how you could use size off in order to avoid this ok so how can we make our code down here actually put this out right so let me kind of show you something that's surprising that we have	['the following', 'heap memory', 'memory', 'code']
the first thing we passed the printf is a format string and so we can do things like percent s or percent d to talk about hey the parameter is going to give you next are going to be a string so here's a pointer and that pointer that i give you i want you to start reading those out as a sequence of bytes or here's a value i want to treat that value and put it out as an integer so forty two for example right and those will appear on the shell or to standard out there other versions of printf which maybe will be useful to you i'll just mention them we're going to do it today but there's asprintf and sprintf which allow you to print the result into memory somewhere and then there's fprintf which allows you to send the result out to a file or some kind of file so it could actually be standard out so if tomorrow i said hey no more fprint for anybody you could immediately turn around and use fprintf instead	['memory', 'parameter', 'printf', 'string', 'pointer']
the first thread thread a could could start up exit and main thread could join on that we could print out an exit before thread b has a chance to start this would be particularly true on sale really busy system or a system that's only got one cpu core are poor threadbear it hasn't had a cpu scheduled yet and so our main thread is done before it he has a chance to start up ok right so all those those as possible if we modified our code so that we included p three exit on the main thread then you know that that means that because we are never returning from maine now our program is going to run until both those threads finish so now we expect both the bc to be printed and the xyz to be printed though we can't actually say definitively what order these two things can print we can make a guess as to which ones more likely but we haven't actually	['code', 'thread', 'system', 'code', 'thread', 'system', 'code', 'thread', 'system']
the last entry is actually a linked list entry have my next pointer and that will be null so if you're writing kind of code very lazily or just wanted short simple demo code we can ignore the fact that it returns multiple entries but if you want to write robust code then realize that there may be more than one way to connect to the server for example perhaps the server offers an ip four address and an ip six address so you might try both you might try one after another or you might create a whole lot of threads and do it asynchronously and see which one actually kinda connect faster ok so let's	['code', 'thread', 'address', 'pointer']
the last entry is actually linked list and trees have my next pointer and that will be no so if you're writing kind of code very lazily or just wanted short simple demo code we can ignore the fact that it returns multiple entries but if you want to write robust code then realize that there may be more than one way to connect to the server for example perhaps the server upper offers an ip four address and an ip six address so you might try both you might try one after another all you might create a whole lot of threads and do it asynchronously and see which one actually kinda connect faster ok so let's	['code', 'thread', 'address', 'pointer']
the number of words and the number of characters as well and if i wish i could actually just say ok only tell me about the number of lines that you see so yeah great we've confirmed that we manage to make a hundred threads and each one of them was responsible for printing out one thing now you might have guessed that my laptop here doesn't actually have a hundred cores so the operating system cheats virtually we can pretend that we have a hundred different cpus running but in reality what happens is that my poor little two or three or four cpus i got inside this machine actually going to be asked to keep changing from one thread to another thread so when a thread makes does something which blocks for example it cause sleep for example it cause read or write and those operations may take a while because there's no data get ready or is unavailable to send the data yet then will assign the cpu	['block', 'a thread', 'thread', 'system']
the race the critical section took one millisecond dirt to run if you're critical section was much smaller than that for example in the code that we've just looked at with the push in the pop or adding another part that might only be orders of say ten microseconds so now the chances of of of threads being inside the critical section is actually slimmer so discovering problems just by testing is hard and that is why we do things like locate don't want it with two threads but when it with four threads now it's much more likely to occur or test it with a brute force loop trying to go into the critical section as often as possible and now you've increased the chances significantly this also applies to the idea of lock contention so lock contention is not a good thing it means that one thread is being forced to wait for another now we did this because we want programs to function correctly	['code', 'section', 'thread', 'code', 'section', 'thread']
the solution we actually describing all the way is called like the base and bound where there's a mapping simple mapping from your virtual memory addresses we add some kind of offset offset that will be the base to get to the actual physical address or inside my ram and then we also put some kind of bound to make sure that addresses inside your process contract pieces of memory that don't don't don't that not your concern not sort of your process alright so this is not a great it's only advantages that was simple describe and also simple to implement in silicon and gives us a little bit of protection between each processor your process can't overwrite my memory well maybe we can do better than that ok so one thing to notice is that actually in my address space over here i've got tons of addresses loads of address numbers which i just don't care about they are not being used right now they're not part of the stack not part of the heap are never need to refer to them and in fact we could even go further and say look this part of my program code like the initialization code that i	['memory', 'the heap', 'code', 'address']
the string associated with a particular error number like one two three four five etc etc etc ok but perhaps you want to know what is actually just gone wrong with your program and so if you want to find out the air associated with a recent system call guess what there is something called ever know urdu there we go so i could say please tell me	['string', 'system', 'string', 'system', 'string', 'system', 'string', 'system', 'string', 'system']
the these string associated with the most recent system ever ok so in fact we could re implement pm so if we needed to write kind of piero ourselves we might do something like the following we might say ok so peer error i just want to print out to standard error	['the following', 'string', 'system', 'the following', 'string', 'system', 'the following', 'string', 'system', 'the following', 'string', 'system', 'the following', 'string', 'system']
the threads i'm joining on has finished as quick and then i can continue so please join can block right meeting that hey the cpu is no it is not going to do anything on my program for potentially along time and in fact the colonel will give that cpu to another thread that would like to run or tell that can't cpu core to shut down and go into low power mode ok so pthread can take a long time right now how do we say if we actually inside a thread hey i'm done i don't want to do anymore ok so for this we need to say i'd like to exit please so : pthread_exit right so the peace road exit is the last thing your thread will ever do there is no return from p thread exit it's done your cpu causes ok i'm going to wash my hands of this thread i know that there's nothing else is going to happen so p thread exit is a one way ticket do not try to execute anymore code after p calling p thread exit right so if i've got my little function let's call it say mine to continue that silly idea at some point i wanted to quit so i would call p thread exit by the way if you return from that function in other words if there's no more stack frames then that is equivalent of calling p thread exit so i might have some code in here this might call other functions called air from that cause g and that cause premier fanatic or something else etc it opens files whatever	['block', 'code', 'a thread', 'thread']
the time between actually testing whether it is null and changing it we don't we don't want to be interrupted during those times there's a second question in here as well however which is how do we generate a character based error message here string called terror former number we're using something called store error i wonder if this is safe to call for multiple threads at the same time and of course one of the reasons that we kind of suspicious about this	['string', 'thread', 'string', 'thread']
then maybe we could call pizza hut conditions signal as well but i would have to be a lot more careful about reasoning about that so i'm going to use p thread condition broadcast just in case there were multiple threads gone to sleep we want to make sure that if we're only going to wake up in that transition that we work them all up so	['thread', 'thread', 'thread', 'thread']
then the bank side my bankers algorithm can ensure that the bank never goes into an overdraft right and never we never allow our process is to continue so that so that there's a possibility that that i would resource i would exhaust the resources for certain type so for example if i have one hundred days and i know that my process two and my process three and so on only ever going to	['type', 'resources', 'type', 'resources']
then you call pthread barrier initiate you pass in one of these type and you say how many threads need to arrive at this barrier before we let them carry on so for example that let's say that i'm going to say write five threads need to arrive at this barrier and when we finished there's also destroy method as usual so how do you say that my thread should wait and is arrived at the barrier easy call pthread barrier wait and at that point your thread will block and it's going to block until in this case for other threads also called p thread barrier wait on the same object on the same barrier right so now i can start holota threads work on my matrix download different files and as each one continues finishes their little task they can call preferred barrier and will know that they will get stuck in there	['block', 'type', 'a thread', 'thread']
there we go so if there happens to be someone sleeping in on this condition variable because that waiting to pop then now they can wake up so we could for performance reasons a little bit more about this and say the only time we need to do this the only possible time that someone could be blocked while popping from this away would be if the value of n was zero so in other words we have just increased it up to one otherwise there's no way that anyone could be sleeping right now so we could weight using about that and we could also reason that we've just added one thing	['block', 'block', 'block', 'block']
there's no possibility of deadlock right now that for every same weight called we call assam post ok right so what if we could have made it a little bit more complicated though and we said that same weight here is going to in order to continue i'm going to wait on this thread and then i'm going to post on some samples to an meanwhile thread two i'm going to wait on counting semaphore two and then i'm going to post on counting semaphore three ok and then some weight three i'm going to then post inseminate one ok if all my counties are forced to started off with a value of zero you can see that no one gets to play that all of my threads have got stuck that my first thread is blocked here waiting for the value for sale wanted change well someone will change down here but unfortunately thread three is blocked waiting for the count for sam three is waiting for pizza slice and were able to get that piece of sliced form it is waiting for sam post to be called by thread two but thread two is not going to give it that pizza slice until it gets a piece of slice out of counting semaphores s two and where will i get that only from thread one when thread one finally called stem post but that's not going to happen because thread what is still waiting for the pizza slice from thread three so now you see we've got this love triangle here between our three threads they'll never going to continue that always waiting for an event that's never going to happen so that's all example of deadlock we can construct lots of these varying bits of complexity usually we don't artificial construct them like this usually were scratching go ahead go why did my system come to a grinding halt and the other thing i want you to notice is that	['block', 'thread', 'system', 'block', 'thread', 'system', 'block', 'thread', 'system', 'block', 'thread', 'system']
there's two useful things you can do you can say ok given some pointers and memory i want to initialize it to be zero to be the empty set of signals and the other thing i want to do is to be able to add a specific signal to this set so again i want to take a pointer to my mask and in this case i'm going to set single arm inside that single set so conceptually we can imagine that is just setting a single bit the one bit that happens to correspond to say sigler inside this integer value ok so once we've set this up we've we've initialized it and then added one alarm where using that to say ok sig block use this mask in other words if i wasn't protected against sell arms hooray i add now i've added it to their processes existing signal block i've also asked to find out what the original mask was so that presumably in a little bit i can reset the mask to what it was before i changed it ok so what should we write down here right so on my p thread call i want to say cig one my options for how i've got block unblock allset mask well it could be that the alarm signal was set before we even started so let's just rather than calling unblock let's call thread sig maggots with saying hey i'm going to give you	['memory', 'block', 'the mask', 'thread', 'pointer']
these guys will set up a little function little handler when that's called asynchronously but we're really limited about what we can do inside that we can't use of any code that calls malloc for example there's a very limited number of system calls that were allowed to use there's even the mutex locks the whole order stuff we just can't use inside our signal handlers why because we've temporarily interrupting our other code and that might be deep inside that other code already in that code is not re enterable so a better way to do this is to actually just have a thread that pulls off the next signal and it just behaves like any normal regular thread so let's see how we can use this here's the big idea is to use	['code', 'a thread', 'thread', 'system']
they prefer to think about units in a decimal system in other words in multiples of a thousand so you the correct way to write this today is to put a little small i after this for example like a kilobyte would mean one thousand bytes or a megabyte so that would be a million bytes as in one zero zero zero zero zero zero bytes however you don't be surprised if i'm the marketing materials the disk manufacturers conveniently forget to write the small i hear also if you're buying a modem we want to talk about bits then if i'm talking about say megabits per second the small b is used to represent bits not bytes so just watch out for those kind of little gotchas there and don't be surprised in the marketing materials if they really if we get to be accurate	['a megabyte', 'system', 'a megabyte', 'system']
this constant this little string so if i was to pause my process i would actually discover the upon running f one there's a memory copy that happens i read from this read only memory that's part of my text segment the actual things i've loaded from disk and i've copied that into the stack so there's one two three four five or six six bytes including the zero bite that have been copied into the stack and blah if i asked him as an address as a pointer would actually be hey i'm beginning of the stack memory where you'll find this this h so as a as an array i cannot change blood to point to other things it is disarray but i can use it as if it's a pointer but the downside however is that in this code but i'm returning blah and i'm returning it as a pointer so great we will find out the address of blob but the contents of that address is no longer about it it was on the stack and that stack value that stagnant is only valid while we were inside f one so that's the kind of common error in beginner c programmers is to accidentally give addresses or variables that are no longer in scope and are no longer valid	['memory', 'code', 'string', 'address', 'pointer']
this is not actual father spain stored on disk it's just the variable and it's the same idea with this this mutex lock its represents a mutex but it's not the attribute x itself ok see what else do you want to say right so you call peter mutex lock and we get to continue great what happens if another thread now calls peter mutex lock on the same object on the same mutex	['a mutex', 'thread', 'a mutex', 'thread']
this other block size up here tells us today about the natural size of blocks for the particular file system so if i'm going to use my read and write calls i probably want to make sure that the number of bytes i'm requesting is some multiple of that or at least that site in order to make sure that i'm efficiently using my file system so that gives me hint about that natural size of read invites	['block', 'system', 'block', 'system']
thread of the time alters our data structure. or if we are modifying a data structure another thread can't read it. ok so let's get started. let's there's a little warm up have a look at some multithreaded code that i've written to download two things at the same time so this is what we got so far here's my main method i'm going to use two p threads today so we can see i've got two thread i ds and when i call pizza hut create i'm going to pass in the address of my two little variables there and i was saying ok p thread please create a thread for me and i wanted to start with my download function that i'm going to pass in a string so my first new thread is going to be given this string and my second youth thread thread is going to get to this this other string so as you can see we're dialed loading some pirate resources from the web right so let's kind of look at my download function here it is so it's going to be given a url and	['a struct', 'code', 'a thread', 'string', 'thread', 'resources', 'address']
thread will go back into peter condition wait and block again so that's what we're doing is we're just say i don't want to repeat any additional logic in here just wake up somebody who might care and simply we need to do that down here where after we've dated the i plus once data structure we better call p thread condition broadcast ok so enough of sketching this out let's actually have a look at some code ok and here is my code you'll see that it's actually littered with a few extra things that now i actually got another thread that is actually going to be displaying what is going on and we can see whether particular i thread has managed to lock mutex locks so if it gets dark inside this moment here it will be stuck on lock	['block', 'a struct', 'code', 'thread']
threads word acquire the left hand lock that was interesting is that right now i'm recording this so one of my cpu cores is busy capturing the lecture content the video content so i was actually surprised that so quickly run into deadlock the other thing that i did to try to make it more likely is i'm using micro sleeps too actually sure that we have an opportunity for deadlock many many many more times in the original provider coded only tested this with sleeps for eight seconds or so over forty second window so opportunity for deadlock is is only handful of times order of ten times or so we would like it to be much higher alright so yes i have i can run it in slow motion let's see how we do that	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
time to broadcast however this is kind of a optimization it's very easy to get these wrong it's very tricky to start modeling thinking about this when you've got multiple threads which might call pop of multiple threads which might call push gets a little bit easier to think about if you've only got one thread of each kind so my advice is treat these optimizations with extreme caution you're introducing possible edge cases which not easy to discover or think about and so if in doubt	['optimizations', 'thread', 'optimizations', 'thread', 'optimizations', 'thread', 'optimizations', 'thread']
two counting semaphores and will see the s one is initialized to two hundred and fifty six so this smells to me like some kind of capacity counting thing which is going to go down as we started add things and as two is initialized to zero so s two sounds to me like it's going to be counting the number of items in ok let's touch you have a look at the code then for my enqueue and dequeue or nq and deck so i see i'm going to move text lock ok so that's good so that only one thread at the time can be actually inside this code and in fact for this particular implementation is chosen to use the same mutex lock for both the nq in the dequeue ok but i do notice inside this implementation is that normally what do we do normally send post so the same way it happens first and we normally only have the mutex lock that wraps the buffer call as well so yeah	['code', 'thread', 'code', 'thread', 'code', 'thread', 'code', 'thread']
underflow that because we said we've incremented or pizza box by one even though we had actually put anything into the buffer yet right so is underflow possible will actually in this particular implementation no because my dick you cannot complete until the mutex lock is released because it is required before actually touching the buffer if this code tried to be a little bit more performance by giving the nq in the dequeue different mutex locks then we would have run into a problem because then we would have allowed a dq thread to try to read a value from the buffer before we've even put the value in right so better code of course would actually only increment the counting semaphore after we modified the buffer so so this line actually belongs down here so do this later ok and we can do it after we've released a mutex lock ok	['code', 'a mutex', 'thread', 'code', 'a mutex', 'thread', 'code', 'a mutex', 'thread']
update the ui somehow in other words take my array of pixels which is just a big block of memory inside the heap and displayed on the screen so how do i do that i do the following let's take a tape why mask it with the value fifteen so in other words i only care about the lowest four bits and if those lowest four bits are equal to fifteen then display the ui ok so providing my screen size is actually some multiple of sixteen then i'll make sure that i update this every sixteen roads and i also updated at the end if it's not some multiple of sixteen then i should call update gui a one more time before exiting or before finishing right so let's have a look at this this actually have a play with this ok so i've compiled already i've got a little make file here	['the following', 'memory', 'the heap', 'block']
update the ui somehow in other words take my array of pixels which is just a big block of memory inside the heap and displayed on the screen so how do i do that i do the following let's take a tape why mask it with the value fifteen so in other words i only care about the lowest four bits and if those lowest four bits are equal to fifteen then display the ui ok so providing my screen size is actually some multiple of sixteen then i'll make sure that i update this every sixteen rows and i also updated at the end if it's not some multiple of sixteen then i should call update gui a one more time before exiting or before finishing right so let's have a look at this this actually have a play with this ok so i've compiled already i've got a little make file here	['the following', 'memory', 'the heap', 'block']
use that file descriptor again to fill out this truck for me ok so these two do the same thing it's just a witcher matter of convenience as to whether you know the path or already have a file descriptor to an open file there's one other version is as well here which is going to leave a little bit but we're going to find that useful when we start talking about symbolic links so let's have a look at the kind of information that we can get back from stat ok right so the system gives us the following struct we can use and big important idea and we seen this multiple times is that ok we're going to give a pointer to struct so we're going to write things like ok here is a address of say some staff that some struct that we've got on our stack or somewhere else it's only going to fill out memory structure force if stat returns success so it's very important to be able to check that it returns ok so if it doesn't return ok ie zero then you can just assume that that memory structure was never touched in south the values inside that memory structure that is going to be arbitrary wait ok so let's see what we can find out about a file first of all great you can actually find the i node number and notice that all of these fields inside my struct start with the sd which is just short for stat ok we can find out some protection information about it so the	['the following', 'memory', 'address', 'system', 'pointer', 'the following', 'memory', 'address', 'system', 'pointer']
used by the process and also possibly the amount of cpu time that is used in more recently is perhaps the last kind of time segment also process may be running or not perhaps we've temporarily paused it for example we running inside the debugger or we sent it a signal to stop it well we finished so we have a process a state diagram that we can describe how the running status of all processes change then we got things like constraints which is part of our security model to make sure that one process can't take over all of the resources inside our system and you can often modify any of these constraints using you limits so for example we might want to limit the amount of processes we can create for particular user or the amount of memory that our process can have that kind of thing or even the number of file descriptors we also have meta information about whether we care a lot about a particular process or thread we can give them different priorities so if you have a thread whose goal is to keep the steering wheels pointed in the right direction that's probably a pretty high priority thread and it should be given a cpu in priority compared to say something which is going to download an update off the internet	['memory', 'a thread', 'a process', 'thread', 'resources', 'system']
versus rpc what have we seen we've got things like marshalling and that can unmark sling and that can include changing bit representations marshall link there so we've got modifying representations we've got pausing we've got oh yes we've we've got we got to traverse data structures and which potentially involves many cache lines or what you're reading or writing to main memory we've also got ever handling as well so even if we don't take those branches there's a lot of branching code including in this we've got potentially authentication an authorization authorization to do as well so this is authentication authorization session handling so if we discovered that the remote connection is no longer good we might automatically reconnect as well so the complexity of our curls is about a hundred to a thousand lines of code at least compared to a simple local call which is perhaps one expert and i forgot one more thing as heat memory as well we might need to do some memory allocation and deallocation so	['memory', 'memory allocation', 'a struct', 'code']
vitus will win and continue and the others will wake up but then they will see that the somebody writing so they will go back to sleep ok so this is the most performant code but we're pretty confident that we released we always always going to wake up all the writers once we've we've got the active readers out of here so let's type i think about the writers again i could just wake up everybody the code will certainly function like that but the cost but there's a cost there's actually pay for the cost twice because now you're asking this system to signal many many many readers of writers and secondly i think about what all those threads are going to do you've woken them up but they're all going to test their conditions for example is although no writers around and then they just might go back to sleep and so we just wasted cpu time evaluating something that we could have reasoned must be zero	['type', 'code', 'thread', 'system']
wait is that the way we rounded let's check yet the attributes yet and now we need the function pointer the address of my function that likely to start ok so i could just type hello it is actually possible to it ampersand hello and the c compiler just ignores the ten percent so that's hello hello parentheses otherwise you'll be evaluating you'll be calling hello on the main thread and that's not what we want we actually just want the address of a function ok and what would we like to pass into hello	['type', 'thread', 'address', 'pointer']
wanting to touch be but no it's stuck on the outside looking at this box can i really want this but i'm being forced to wait because process one has exclusive access ok so that's the beginnings of a resource allocation graph or rag right and you can see the process to cannot continue right now it doesn't have everything it needs and we can actually say oh look it's stuck because it's waiting for resource be and the reason we can't get it is because process one is still running right so do we have deadlock well no we don't because we can see that process one isn't actually waiting for any resources yeah sure it's being a bit slow and finishing up but there's no reason for it to actually run forever so at some point it's going to finish and when it does so it can release these resources ok so delete that line and we delete that line so we can now see that process too and no longer needs to be waiting for the mystery source be and so we could raise the at and turn that back into a line that's looking at it and say ok great now process to has everything it needs it can continue so if we were writing code you can imagine our call to peter mutex lock has finally completed or access to the reader writer data structures finally given 's ability to read that so great we can continue right so eventually process too because it has all the resources it needs can continue as well we don't care how long it's going to take all we can say is for sure is that there is no deadlock ok so in this case no and no alright so that was an easy one join me in the next video when i look at a more complicated one alright see you then	['a struct', 'code', 'resources', 'a struct', 'code', 'resources']
we could handle that and exit or something right so if there's no no real to memory we better stop otherwise hey let's update our data pointed that key and you'll notice i'm not writing any kind of casting in here so i was some people traditionally like to put casting here 'cause we're changing the type from a void pointer to a double pointer in practice i found i don't like to do that i think it's necessary and be leads to more visual clutter when the most likely mistake is to accidentally request the incorrect amount of memory so i had much more other kind of like this coder stand out where we actually think about the exact number of bytes where we are requesting ok so that's our example use of real ac it's very powerful it can be very fast to change the amount of memory allocated and it's a good little trick to learn so i'll see you in the next video bye	['memory', 'type', 'code', 'pointer']
we go over to main memory you will see he may maybe i need to read the following four bytes please ok we pull that into a cpu register then we invoke the arithmetic logic unit to add one to our register ok so we've recalculated new value and then we take that bit pattern and we throw it back towards memory here you go memory have a new value the adding one is extremely fast writing to main memory is extremely slow compared to what the cpu can do so of course practice we have levels of cash operating but let's	['the following', 'memory', 'the following', 'memory', 'the following', 'memory']
we have some kind of key or index to get a particular name ok and we are going to say return a character pointer ok so what might r r code look like for this right so i need to be able to send this key down and i also need to send which function i want to run on the remote side so i've got several choices here perhaps i actually i want to write to the far to script the actual name of the function that i'm trying to call so i could say get name and i could case so let's get name so that's going to be want to kind of seven characters right or perhaps i i want to have the name with some kind of termination character so perhaps the colon here so would send eight characters and i also need to send my parameters so that's easy right now i've just got one parameter but i still need to choose exactly how if i wanted to send it in a binary format i could send the bites at mikey here and of course the size of that data structure	['parameter', 'a struct', 'code', 'pointer']
we instead passing nothing what happens if we pass in address zero so we need null know that this is equivalent to memory address zero what are things going to happen so the exciting thing here is that actually when our process runs our memories divided into different segments some parts of it is read only so for example the actual code and the string literals in the other constants that we might declare inside our function i have to be loaded into the process but that is put inside read only memory and if you try to write to that memory you can't your process will actually actually stop with the segmentation fault other parts of memory just simply do not exist yet we can have large areas of memory dresses which are not mapped to physical ram other parts of memory will be mapped to the stack and other parts that will see later on the course ok so let's try this and see what happens ok right	['memory', 'code', 'string', 'address']
we know deterministically that we're going to get the values between a hundred and a hundred and nine those threads can run in an arbitrary order so the output is not guaranteed to be in exactly the same app or ordering that we actually defined it inside the code so let's have a look at kind of one more alternative here to make a program completely deterministic here's what i'm going to do i'm going to say p thread	['code', 'thread', 'code', 'thread', 'code', 'thread']
we read it kind of backwards so inside out from the variable if you use it inside an expression you're saying hey follow the money right now you're looking at an address so go and use the type to go and actually read what's at that address is an interview for bites or eight whatever it is if its character just read that one bite right so we can read what's there and we want to know is what do we find ok so we really one character so i'd like to check to see if i found it at how can i do that well perhaps i'm an ascii geek and i know happen to know that that is sixty value sixty four but that code is not very readable it maybe it's better to use oh no that's not right because that's actually a c string and so that would just give me an address instead what i need is a single quotes to say here's an here's an ascii character please convert that into an ascii value for me right so if that's found great we can stop looping around so now we can actually return one to mean success ok otherwise we want to go on a loop ok so next time i loop i actually want to look at the next	['type', 'code', 'string', 'address']
we use the page tables so we tracked through the page tables ok the upper ten bits tell me to use this table the middle ten bits time we choose this table and this is i'm sorry that doesn't correspond to any memory here's what we'll do we'll put the process on pause because we've just got a page fault and as i turn around look behind me will quickly fill in the background and so that i'll never know it was missing any pointers at this time and we're going to do the same thing in my process so what will do is will identify a piece of physical memory ok out of all of these let's choose this one this one doesn't seem to be doing much right now and we will say it's ok i know where the bytes are they are still on disk maybe it's on a network mount maybe it's on the local ssd but i have the contents of the program which i can load into memory so i will go to my i o systems say hey please can read me this page of memory four thousand ninety six bytes and will wait for that to complete so hopefully in just a few milliseconds time but it might take longer i'll actually have those bites now and now we can fix up our page table to say ok don't look at nothing anymore instead this entry is now going to be just here	['a page', 'memory', 'background', 'system', 'pointer']
we usually exact does not return usually with exact we provide a program on disk to load and that's the moment we give our poor little process ahead temp head transplant we've completely thrown away all of the heap memory order the stack no need to do free or all that memory has disappeared to be replaced by a brand new program it's the same process and will have the same process id and the same number of open files but now it's running a completely different program that is going to start from maine so hopefully you can now see that a very very common pattern is to call fork and then inside the child process we want to do something else we don't keep executing the same code so the child process will call exec meanwhile the parent process wants to wait for the child to finish	['heap memory', 'memory', 'the heap', 'code']
we want to implement things like copy on write an make it transactional we want snapshots we want clones we want to be able to send these snapshots from one disk to a different disk we want to be able to stripe physically i'm store our our data across different parts of a disk we want to have variable block size is we want to make it lightweight we want to be able to modify our cash we want even potentially different endianness for performance and of course you want things like deduplication encryption right so that's going to take awhile to write all the code to support about that and here's another one which another file system that then exports today yeah we want space efficient indices and packing of very small files while being able to support very large files we don't want to have to make choices at format time how many i knows we want again we want snapshot beat your vest has checksums to make sure that the data and the metadata or can still correct we want different compression algorithms	['block', 'code', 'system', 'block', 'code', 'system']
we were passing in a pointer to that memory so yes of course they can access heap memory and you could even create that heap memory on a different thread there's nothing special about the main thread other than the fact that if it returns then we exit the whole process so keep it to be shared i could have written malloc inside a different a different function all the things that i could do is i my main thread i could also do inside the other threads we notice like i even did right here i could have done printf here as well	['heap memory', 'memory', 'printf', 'thread', 'pointer']
we would end up writing something like this we would say right number of items that we actually want should be our parameter an items minus the half that the lower half that the first thread is going to do for us ok so that's taken care of a potential off by one hour and in this case we are going to pass in the data ok now we can use pointer arithmetic let's make sure that we're pointing to the right kind of thing we just want to offset by half so you could imagine writing this in a loop as well	['parameter', 'thread', 'pointer', 'parameter', 'thread', 'pointer']
we're going to skip on some details that make it a little bit more complicated but i'm going to write it just like this for now there's pass in the address of my condition variable and so again this is a bit like file handles that yes i have a variable in my code but actually refers to something else the actual object is not the variable so will write it like that and i'm going to skip over the fact that i'm going to act you need a little bit more than that but for now we can think of it as our condition variable represents a place where our thread goes for a little nap ok so please go into this little hotel room here for it in an hour long will nap and will wake you up when life is improved by life is better when it's warmer outside when you've got your cash when you've got your keys and we're ready to go ok so we're sending our slept a thread to sleep like a quick hypnotic trance off you go so it do not do not pass go do not continue	['code', 'a thread', 'thread', 'address']
we've got a little structure here called philosopher and you can see it's going to be typed deft so that we can just say philosopher later on inside that i'm going to have a pointer to the left fork and the right fork and of course a philosopher has a name	['type', 'pointer', 'type', 'pointer', 'type', 'pointer', 'type', 'pointer']
we've got again clearly that the amount of space is being a lot smaller but less anybody would do anything if the difference is actually significant so perhaps like if the old size minus the new size is greater than some threshold so what would that threshold look like good question let's say a thousand and twenty four bytes right so i would if this is production code i would definitely put that into a variable ok so in which case now we know we've got some spare space arm it's at least as big as a metadata and even after that is going to be useful so what would we do at this point ok so here's the kind of wonderful thing is that i could make a pointer to any memory i want and declare this truck there so i can say ok this is my my new entry here and that will be where my existing data ends so what would that look like well it might look something like this what do you think about the following i've got the existing entry entry we're currently talking about and i just need to go to the end so that would be	['the following', 'memory', 'code', 'pointer']
we've got this test here and then later maybe a few nanoseconds later but it might be a bit longer eventually by calling peter condition wait my thread is going to block so here's the problem scenario what if we had an interleaving of these operations such that changing the value of x here happens after this test	['block', 'thread', 'block', 'thread', 'block', 'thread', 'block', 'thread']
we've now got away to read in values and to efficiently use our heap memory ok the last thing we didn't do is too if you want to write production quality code let's see if we add up failed so i would have another pointer in here ok to see if	['heap memory', 'memory', 'code', 'pointer']
well if you were thinking along the lines that recursion unbounded can lead to a stackoverflow then congratulations you start to think like a security person here yeah so one problem with recursion is that if we never had a base case then our code will start to overwrite random pieces of memory that may be all crash but on these smaller systems it might just our stack might just keep going and start overwriting kind of critical values inside the heap	['memory', 'the heap', 'code', 'system']
were actually going to obviously return that address back to the caller so that they have their memory that they requested but the piece of memory that we found is probably larger than what was requested which means there's going to be some unused space at the end so let's change our link list let's add a new entry for that unused part so that future calls to malloc can potentially make use of that spare space	['memory', 'address', 'memory', 'address']
which would just increment the counter to now accessing the mutex changing the counter unlocking the mutex so we've actually added a lot more complexity in terms of number of structures that have to be executed for each iteration vanderloop ok so that wasn't didn't make a program any faster and in fact it slowed it down a bit just because we're using their lock in such a fine grained manner but it didn't sure that are two threads could actually carry carry on now and finish it about the same time so now we've got an interleaving of our two threads but we've ensured that the actual change of the data structure only happens in one thread or the other thread at a time	['the data structure', 'a struct', 'thread', 'the data structure', 'a struct', 'thread']
will continue the process will continue until all of the other p three s have finished so that's going to lazy way of saying i just wanna start all these threads and i'm just done when the last one turns out the lights and shut the door ok so that's kind of a little trick that you'll see in kind of many smaller p thread programs right so of my next question to you is i've mentioned quite a few but can you think of four ways that a thread can be terminated right are you ready go	['a thread', 'thread', 'a thread', 'thread']
will print out too and then we decrement it down to one again and then we unlock the mutex ok so the next step that comes out of here will only escape out of p three condition wait after we've unlock the mutex so it will also see a value of fireworks of one it also does a big forecast waking everybody up and most are too and so it will print out the value of two etc right and so on the next thread will come out check the condition for the while loop ok that is no longer true so it comes to an does the same thing increments it from one to two and then two to one and then unlocks the mutex which allows the next set to escape it checks the value and so on and so on so right so let's just kind of run this just to kind of prove it right so we have ok compiled it	['thread', 'thread', 'thread', 'thread', 'thread']
will run it ok and i'll type something like one two three and you'll see that great we've actually script off the new line an only printing that so and we can now use it as a c string so abc and we have abc and we have a longer string and we change capacity and potentially the address of a buffer ok so what do we got little get line demo so that's if you get line lots of kind of moving past it is to think carefully about but it's actually a very powerful utility that gives us a great performance because we can reuse the same piece of memory if you truly wanted to read these different lines into different parts of memory then one tricks you could do would be to reset buffer and reset buffer capacity back to their zero values and get line when you call it again would never know about those those earlier memory allocations that would be a little bit strange but you could do that so have we got great code yes not bad but remember we can actually improve things a little bit	['memory', 'memory allocation', 'type', 'code', 'string', 'address']
with one case i've got another value of c inside here which is ten and then change to eleven ok are we done no that was just for one thread ok so this is kind of the big important idea that's the whole point of this example is that we're looking at the stack of just one thread here but in fact we're going to start three threads so we have the same picture again for the second thread that we start and these could all be running independently so in fact i'm going to see the value of c nine times so we saw it three here and we know we got three threads down here another three here and then lower down in memory another thread that we started and we're going to see the value of c a three more time so each of those us stack frames because we have recursive function i'm right so that's a lot of c values and hopefully i've got the point across that even though we've just written this once inside our code we might see it many times inside a memory but wait you say i happen to know something about compilers i mean i happen to know this is real tail recursion and the compiler could have optimized this to actually just be a loop it could have changed value program and just gone around the loop and run again so in fact i wouldn't actually be there in memory three times well yes you're correct you could also say but wait the compiler can notice that sees never actually used and so therefore it could optimize it out completely and therefore it won't be in memory at all and you'd be correct again so yes we have to be careful about where they were talking about what truly happens when we turn on all optimizations and what happens with our simple model of how we compile c code to running code with that we're going to skip into the next video where i talk now about more exciting example where actually going to start working on a real problem and we are going to kind of generate manderbach pictures using	['optimizations', 'the loop', 'memory', 'code', 'thread']
would actually have to write code to cope with the fact that packets might go missing but this is useful if you want for example to provide an interactive feedback as soon as the user starts typing something into the search part you want to be able to display immediately some potential results so that sounds to me like udp might be a great course so if you're prepared to employ a lots of great system programmers from say from illinois then if you don't mind that expense then udp gives you a lower latency response and besides if you're doing this just for incremental search is you don't care anyway if you drop a packet because in a moment the user is going to be typing another character anyway and so you can reissue a new search based on that new information right but most packets today for http are using tcp	['code', 'system', 'code', 'system', 'code', 'system']
you could imagine where an interleaving of instructions where both threads see value of null because we haven't opened the file yet so both threads decide to call f open and then write that result into the single file handle the global variable there so that wouldn't be great we only want one thread to ever call ever open so that is certainly a critical section	['section', 'thread', 'section', 'thread']
you want to put out some errors ok so here's first way you've probably seen things like ok i can use p error to print an error to standard error and i can include piece of text here which gets included along with some standard string ok there's also if you prefer a way to get just a simple string and this is it you can say store error and i can ask for a	['string', 'string', 'string', 'string', 'string']
