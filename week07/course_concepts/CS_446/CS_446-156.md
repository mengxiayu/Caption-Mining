#CS_446
#lecture
[[std distance]]
[[quarter machine]]
[[margin classifier support vector]]
[[mistake f dimension]]
[[separator transformation]]
[[separator alot]]
[[debt transfer prediction label]]
[[separator affine]]
[[outlier tide chat]]
[[lagrangian loss]]
[[prime optimization]]
[[loss curve]]
[[recap separator]]
[[model prediction]]
[[machine learning loss]]
[[feasibility fee]]
[[wr claim optimization solution pair]]
[[machine learning]]
[[mistake separating prediction setup]]
[[inequality constraint]]
[[amount mistake]]
[[fun exercise]]
[[align appoint align]]
[[parameter role]]
[[setting exusia]]
[[organization lingo box constraint]]
[[optimization energy]]
[[margin principle margin]]
[[mistake penalty]]
[[objective star optimal]]
[[feed transpose fee]]
[[intuition mistake]]
[[outlier quadratic]]
[[reading mistake]]
[[rn xx prime]]
[[loss fee]]
[[fee transpose fee]]
[[transpose classification]]
[[fee transformation]]
[[separator mistake]]
[[margin nuance]]
[[descent std]]
[[separating hyperplane]]
[[mistake amount mistake]]
[[amount translation]]
[[index mistake]]
[[prediction matrix entry matrix separator]]
[[sequence simplification]]
[[classifier loss]]
[[fee thought]]
[[separating hyperplane sparsity]]
[[machine learning machine learning perceptron minimize]]
[[magnitude mistake solution]]
[[support vector machine kernel]]
[[replacement min]]
[[attention norm]]
[[dataset fee]]
[[solution tilde separation r]]
[[classifier discussion]]
[[notation bracket]]
[[constraint optimization]]
[[task summation]]
[[support vector machine pm solution support vector machine]]
[[trip solution]]
[[ws member statement classifier]]
[[predictor prediction model learner inference loss]]
[[substitution optimization]]
[[loss teaser]]
[[maximize minimum distance]]
[[penalty mistake]]
[[risk minimization]]
[[toy mistake]]
[[sample machine learning]]
[[loss nature]]
[[variety loss]]
[[amount committee lesson mistake]]
[[response prediction]]
[[magnitude distance mistake]]
[[norm part]]
[[prediction slack mistake]]
[[substitution replacement]]
[[solution literature]]
[[mistake quantity]]
[[learning task parameter]]
[[prediction robust]]
[[margin fme]]
[[lagrangian jewel]]
[[machine loss]]
[[times sample]]
[[crosse convenience]]
[[risk minimization loss]]
[[vector transpose]]
[[computation intuition]]
[[computing distance]]
[[angle margin]]
[[solver primal]]
[[setup isano]]
[[classification fee]]
[[support vector]]
[[training prediction training]]
[[task fee]]
[[prediction model concern loss label]]
[[vector machine]]
[[band setting]]
[[model margin]]
[[prediction lambda]]
[[penalty leisure prediction]]
[[support vector machine]]
[[support vector machine director machine]]
[[optimization setup]]
[[art trick]]
[[magnitude mistake]]
[[learning notation]]
[[feasibility part claim]]
[[mistake site]]
[[optimization loss]]
[[separator foot]]
[[parameter setting]]
[[jewel solution]]
[[matrix pair training]]
[[prediction slack mistake magnitude]]
[[mistake outlier]]
[[machine penalty]]
[[prediction transpose]]
[[transformation parameter prediction]]
[[norm scaling]]
[[kernel prime]]
[[squared penalty mistake]]
[[inequality constraint lender lambda]]
[[loss mistake]]
[[distance intuition projection]]
[[bout slack]]
[[capital prediction label]]
[[parameter equality constraint hinge loss]]
[[star tilde solution]]
[[dimension constraint parameter]]
[[classifier feasibility]]
[[task learning]]
[[optimization rescaling]]
[[formula transpose distance]]
[[loss distance]]
[[margin principle]]
[[transformation fee]]
[[parameter trick]]
[[background part]]
[[hinge loss]]
[[min norm]]
[[gradient quadratic gradient]]
[[solution support vector machine pivot]]
[[motivation support vector machine]]
[[loss label]]
[[margin part norm chat]]
