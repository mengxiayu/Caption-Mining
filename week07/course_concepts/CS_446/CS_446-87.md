#CS_446
#lecture
[[hinge loss hinge loss epsilon]]
[[reading ian goodfellow book learning chapter]]
[[regression multiclass]]
[[loss las]]
[[alex net]]
[[score probability softmax]]
[[convolution concept train]]
[[tensor flow]]
[[score probability]]
[[layer max]]
[[kernel nonlinearity objective]]
[[output image]]
[[output nonlinearity]]
[[net width]]
[[ton computation folk]]
[[communication gpus]]
[[layer subsampling]]
[[rgb image depth]]
[[net dimension net track output computation convolution]]
[[recap guy]]
[[kernel matrix]]
[[para meter convolution]]
[[max pooling]]
[[bunch symbol]]
[[professor clue anne]]
[[softmax layer]]
[[nose siri]]
[[kernel filter]]
[[machine folk]]
[[neural network]]
[[inference training]]
[[weight vector]]
[[hyperparameter search]]
[[recall convolution]]
[[filter hyperparameter stride]]
[[activation concept]]
[[acyclic graph]]
[[convolution layer]]
[[top loss bottom]]
[[train classifier]]
[[network architecture search nis]]
[[map dimension]]
[[net structure regard]]
[[matrix convolution]]
[[transpose colleague]]
[[computation graph]]
[[linearity shortcoming]]
[[weight classification]]
[[stride formula student]]
[[hat plus exponential]]
[[transpose fi ellis]]
[[classification net]]
[[support vector machine formulation]]
[[bias hyperparameter width height depth stride]]
[[task loss constraint]]
[[learning framework optimization]]
[[height width]]
[[output formula]]
[[chain manner]]
[[vector component signal shortcoming]]
[[task loss]]
[[acyclic graph output]]
[[package torch]]
[[meter output]]
[[support vector machine loss]]
[[machine learning expert]]
[[instance optimization]]
[[net image]]
[[assumption instance]]
[[node graph weight]]
[[support vector machine]]
[[node output]]
[[filter pixel]]
[[pixel boundary]]
[[bias sammy]]
[[filter hyperparameter]]
[[filter stride]]
[[network plant]]
[[limit exponential]]
[[height channel]]
[[layer convolution activation]]
[[leaf node]]
[[oftentime support vector machine]]
[[layer matrix multiplie]]
[[convolution net]]
[[regression los]]
[[colonel kernels mechanism kernel mix]]
[[competitor net]]
[[concept net]]
[[height depth]]
[[task weight classification concept]]
[[shortcoming formulation]]
[[output probability]]
[[max pooling ann]]
[[width image boundary]]
[[library graph]]
[[matrix multiplication net]]
[[wyatt output]]
