#CS_361
#lecture
[[attention algorithm track]]
[[basis degree hyperparameter]]
[[debug iteration]]
[[derivative mistake loss]]
[[connection union]]
[[descent algorithm]]
[[task accuracy]]
[[track radiance]]
[[part exercise]]
[[parameter learning amount]]
[[office dose notation]]
[[accuracy optimizer]]
[[neural network notebook]]
[[output layer]]
[[age prime]]
[[exponent shape curve]]
[[variance gradient]]
[[connection neuron weight]]
[[net layer]]
[[component exercise]]
[[overview chain]]
[[bunch optimizer]]
[[descent batch randomness]]
[[trouble office]]
[[descent algorithm thought]]
[[layer connection]]
[[net part assignment]]
[[neuron layer]]
[[shingle part]]
[[gradient descent sample batch]]
[[network part]]
[[badge batch]]
[[gradient descent]]
[[theory portion]]
[[perspective derivative]]
[[net network]]
[[gamma handwriting]]
[[grade scope]]
[[theory lowe]]
[[discussion reminder]]
[[gamma convexity]]
[[table exercise runtime]]
[[weight classification]]
[[iteration hat]]
[[batch amount]]
[[track gradient]]
[[connection weight]]
[[weight connection]]
[[derivative respect]]
[[descent truth]]
[[net optimizer]]
[[optimizer learning exercise]]
[[presentation guy]]
[[scope exercise]]
[[truth degree]]
[[net neuron circle neuron]]
[[support vector machine]]
[[weight connection classification]]
[[print option]]
[[neuron layer weight]]
[[connection neuron]]
[[gamma hyperparameter loss]]
[[layer neuron]]
[[moment vector track]]
[[loss layer]]
[[derivative e]]
[[exercise complexity]]
[[output layer category]]
[[weight connection neuron]]
[[student office]]
[[curve squared]]
[[assumption convexity]]
