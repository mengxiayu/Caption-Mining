#CS_361
#lecture
[[net statement]]
[[gradient descent batch]]
[[descent algorithm]]
[[spot gradient]]
[[part exercise]]
[[gradient dew gradient]]
[[reminder exercise]]
[[loss sample loss]]
[[item curve saddle]]
[[derivative loss]]
[[portion depth]]
[[default algorithm]]
[[output layer]]
[[announcement session]]
[[track gradient track]]
[[variance gradient]]
[[xj instruction]]
[[neuron output layer neuron output layer digit]]
[[derivative chain]]
[[curve momentum ball]]
[[objective optimization]]
[[trouble guy]]
[[guy chain]]
[[typo transpose xj transpose]]
[[saddle derivative]]
[[weakness optimizer]]
[[guy office exercise]]
[[reminder convex]]
[[output layer neuron]]
[[connection neuron weight]]
[[trouble chain]]
[[sample optimizer]]
[[variance gradient decay beta]]
[[decay algorithm]]
[[amount loss]]
[[e derivative]]
[[neuron layer]]
[[scope search optimiser]]
[[default setting]]
[[integer discreet]]
[[ticket xj statement]]
[[guy understanding]]
[[sample loss objective]]
[[complexity table exercise]]
[[credit homework]]
[[gradient descent]]
[[training sample]]
[[variance password]]
[[distribution integer]]
[[gradient descent randomness sample]]
[[neuron net neuron]]
[[series neuron stack neuron layer neuron neural net]]
[[exponent gamma]]
[[programming aspect item algorithm]]
[[guy report hint]]
[[optimizer learning]]
[[port part]]
[[loss sample]]
[[derivative vector]]
[[chain guy]]
[[resource intuition algorithm]]
[[image objective part optimization algorithm]]
[[amount depth exercise]]
[[optimization exercise programming part]]
[[session guy]]
[[gradient curve]]
[[circle neuron stack neuron layer]]
[[gradient descent gradient]]
[[gradient descent algorithm]]
[[accuracy observation performance algorithm objective]]
[[track momentum cursing]]
[[credit report]]
[[author algorithm]]
[[descent sample]]
[[hint exercise]]
[[student office]]
[[layer neuron]]
[[gradient descent optimizer thought]]
